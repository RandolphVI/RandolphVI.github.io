<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="baidu-site-verification" content="IYvqjZ3csg">
<meta name="google-site-verification" content="o9GDuh4E6CmwFpEqUYW7VMmq_fysc1_3PpSQSNWSD8Y">


  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-mac-osx.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css">


  <meta name="keywords" content="Machine Learning,Books,Python,Natural Language Processing,">





  <link rel="alternate" href="/atom.xml" title="黃某人" type="application/atom+xml">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1">






<meta name="description" content="本文是关于「Natural Language Processing with Python」这本书的 Chapter 1 &amp; 2 的学习笔记。">
<meta name="keywords" content="Machine Learning,Books,Python,Natural Language Processing">
<meta property="og:type" content="article">
<meta property="og:title" content="♞「Books」NLP with Python - Chapter 1 &amp; 2">
<meta property="og:url" content="http://randolph.pro/2015/09/11/♞「Books」NLP with Python - Chapter 1 & 2/index.html">
<meta property="og:site_name" content="黃某人">
<meta property="og:description" content="本文是关于「Natural Language Processing with Python」这本书的 Chapter 1 &amp; 2 的学习笔记。">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://farm5.staticflickr.com/4423/36425940061_fe957aaf15_o.jpg">
<meta property="og:image" content="https://farm1.staticflickr.com/445/31263100710_d839312795_o.png">
<meta property="og:image" content="https://farm1.staticflickr.com/474/31598383846_537809b299_o.png">
<meta property="og:image" content="https://farm5.staticflickr.com/4352/36729830135_f3a2ba6679_o.png">
<meta property="og:image" content="https://farm5.staticflickr.com/4431/35896100614_0455b1c8b5_o.png">
<meta property="og:image" content="https://farm5.staticflickr.com/4372/36755792555_824c407bc2_o.png">
<meta property="og:image" content="https://farm5.staticflickr.com/4372/36755792555_824c407bc2_o.png">
<meta property="og:updated_time" content="2019-03-17T06:37:49.364Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="♞「Books」NLP with Python - Chapter 1 &amp; 2">
<meta name="twitter:description" content="本文是关于「Natural Language Processing with Python」这本书的 Chapter 1 &amp; 2 的学习笔记。">
<meta name="twitter:image" content="https://farm5.staticflickr.com/4423/36425940061_fe957aaf15_o.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"right","display":"hide","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: 'KGO9YVRPZZ',
      apiKey: 'dcf60767769bda7791ae195caf3dfb10',
      indexName: 'Randolph',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://randolph.pro/2015/09/11/♞「Books」NLP with Python - Chapter 1 & 2/">





  <title>♞「Books」NLP with Python - Chapter 1 & 2 | 黃某人</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?80985281ddae6899cfd57ad9d458b284";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->










</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-right page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">黃某人</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">痴</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  
  <div class="algolia-popup popup search-popup">
    <div class="algolia-search">
      <div class="algolia-search-input-icon">
        <i class="fa fa-search"></i>
      </div>
      <div class="algolia-search-input" id="algolia-search-input"></div>
    </div>

    <div class="algolia-results">
      <div id="algolia-stats"></div>
      <div id="algolia-hits"></div>
      <div id="algolia-pagination" class="algolia-pagination"></div>
    </div>

    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>




    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://randolph.pro/2015/09/11/♞「Books」NLP with Python - Chapter 1 & 2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Randolph">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="黃某人">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">♞「Books」NLP with Python - Chapter 1 & 2</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-plus-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2015-09-11T00:00:00+08:00">
                2015-09-11
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Books/" itemprop="url" rel="index">
                    <span itemprop="name">Books</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Books/Book-「NLP-with-Python」/" itemprop="url" rel="index">
                    <span itemprop="name">Book:「NLP with Python」</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2015/09/11/♞「Books」NLP with Python - Chapter 1 & 2/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2015/09/11/♞「Books」NLP with Python - Chapter 1 & 2/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2015/09/11/♞「Books」NLP with Python - Chapter 1 & 2/" class="leancloud_visitors" data-flag-title="♞「Books」NLP with Python - Chapter 1 & 2">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-fire"></i>
               </span>
               <span class="leancloud-visitors-count"></span>
               <span>℃</span>
               <span class="post-meta-divider">|</span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                <span title="Words count in article">
                  4,821
                </span>
                <span> words </span>
                
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                <span title="Reading time">
                  27
                </span>
                <span> mins </span>
              
            </div>
          

          
              <div class="post-description">
                  本文是关于「Natural Language Processing with Python」这本书的 Chapter 1 & 2 的学习笔记。
              </div>
          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><img src="https://farm5.staticflickr.com/4423/36425940061_fe957aaf15_o.jpg" alt></p>
<p>有关该书的其他学习笔记系列：<a href="http://randolph.pro/categories/Machine-Learning/Natural-Language-Processing/Book-「NLP-with-Python」/">Book:「NLP with Python」</a></p>
<p><strong>说明：由于该书出版较早，里面代码内容均是基于 python 2.x 的，且个别函数无法正常使用。另外，本人学习时，则是采用 python 3.x 与 NLTK 3.x，文章代码内容均进行了适当的修改，特此说明。</strong></p>
<p><strong>另外，该书作者一直有在更新该书，包括一些错误勘正，并且对其进行了从 python 2.x 到 python 3.x 的代码风格转换，可以访问该书网站<a href="http://www.nltk.org/book/" target="_blank" rel="noopener">Natural Language Processing with Python</a>。</strong></p>
<h1 id="Related"><a href="#Related" class="headerlink" title="Related"></a>Related</h1><ul>
<li><strong>NLTK</strong></li>
<li><strong>concordance() function</strong></li>
<li><strong>Word Sense Disambiguation &amp; Pronoun Resolution</strong></li>
<li><strong>Text Corpus Structure</strong></li>
<li><strong>WordNet</strong></li>
</ul>
<hr>
<h1 id="Key"><a href="#Key" class="headerlink" title="Key:"></a>Key:</h1><h2 id="What’s-NLTK"><a href="#What’s-NLTK" class="headerlink" title="What’s NLTK?"></a><strong>What’s NLTK?</strong></h2><p><strong><code>NLTK</code></strong> 是一个自然语言工具包，最初创建于 2001 年，最初是宾州大学计算机与信息科学系计算语言学课程的一部分，大部分 NLP 研究者入门的首选工具。</p>
<p>另外，这本书是关于用 Python 进行自然语言处理的一本入门书，基本上可以看做是 <strong><code>NLTK</code></strong> 这个库的 HandBook，使用的方法均是 <strong><code>nltk</code></strong> 库中的方法。如果希望查阅 API 文档或者是下载安装 <strong><code>NLTK</code></strong>，可以前往 <a href="http://www.nltk.org" target="_blank" rel="noopener"> 官方网站 </a> 下载，官网上提供和的 API 文档涵盖了工具包中的每一个模块、类和函数，详细说明了各种参数，以及用法示例，在此不再赘述。</p>
<ul>
<li><strong>简单介绍一下 <code>NLTK</code> 的几个重要的模块以及功能描述：</strong></li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>语言处理任务</th>
<th>NLTK 模块</th>
<th>功能描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>获取语料库</td>
<td>nltk.corpus</td>
<td>语料库和字典的标准化接口</td>
</tr>
<tr>
<td>字符串处理</td>
<td>nltk.tokenize, nltk.stem</td>
<td>分词、句子分解、提取主干</td>
</tr>
<tr>
<td>搭配探究</td>
<td>nltk.collocations</td>
<td>t- 检验、卡方、点互信息</td>
</tr>
<tr>
<td>词性标识符</td>
<td>nltk.tag</td>
<td>n-gram、backoff、Brill、HMM、TnT</td>
</tr>
<tr>
<td>分类</td>
<td>nltk.classify，nltk.cluster</td>
<td>决策树、最大熵、朴素贝叶斯、EM、k-means</td>
</tr>
<tr>
<td>分块</td>
<td>nltk.chunk</td>
<td>正则表达式、n-gram、命名实体</td>
</tr>
<tr>
<td>解析</td>
<td>nltk.parse</td>
<td>图表、基于特征、一致性、概率性、依赖项</td>
</tr>
<tr>
<td>语义解释</td>
<td>nltk.sem，nltk.inference</td>
<td>ℷ 演算、一阶逻辑、模型检验</td>
</tr>
<tr>
<td>指标评测</td>
<td>nltk.metrice</td>
<td>精度、召回率、协议系数</td>
</tr>
<tr>
<td>概率与估计</td>
<td>nltk.probability</td>
<td>频率分布、平滑概率分布</td>
</tr>
<tr>
<td>应用</td>
<td>nltk.app，nltk.chat</td>
<td>图形化的关键词排序、分析器、WordNet 查看器、聊天机器人</td>
</tr>
<tr>
<td>语言学领域的工作</td>
<td>nltk.toolbox</td>
<td>处理 SIL 数据格式的工具箱</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h2 id="Download-with-NLTK"><a href="#Download-with-NLTK" class="headerlink" title="Download with NLTK"></a>Download with NLTK</h2><p>安装完之后 <strong><code>NLTK</code></strong>，我们还需要下载 <strong><code>NLTK</code></strong> 的语料库，在 Python 解释器中输入：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; nltk.download()</span><br></pre></td></tr></table></figure>
<p>之后，会弹出相应的下载窗口，由于语料库数量较多，内容较大，耐心等待下载完毕。</p>
<hr>
<h2 id="concordance-function"><a href="#concordance-function" class="headerlink" title="concordance function"></a>concordance <strong>function</strong></h2><ul>
<li><strong><code>concordance()</code></strong> 函数：这个函数挺有意思的，是 <strong><code>nltk</code></strong> 下的一个函数，可以显示指定单词的出现情况（使用这个函数，指定单词的大小写不敏感），同时还可以显示一些上下文。下面是该函数的使用场景（其中 text1 的内容是 <code>nltk.book</code> 导入后中的 text1）:</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; text1.concordance(&apos;monstrous&apos;)</span><br><span class="line">    Building index...</span><br><span class="line">    Displaying 11 of 11 matches:</span><br><span class="line">    ong the former , one was of a most monstrous size . ... This came towards us ,</span><br><span class="line">    ON OF THE PSALMS . &quot; Touching that monstrous bulk of the whale or ork we have r</span><br><span class="line">    ll over with a heathenish array of monstrous clubs and spears . Some were thick</span><br><span class="line">    d as you gazed , and wondered what monstrous cannibal and savage could ever hav</span><br><span class="line">    that has survived the flood ; most monstrous and most mountainous ! That Himmal</span><br><span class="line">    they might scout at Moby Dick as a monstrous fable , or still worse and more de</span><br><span class="line">    th of Radney .&apos;&quot; CHAPTER 55 Of the monstrous Pictures of Whales . I shall ere l</span><br><span class="line">    ing Scenes . In connexion with the monstrous pictures of whales , I am strongly</span><br><span class="line">    ere to enter upon those still more monstrous stories of them which are to be fo</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="Word-Sense-Disambiguation-amp-Pronoun-Resolution"><a href="#Word-Sense-Disambiguation-amp-Pronoun-Resolution" class="headerlink" title="Word Sense Disambiguation &amp; Pronoun Resolution"></a>Word Sense Disambiguation &amp; Pronoun Resolution</h2><ul>
<li>Word Sense Disambiguation</li>
</ul>
<p>词义消歧，简而言之，我们需要做的就是分析出特定上下文中的词被赋予的是哪个意思。例如：</p>
<blockquote>
<p>a. <strong>serve</strong>: help with food or drink; hold an office; put ball into play </p>
<p>b. <strong>dish</strong>: plate; course of a meal; communications device</p>
</blockquote>
<ul>
<li>Pronoun Resolution</li>
</ul>
<p>指代消解，是解决“词义消歧”的一个手段，解决“谁对谁做了什么”，即检测动词的主语和宾语，另外还有 <strong> 语义角色标注</strong>（semantic role labing）— 确定名词短语如何与动词相关联（如代理、受事、工具等）。</p>
<hr>
<h2 id="Text-Corpus-Structure"><a href="#Text-Corpus-Structure" class="headerlink" title="Text Corpus Structure"></a>Text Corpus Structure</h2><p>以下是几种常见的语料库结构：</p>
<p><img src="https://farm1.staticflickr.com/445/31263100710_d839312795_o.png" alt></p>
<ul>
<li>最简单的一种语料库是一些孤立的没有什么特别结构的文本集合；</li>
<li>一些语料库按如文体（布朗语料库）等分类成组织结构；</li>
<li>一些分类会重叠，如主题类别（路透社语料库）；</li>
<li>另外一些语料库可以表示随时间变化，语言用法的改变（就职演说语料库）；</li>
</ul>
<hr>
<h2 id="WordNet"><a href="#WordNet" class="headerlink" title="WordNet"></a>WordNet</h2><ul>
<li>Senses and Synonyms.（意义与同义词）</li>
<li>Synonyms and Synset.（同义词集与词条）</li>
<li>The WordNet Hierarchy.（WordNet 的层次结构）</li>
</ul>
<blockquote>
<p>WordNet synsets correspond to abstract concepts, and they don’t always have corre- sponding words in English. These concepts are linked together in a hierarchy. Some concepts are very general, such as Entity, State, Event; these are called unique begin- ners or root synsets. Others, such as gas guzzler and hatchback, are much more specific.</p>
</blockquote>
<p>WordNet 概念的层次片段：每个节点对应一个同义词集；边表示上位词 / 下位词关系，即上级概念与从属概念的关系。</p>
<p><img src="https://farm1.staticflickr.com/474/31598383846_537809b299_o.png" alt></p>
<ul>
<li>Hyponyms and Hypernyms.（下位词与上位词）</li>
<li>Antonyms.（反义词）</li>
</ul>
<hr>
<h1 id="Correct-errors-in-printing"><a href="#Correct-errors-in-printing" class="headerlink" title="Correct errors in printing:"></a>Correct errors in printing:</h1><ul>
<li>P19:</li>
</ul>
<p>在 「Frequency Distributions」 的那块内容中：</p>
<blockquote>
<p>… for <code>text2</code>. Be careful to use … If you get an error message <code>NameError: name &#39;FreqDist&#39;is not defined</code>, you need to start your work with <strong><code>from nltk.book import *</code></strong>。</p>
</blockquote>
<p>需更正为：</p>
<blockquote>
<p>… for <code>text2</code>. Be careful to use … If you get an error message <code>NameError: name &#39;FreqDist&#39;is not defined</code>, you need to start your work with <strong><code>from nltk import *</code></strong>。</p>
</blockquote>
<p><strong>原因：<code>nltk.book</code> 中并不存在 <code>FreqDist()</code> 这一函数。</strong></p>
<hr>
<h1 id="Practice"><a href="#Practice" class="headerlink" title="Practice:"></a>Practice:</h1><p>Chapter 1 的习题比较简单，因此以下均是 Chapter 2 的习题解答：</p>
<blockquote>
<p>4.○ Read in the texts of the <strong><em>State of the Union</em></strong> addresses, using the <strong><code>state_union</code></strong> corpus reader. Count occurrences of <strong>men</strong>, <strong>women</strong>, and <strong>people</strong> in each document. What has happened to the usage of these words over time?</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> state_union</span><br><span class="line"></span><br><span class="line">cfd = nltk.ConditionalFreqDist(</span><br><span class="line">    (target, fileid[:<span class="number">4</span>])</span><br><span class="line">    <span class="keyword">for</span> fileid <span class="keyword">in</span> state_union.fileids()</span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> state_union.words(fileid)</span><br><span class="line">    <span class="keyword">for</span> target <span class="keyword">in</span> [<span class="string">'men'</span>, <span class="string">'women'</span>, <span class="string">'people'</span>]</span><br><span class="line">    <span class="keyword">if</span> w.lower() == target)</span><br><span class="line">cfd.plot()</span><br></pre></td></tr></table></figure>
<p><img src="https://farm5.staticflickr.com/4352/36729830135_f3a2ba6679_o.png" alt></p>
<hr>
<blockquote>
<p>5.○ Investigate the holonym-meronym relations for some nouns. Remember that there are three kinds of holonym-meronym relation, so you need to use <strong><code>member_mer onyms()</code></strong>, <strong><code>part_meronyms()</code></strong>, <strong><code>substance_meronyms()</code></strong>, <strong><code>member_holonyms()</code></strong>, <strong><code>part_holonyms()</code></strong>, and <strong><code>substance_holonyms()</code></strong>.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> wordnet <span class="keyword">as</span> wn</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relations</span><span class="params">(noun)</span>:</span></span><br><span class="line">    noun_synset = wn.synset(noun)</span><br><span class="line">    print(<span class="string">'Member Meronyms: \n'</span>)</span><br><span class="line">    print(noun_synset.member_meronyms())</span><br><span class="line">    print(<span class="string">'\n Part Meronyms: \n'</span>)</span><br><span class="line">    print(noun_synset.part_meronyms())</span><br><span class="line">    print(<span class="string">'\n Substance Meronyms: \n'</span>)</span><br><span class="line">    print(noun_synset.substance_meronyms())</span><br><span class="line">    print(<span class="string">'\n Member Holonyms: \n'</span>)</span><br><span class="line">    print(noun_synset.member_holonyms())</span><br><span class="line">    print(<span class="string">'\n Part Holonyms: \n'</span>)</span><br><span class="line">    print(noun_synset.part_holonyms())</span><br><span class="line">    print(<span class="string">'\n Substance Holonyms: \n'</span>)</span><br><span class="line">    print(noun_synset.substance_holonyms())</span><br><span class="line">relations(<span class="string">'tree.n.01'</span>)</span><br><span class="line">print(<span class="string">'----------\n'</span>)</span><br><span class="line">relations(<span class="string">'honey.n.01'</span>)</span><br><span class="line">print(<span class="string">'----------\n'</span>)</span><br><span class="line">relations(<span class="string">'wood.n.01'</span>)</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>6.○ In the discussion of comparative wordlists, we created an object called <strong>translate</strong>, which you could look up using words in both German and Italian in order to get corresponding words in English. What problem might arise with this approach? Can you suggest a way to avoid this problem?</p>
</blockquote>
<ul>
<li>在德语与意大利语中可能存在拼写相同的单词，通过 <strong>translate</strong> 转换成英语之后分别得到不同的翻译结果。解决办法就是，添加语言 <code>tag</code> 标记在各个单词上，避免上述情况发生。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> swadesh</span><br><span class="line"><span class="comment"># 意大利语转英语，添加 '-it' 语言标记</span></span><br><span class="line">it2en = [(i + <span class="string">'-it'</span>, e) <span class="keyword">for</span> (i, e) <span class="keyword">in</span> swadesh.entries([<span class="string">'it'</span>, <span class="string">'en'</span>])]</span><br><span class="line">translate = dict(it2en)</span><br><span class="line">print(translate[<span class="string">'madre-it'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 德语转英语，添加 '-de' 语言标记</span></span><br><span class="line">de2en = [(d + <span class="string">'-de'</span>, e) <span class="keyword">for</span> (d, e) <span class="keyword">in</span> swadesh.entries([<span class="string">'de'</span>, <span class="string">'en'</span>])]</span><br><span class="line">translate.update(dict(de2en))</span><br><span class="line">print(translate[<span class="string">'Hund-de'</span>])</span><br></pre></td></tr></table></figure>
<ul>
<li>另外，如果输入错误（例如不存在的词语或者其他没有通过 <strong><code>translate.update(dict(xx))</code></strong> 加入字典的语言词语，则会引发 <strong>KeyError</strong>）。其中一个解决办法是，添加一个错误处理情况。</li>
</ul>
<hr>
<blockquote>
<p>7.○ According to Strunk and White’s <strong><em>Elements of Style</em></strong>, the word <strong>however</strong>, used at the start of a sentence, means “in whatever way” or “to whatever extent,” and not “nevertheless.” They give this example of correct usage: <a href="http://www.bartleby.com/141/strunk3.html" target="_blank" rel="noopener">However you advise him, he will probably do as he thinks best.</a> Use the concordance tool to study actual usage of this word in the various texts we have been considering. See also the <strong>LanguageLog</strong> posting “Fossilized prejudices about ‘however’” at <a href="http://itre.cis.upenn.edu/~myl/languagelog/archives/001913.html" target="_blank" rel="noopener">this website</a>.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">emma = nltk.Text(gutenberg.words(<span class="string">'austen-emma.txt'</span>))</span><br><span class="line">emma.concordance(<span class="string">'however'</span>)</span><br><span class="line">print(<span class="string">'----------\n'</span>)</span><br><span class="line">last = inaugural.fileids()[<span class="number">-3</span>]</span><br><span class="line">print(last)</span><br><span class="line">inaugural = nltk.Text(inaugural.words(last))</span><br><span class="line">inaugural.concordance(<span class="string">'however'</span>)</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>8.◑ Define a conditional frequency distribution over the Names Corpus that allows you to see which initial letters are more frequent for males versus females (see Figure 2-7).</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"></span><br><span class="line">names = nltk.corpus.names</span><br><span class="line">cfd = nltk.ConditionalFreqDist(</span><br><span class="line">    (fileid, name[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">for</span> fileid <span class="keyword">in</span> names.fileids()</span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> names.words(fileid))</span><br><span class="line">cfd.plot()</span><br></pre></td></tr></table></figure>
<p><img src="https://farm5.staticflickr.com/4431/35896100614_0455b1c8b5_o.png" alt></p>
<hr>
<blockquote>
<p>9.◑ Pick a pair of texts and study the differences between them, in terms of vocabulary, vocabulary richness, genre, etc. Can you find pairs of words that have quite different meanings across the two texts, such as <strong>monstrous</strong> in <strong><em>Moby Dick</em></strong> and in <strong><em>Sense</em></strong> and Sensibility?</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">religion = brown.words(fileids=<span class="string">'cd12'</span>)</span><br><span class="line">movie = webtext.words(fileids=<span class="string">'pirates.txt'</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Vocabulary of Book1: %d'</span> % len(set(religion)))</span><br><span class="line">print(<span class="string">'Vocabulary Richness of Book1: %f'</span> % (len(set(religion)) / len(religion)))</span><br><span class="line"></span><br><span class="line">print(<span class="string">'----------\n'</span>)</span><br><span class="line">print(<span class="string">'Vocabulary of Book2: %d'</span> % len(set(movie)))</span><br><span class="line">print(<span class="string">'Vocabulary Richness Book2: %f'</span> % (len(set(movie)) / len(movie)))</span><br><span class="line">print(<span class="string">'----------\n'</span>)</span><br><span class="line"></span><br><span class="line">movie_text = nltk.Text(movie)</span><br><span class="line">religion_text = nltk.Text(religion)</span><br><span class="line"></span><br><span class="line"><span class="comment">## Word use:</span></span><br><span class="line">movie_text.concordance(<span class="string">'love'</span>)</span><br><span class="line">print(<span class="string">'----------\n'</span>)</span><br><span class="line">religion_text.concordance(<span class="string">'love'</span>)</span><br><span class="line">print(<span class="string">'----------\n'</span>)</span><br><span class="line"></span><br><span class="line">movie_text.concordance(<span class="string">'bear'</span>)</span><br><span class="line">print(<span class="string">'----------\n'</span>)</span><br><span class="line">religion_text.concordance(<span class="string">'bear'</span>)</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>10.◑ Read the BBC News article: “UK’s Vicky Pollards ‘left behind’” at <a href="http://news.bbc.co.uk/1/hi/education/6173441.stm" target="_blank" rel="noopener">this website</a>. The article gives the following statistic about teen language: “the top 20 words used, including <strong>yeah</strong>, <strong>no</strong>, <strong>but</strong> and like, account for around a third of all words.” How many word types account for a third of all word tokens, for a variety of text sources? What do you conclude about this statistic? Read more about this on LanguageLog, at <a href="http://itre.cis.upenn.edu/~myl/languagelog/archives/003993.html" target="_blank" rel="noopener">this website</a>.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">emma = gutenberg.words(<span class="string">'austen-emma.txt'</span>)</span><br><span class="line">inaugural = inaugural.words(<span class="string">'2001-Bush.txt'</span>)</span><br><span class="line">religion = brown.words(fileids=<span class="string">'cd12'</span>)</span><br><span class="line">movie = webtext.words(fileids=<span class="string">'pirates.txt'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">third_of_tokens</span><span class="params">(text)</span>:</span></span><br><span class="line">    words_in_text = [w <span class="keyword">for</span> w <span class="keyword">in</span> text <span class="keyword">if</span> any(c.isalpha() <span class="keyword">for</span> c <span class="keyword">in</span> w)]</span><br><span class="line"></span><br><span class="line">    fd = nltk.FreqDist(words_in_text)</span><br><span class="line">    most = fd.most_common(<span class="number">1000</span>)</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    third_words = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> word, num <span class="keyword">in</span> most:</span><br><span class="line">        <span class="keyword">if</span> ((count &lt; (len(words_in_text) / <span class="number">3</span>)) &amp; any(c.isalpha() <span class="keyword">for</span> c <span class="keyword">in</span> word)):</span><br><span class="line">            count = count + num</span><br><span class="line">            third_words.append(word)</span><br><span class="line">    print(third_words)        </span><br><span class="line">    print(len(third_words))</span><br><span class="line">    </span><br><span class="line">third_of_tokens(emma)</span><br><span class="line">third_of_tokens(inaugural)</span><br><span class="line">third_of_tokens(religion)</span><br><span class="line">third_of_tokens(movie)</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>11.◑ Investigate the table of modal distributions and look for other patterns. Try to explain them in terms of your own impressionistic understanding of the different genres. Can you find other closed classes of words that exhibit significant differences across different genres?</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> brown</span><br><span class="line"></span><br><span class="line">cfd = nltk.ConditionalFreqDist(</span><br><span class="line">    (genre, word)</span><br><span class="line">    <span class="keyword">for</span> genre <span class="keyword">in</span> brown.categories()</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> brown.words(categories=genre))</span><br><span class="line"></span><br><span class="line">genres = [<span class="string">'adventure'</span>, <span class="string">'belles_lettres'</span>, <span class="string">'editorial'</span>, <span class="string">'fiction'</span>, <span class="string">'government'</span>, <span class="string">'hobbies'</span>, <span class="string">'humor'</span>, <span class="string">'learned'</span>, <span class="string">'lore'</span>, <span class="string">'mystery'</span>, <span class="string">'news'</span>, <span class="string">'religion'</span>, <span class="string">'reviews'</span>, <span class="string">'romance'</span>, <span class="string">'science_fiction'</span>]</span><br><span class="line"></span><br><span class="line">pronouns = [<span class="string">'I'</span>, <span class="string">'you'</span>, <span class="string">'he'</span>, <span class="string">'she'</span>, <span class="string">'it'</span>, <span class="string">'we'</span>, <span class="string">'they'</span>]</span><br><span class="line">cfd.tabulate(conditions=genres, samples=pronouns)</span><br><span class="line">print(<span class="string">'----------\n'</span>)</span><br><span class="line">wh = [<span class="string">'what'</span>, <span class="string">'when'</span>, <span class="string">'who'</span>, <span class="string">'why'</span>, <span class="string">'where'</span>]</span><br><span class="line">cfd.tabulate(conditions=genres, samples=wh)</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>12.◑ The CMU Pronouncing Dictionary contains multiple pronunciations for certain words. How many distinct words does it contain? What fraction of words in this dictionary have more than one possible pronunciation?</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> cmudict</span><br><span class="line"></span><br><span class="line">count_distinct = <span class="number">0</span></span><br><span class="line">dublettes = []</span><br><span class="line">prev = <span class="string">''</span></span><br><span class="line"><span class="keyword">for</span> entry <span class="keyword">in</span> cmudict.entries():</span><br><span class="line">    <span class="keyword">if</span> ((entry[<span class="number">0</span>] == prev) <span class="keyword">and</span> (entry[<span class="number">0</span>] <span class="keyword">not</span> <span class="keyword">in</span> dublettes)):</span><br><span class="line">        dublettes.append(entry[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">else</span>: </span><br><span class="line">        count_distinct = count_distinct + <span class="number">1</span></span><br><span class="line">        prev = entry[<span class="number">0</span>]</span><br><span class="line">print(count_distinct)</span><br><span class="line">print(<span class="string">'The fraction: %f'</span> % ((len(dublettes) / count_distinct)))</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>13.◑ What percentage of noun synsets have no hyponyms? You can get all noun synsets using <strong><code>wn.all_synsets(&#39;n&#39;)</code></strong>.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> wordnet <span class="keyword">as</span> wn</span><br><span class="line"></span><br><span class="line">all_syns = list(wn.all_synsets(<span class="string">'n'</span>))</span><br><span class="line">no_hyponyms = [s <span class="keyword">for</span> s <span class="keyword">in</span> all_syns <span class="keyword">if</span> len(s.hyponyms()) == <span class="number">0</span>]</span><br><span class="line">print(<span class="string">'The fraction: %f'</span> % (len(no_hyponyms) / len(all_syns)))</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>14.◑ Define a function <strong><code>supergloss(s)</code></strong> that takes a synset s as its argument and returns a string consisting of the concatenation of the definition of <strong>s</strong>, and the definitions of all the hypernyms and hyponyms of <strong>s</strong>.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> wordnet <span class="keyword">as</span> wn</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">supergloss</span><span class="params">(s)</span>:</span></span><br><span class="line">    gloss = <span class="string">'definition:'</span> + s.definition() + <span class="string">'\n\n'</span></span><br><span class="line">    gloss = gloss + <span class="string">'Hypernyms:\n'</span></span><br><span class="line">    <span class="keyword">for</span> hypernym <span class="keyword">in</span> s.hypernyms():</span><br><span class="line">        gloss = gloss + hypernym.name() + <span class="string">':'</span> + hypernym.definition() + <span class="string">'\n'</span></span><br><span class="line">    gloss = gloss + <span class="string">'\nHyponyms:\n'</span></span><br><span class="line">    <span class="keyword">for</span> hyponym <span class="keyword">in</span> s.hyponyms():</span><br><span class="line">        gloss = gloss + hyponym.name() + <span class="string">':'</span> + hyponym.definition() + <span class="string">'\n'</span></span><br><span class="line">    <span class="keyword">return</span> gloss</span><br><span class="line"></span><br><span class="line">print(supergloss(wn.synset(<span class="string">'bicycle.n.01'</span>)))</span><br><span class="line">print(<span class="string">'----------\n'</span>)</span><br><span class="line">print(supergloss(wn.synset(<span class="string">'believe.v.01'</span>)))</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>15.◑ Write a program to find all words that occur at least three times in the Brown Corpus.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> brown</span><br><span class="line"></span><br><span class="line">fd = nltk.FreqDist(brown.words())</span><br><span class="line">triple_words = [w <span class="keyword">for</span> w <span class="keyword">in</span> fd.keys() <span class="keyword">if</span> fd[w] &gt; <span class="number">2</span>]</span><br><span class="line">print(len(brown.words()))</span><br><span class="line">print(len(triple_words))</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>16.◑ Write a program to generate a table of lexical diversity scores (i.e., token/type ratios), as we saw in Table 1-1. Include the full set of Brown Corpus genres (<strong><code>nltk.corpus.brown.categories()</code></strong>). Which genre has the lowest diversity (greatest number of tokens per type)? Is this what you would have expected?</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> brown</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lexical_diversity</span><span class="params">(text)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> (len(text) / len(set(text)))</span><br><span class="line"><span class="keyword">for</span> genre <span class="keyword">in</span> brown.categories():</span><br><span class="line">    print(genre + <span class="string">':'</span> + str(lexical_diversity(brown.words(categories=genre))))</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>17.◑ Write a function that finds the 50 most frequently occurring words of a text that are not stopwords.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">most_frequent_content_words</span><span class="params">(text)</span>:</span></span><br><span class="line">    stopwords_list = stopwords.words(<span class="string">'english'</span>)</span><br><span class="line">    content_words = [w.lower() <span class="keyword">for</span> w <span class="keyword">in</span> text <span class="keyword">if</span> w.lower() <span class="keyword">not</span> <span class="keyword">in</span> stopwords_list <span class="keyword">and</span> any(c.isalpha() <span class="keyword">for</span> c <span class="keyword">in</span> w)]</span><br><span class="line">    fd = nltk.FreqDist(content_words)</span><br><span class="line">    <span class="keyword">return</span> [w <span class="keyword">for</span> w, num <span class="keyword">in</span> fd.most_common(<span class="number">50</span>)]</span><br><span class="line">    </span><br><span class="line">emma = gutenberg.words(<span class="string">'austen-emma.txt'</span>)</span><br><span class="line">movie = webtext.words(fileids=<span class="string">'pirates.txt'</span>)</span><br><span class="line">print(most_frequent_content_words(emma))</span><br><span class="line">print(<span class="string">'----------\n'</span>)</span><br><span class="line">print(most_frequent_content_words(movie))</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>18.◑ Write a program to print the 50 most frequent bigrams (pairs of adjacent words) of a text, omitting bigrams that contain stopwords.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">most_frequent_bigrams</span><span class="params">(text)</span>:</span></span><br><span class="line">    stopwords_list = stopwords.words(<span class="string">'english'</span>)</span><br><span class="line">    bigrams = [b <span class="keyword">for</span> b <span class="keyword">in</span> nltk.bigrams(text) <span class="keyword">if</span> b[<span class="number">0</span>] <span class="keyword">not</span> <span class="keyword">in</span> stopwords_list <span class="keyword">and</span> b[<span class="number">1</span>] <span class="keyword">not</span> <span class="keyword">in</span> stopwords_list <span class="keyword">and</span> any(c.isalpha() <span class="keyword">for</span> c <span class="keyword">in</span> b[<span class="number">0</span>]) <span class="keyword">and</span> any(c.isalpha() <span class="keyword">for</span> c <span class="keyword">in</span> b[<span class="number">1</span>])]</span><br><span class="line">    fd = nltk.FreqDist(bigrams)</span><br><span class="line">    <span class="keyword">return</span> [b <span class="keyword">for</span> b, num <span class="keyword">in</span> fd.most_common(<span class="number">50</span>)]</span><br><span class="line"></span><br><span class="line">emma = gutenberg.words(<span class="string">'austen-emma.txt'</span>)</span><br><span class="line">movie = webtext.words(fileids=<span class="string">'pirates.txt'</span>)</span><br><span class="line">print(most_frequent_bigrams(emma))</span><br><span class="line">print(<span class="string">'----------\n'</span>)</span><br><span class="line">print(most_frequent_bigrams(movie))</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>19.◑ Write a program to create a table of word frequencies by genre, like the one given in Section 2.1 for modals. Choose your own words and try to find words whose presence (or absence) is typical of a genre. Discuss your findings.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> brown</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">table</span><span class="params">(words, genres)</span>:</span></span><br><span class="line">    cfd = nltk.ConditionalFreqDist(</span><br><span class="line">        (genre, word)</span><br><span class="line">        <span class="keyword">for</span> genre <span class="keyword">in</span> brown.categories()</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> brown.words(categories=genre))</span><br><span class="line">    cfd.tabulate(conditions=genres, samples=words)</span><br><span class="line">    </span><br><span class="line">table([<span class="string">'perhaps'</span>, <span class="string">'maybe'</span>, <span class="string">'possibly'</span>, <span class="string">'surely'</span>, <span class="string">'certainly'</span>, <span class="string">'absolutely'</span>], [<span class="string">'news'</span>, <span class="string">'religion'</span>, <span class="string">'government'</span>, <span class="string">'learned'</span>, <span class="string">'fiction'</span>, <span class="string">'romance'</span>, <span class="string">'humor'</span>])</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>20.◑ Write a function <strong><code>word_freq()</code></strong> that takes a word and the name of a section of the Brown Corpus as arguments, and computes the frequency of the word in that sec- tion of the corpus.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> brown</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">word_freq</span><span class="params">(word, genre)</span>:</span></span><br><span class="line">    fd = nltk.FreqDist(brown.words(categories=genre))</span><br><span class="line">    <span class="keyword">return</span> fd[word]</span><br><span class="line"></span><br><span class="line">print(word_freq(<span class="string">'God'</span>, <span class="string">'religion'</span>))</span><br><span class="line">print(word_freq(<span class="string">'God'</span>, <span class="string">'government'</span>))</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>21.◑ Write a program to guess the number of syllables contained in a text, making use of the CMU Pronouncing Dictionary.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">prondict = cmudict.dict()</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">guess_syllables</span><span class="params">(text)</span>:</span></span><br><span class="line">    count_syllables = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> text:</span><br><span class="line">        <span class="keyword">if</span> any(c.isalpha() <span class="keyword">for</span> c <span class="keyword">in</span> word):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                pron = prondict[word.lower()][<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">except</span> KeyError:</span><br><span class="line">                print(<span class="string">'"'</span> + word.lower() + <span class="string">'" does not exist in CMU!'</span>)</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">else</span>:    </span><br><span class="line">                <span class="keyword">for</span> syllable <span class="keyword">in</span> pron:</span><br><span class="line">                    <span class="keyword">if</span> any(c.isnumeric() <span class="keyword">for</span> c <span class="keyword">in</span> syllable):</span><br><span class="line">                        count_syllables = count_syllables + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> count_syllables</span><br><span class="line"></span><br><span class="line">print(guess_syllables([<span class="string">'She'</span>, <span class="string">'sells'</span>, <span class="string">'seashells'</span>, <span class="string">'by'</span>, <span class="string">'the'</span>, <span class="string">'seashore'</span>]))</span><br><span class="line">print(<span class="string">'----------\n'</span>)</span><br><span class="line">print(guess_syllables([<span class="string">'This'</span>, <span class="string">'is'</span>, <span class="string">'an'</span>, <span class="string">'absolutely'</span>, <span class="string">'fantastic'</span>, <span class="string">'pythonic'</span>, <span class="string">'program'</span>, <span class="string">'.'</span>]))</span><br><span class="line">print(<span class="string">'----------\n'</span>)</span><br><span class="line">print(guess_syllables(nltk.Text(brown.words(fileids=<span class="string">'cd12'</span>))))    <span class="comment"># religion_text</span></span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>22.◑ Define a function <strong><code>hedge(text)</code></strong> that processes a text and produces a new version with the word <strong>‘like’</strong> between every third word.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hedge</span><span class="params">(text)</span>:</span></span><br><span class="line">    text_hedged = []</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> text:</span><br><span class="line">        text_hedged.append(word)</span><br><span class="line">        count = count + <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> count == <span class="number">3</span>:</span><br><span class="line">            text_hedged.append(<span class="string">'like'</span>)</span><br><span class="line">            count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> text_hedged</span><br><span class="line"></span><br><span class="line">new_text = hedge([<span class="string">'She'</span>, <span class="string">'sells'</span>, <span class="string">'seashells'</span>, <span class="string">'by'</span>, <span class="string">'the'</span>, <span class="string">'seashore'</span>, <span class="string">'the'</span>, <span class="string">'shells'</span>, <span class="string">'she'</span>, <span class="string">'sells'</span>, <span class="string">'are'</span>, <span class="string">'seashells'</span>])</span><br><span class="line">print(new_text)</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>23.● <strong>Zipf’s Law</strong>: Let <strong><code>f(w)</code></strong> be the frequency of a word <em>w</em> in free text. Suppose that all the words of a text are ranked according to their frequency, with the most frequent word first. Zipf’s Law states that the frequency of a word type is inversely proportional to its rank (i.e., <em>f × r = k</em>, for some constant <em>k</em>). For example, the 50th most common word type should occur three times as frequently as the 150th most common word type.<br>a. Write a function to process a large text and plot word frequency against word rank using <strong><code>pylab.plot</code></strong>. Do you confirm Zipf’s law? (Hint: it helps to use a logarithmic scale.) What is going on at the extreme ends of the plotted line?</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">emma = gutenberg.words(<span class="string">'austen-emma.txt'</span>)</span><br><span class="line">religion = brown.words(fileids=<span class="string">'cd12'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">zipf</span><span class="params">(text)</span>:</span></span><br><span class="line">    fd = nltk.FreqDist(text)</span><br><span class="line">    rank = <span class="number">1</span></span><br><span class="line">    freqs = []</span><br><span class="line">    ranks = []</span><br><span class="line">    <span class="keyword">for</span> sample, count <span class="keyword">in</span> fd.most_common(<span class="number">200</span>):</span><br><span class="line">        <span class="keyword">if</span> any(c.isalpha() <span class="keyword">for</span> c <span class="keyword">in</span> sample):</span><br><span class="line">            freqs.append(fd.freq(sample))</span><br><span class="line">            ranks.append(rank)</span><br><span class="line">            rank = rank + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> (ranks, freqs)</span><br><span class="line"></span><br><span class="line">plt.figure(<span class="number">1</span>)</span><br><span class="line">plt.subplot(<span class="number">121</span>)</span><br><span class="line">plt.plot(zipf(emma)[<span class="number">0</span>], zipf(emma)[<span class="number">1</span>])</span><br><span class="line">plt.xlabel(<span class="string">'Ranks'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Freqs'</span>)</span><br><span class="line">plt.title(<span class="string">'emma'</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">122</span>)</span><br><span class="line">plt.plot(zipf(religion)[<span class="number">0</span>], zipf(religion)[<span class="number">1</span>])</span><br><span class="line">plt.xlabel(<span class="string">'Ranks'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Freqs'</span>)</span><br><span class="line">plt.title(<span class="string">'religion'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://farm5.staticflickr.com/4372/36755792555_824c407bc2_o.png" alt></p>
<p>b. Generate random text, e.g., using <strong><code>random.choice(&quot;abcdefg &quot;)</code></strong>, taking care to include the space character. You will need to <strong><code>import random first</code></strong>. Use the string concatenation operator to accumulate characters into a (very) long string. Then tokenize this string, generate the Zipf plot as before, and compare the two plots. What do you make of Zipf’s Law in the light of this?</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">zipf</span><span class="params">(text)</span>:</span></span><br><span class="line">    fd = nltk.FreqDist(text)</span><br><span class="line">    rank = <span class="number">1</span></span><br><span class="line">    freqs = []</span><br><span class="line">    ranks = []</span><br><span class="line">    <span class="keyword">for</span> sample, count <span class="keyword">in</span> fd.most_common(<span class="number">200</span>):</span><br><span class="line">        <span class="keyword">if</span> any(c.isalpha() <span class="keyword">for</span> c <span class="keyword">in</span> sample):</span><br><span class="line">            freqs.append(fd.freq(sample))</span><br><span class="line">            ranks.append(rank)</span><br><span class="line">            rank = rank + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> (ranks, freqs)</span><br><span class="line"></span><br><span class="line">random_text = <span class="string">''</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100000</span>):</span><br><span class="line">    random_text = random_text + random.choice(<span class="string">'abcdefg '</span>)</span><br><span class="line">text_split = random_text.split()</span><br><span class="line"></span><br><span class="line">plt.figure(<span class="number">1</span>)</span><br><span class="line">plt.plot(zipf(text_split)[<span class="number">0</span>], zipf(text_split)[<span class="number">1</span>])</span><br><span class="line">plt.xlabel(<span class="string">'Ranks'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Freqs'</span>)</span><br><span class="line">plt.title(<span class="string">'Random Text'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://farm5.staticflickr.com/4372/36755792555_824c407bc2_o.png" alt></p>
<hr>
<blockquote>
<p>24.● Modify the text generation program in Example 2-1 further, to do the following tasks:<br>a. Store the <em>n</em> most likely words in a list words, then randomly choose a word from the list using <strong><code>random.choice()</code></strong>. (You will need to <strong><code>import random</code></strong> first.)<br>b. Select a particular genre, such as a section of the Brown Corpus or a Genesis translation, one of the Gutenberg texts, or one of the Web texts. Train the model on this corpus and get it to generate random text. You may have to experiment with different start words. How intelligible is the text? Discuss the strengths and weaknesses of this method of generating random text.<br>c. Now train your system using two distinct genres and experiment with generating text in the hybrid genre. Discuss your observations.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">emma = gutenberg.words(<span class="string">'austen-emma.txt'</span>)</span><br><span class="line">religion = brown.words(fileids=<span class="string">'cd12'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_model_random</span><span class="params">(text, num=<span class="number">15</span>, n=<span class="number">50</span>)</span>:</span></span><br><span class="line">    words = [w <span class="keyword">for</span> w, count <span class="keyword">in</span> nltk.FreqDist(text).most_common(n)]</span><br><span class="line">    word = random.choice(words)</span><br><span class="line">    result = <span class="string">''</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">        result = result + word + <span class="string">' '</span></span><br><span class="line">        word = random.choice(words)</span><br><span class="line">    print(result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Question b</span></span><br><span class="line">generate_model_random(emma)</span><br><span class="line">generate_model_random(religion, <span class="number">25</span>, <span class="number">200</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Question c</span></span><br><span class="line">generate_model_random(brown.words(categories=[<span class="string">'news'</span>, <span class="string">'romance'</span>]))</span><br><span class="line">generate_model_random(brown.words(categories=[<span class="string">'news'</span>, <span class="string">'romance'</span>]), <span class="number">100</span>, <span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>25.● Define a function <strong><code>find_language()</code></strong> that takes a string as its argument and returns a list of languages that have that string as a word. Use the <strong>udhr</strong> corpus and limit your searches to files in the Latin-1 encoding.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> udhr</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_language</span><span class="params">(word)</span>:</span></span><br><span class="line">    languages = []</span><br><span class="line">    <span class="keyword">for</span> fileid <span class="keyword">in</span> udhr.fileids():</span><br><span class="line">        <span class="keyword">if</span> fileid.endswith(<span class="string">'-Latin1'</span>) <span class="keyword">and</span> word <span class="keyword">in</span> udhr.words(fileid):</span><br><span class="line">            languages.append(fileid[:<span class="number">-7</span>])</span><br><span class="line">    <span class="keyword">return</span> languages     </span><br><span class="line">            </span><br><span class="line">print(find_language(<span class="string">'and'</span>))</span><br><span class="line"><span class="keyword">print</span> find_language(<span class="string">'in'</span>)</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>26.● What is the branching factor of the noun hypernym hierarchy? I.e., for every noun synset that has hyponyms—or children in the hypernym hierarchy—how many do they have on average? You can get all noun synsets using <strong><code>wn.all_syn sets(&#39;n&#39;)</code></strong>.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> wordnet <span class="keyword">as</span> wn</span><br><span class="line"></span><br><span class="line">num_hyponyms = <span class="number">0</span></span><br><span class="line">sum_hyponyms = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> synset <span class="keyword">in</span> wn.all_synsets(<span class="string">'n'</span>):</span><br><span class="line">    hyponyms = synset.hyponyms()</span><br><span class="line">    <span class="keyword">if</span> len(hyponyms) &gt; <span class="number">0</span>:</span><br><span class="line">        num_hyponyms = num_hyponyms + <span class="number">1</span></span><br><span class="line">        sum_hyponyms = sum_hyponyms + len(hyponyms)</span><br><span class="line">        </span><br><span class="line">print(sum_hyponyms / num_hyponyms)</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>27.● The polysemy of a word is the number of senses it has. Using WordNet, we can determine that the noun <em>dog</em> has seven senses with <strong><code>len(wn.synsets(&#39;dog&#39;, &#39;n&#39;))</code></strong>. Compute the average polysemy of nouns, verbs, adjectives, and adverbs according to WordNet.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> wordnet <span class="keyword">as</span> wn</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">average_polysemy</span><span class="params">(category)</span>:</span></span><br><span class="line">    seen_words = []</span><br><span class="line">    num_poly = <span class="number">0</span></span><br><span class="line">    sum_poly = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> synset <span class="keyword">in</span> wn.all_synsets(category):</span><br><span class="line">        <span class="comment"># Too many words, it's necessary to limit.</span></span><br><span class="line">        <span class="keyword">if</span> num_poly &gt; <span class="number">20000</span>:</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">for</span> lemma <span class="keyword">in</span> synset.lemmas():</span><br><span class="line">            lemma_name = lemma.name()</span><br><span class="line">            <span class="keyword">if</span> lemma_name <span class="keyword">not</span> <span class="keyword">in</span> seen_words:</span><br><span class="line">                seen_words.append(lemma_name)</span><br><span class="line">                num_poly = num_poly + <span class="number">1</span></span><br><span class="line">                sum_poly = sum_poly + len(wn.synsets(lemma_name, category))</span><br><span class="line">    <span class="keyword">return</span> (sum_poly / num_poly)</span><br><span class="line"></span><br><span class="line">print(average_polysemy(<span class="string">'n'</span>))</span><br><span class="line">print(average_polysemy(<span class="string">'v'</span>))</span><br><span class="line">print(average_polysemy(<span class="string">'a'</span>))</span><br><span class="line">print(average_polysemy(<span class="string">'r'</span>))</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>28.● Use one of the predefined similarity measures to score the similarity of each of the following pairs of words. Rank the pairs in order of decreasing similarity. How close is your ranking to the order given here, an order that was established exper- imentally by (Miller &amp; Charles, 1998): <strong><code>car-automobile</code></strong>, <strong><code>gem-jewel</code></strong>, <strong><code>journey-voyage</code></strong>, <strong><code>boy-lad</code></strong>, <strong><code>coast-shore</code></strong>, <strong><code>asylum-madhouse</code></strong>, <strong><code>magician-wizard</code></strong>, <strong><code>midday-noon</code></strong>, <strong><code>furnace- stove</code></strong>, <strong><code>food-fruit</code></strong>, <strong><code>bird-cock</code></strong>, <strong><code>bird-crane</code></strong>, <strong><code>tool-implement</code></strong>, <strong><code>brother-monk</code></strong>, <strong><code>lad- brother</code></strong>, <strong><code>crane-implement</code></strong>, <strong><code>journey-car</code></strong>, <strong><code>monk-oracle</code></strong>, <strong><code>cemetery-woodland</code></strong>, <strong><code>food- rooster</code></strong>, <strong><code>coast-hill</code></strong>, <strong><code>forest-graveyard</code></strong>, <strong><code>shore-woodland</code></strong>, <strong><code>monk-slave</code></strong>, <strong><code>coast-forest</code></strong>, <strong><code>lad-wizard</code></strong>, <strong><code>chord-smile</code></strong>, <strong><code>glass-magician</code></strong>, <strong><code>rooster-voyage</code></strong>, <strong><code>noon-string</code></strong>.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> itemgetter</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> wordnet <span class="keyword">as</span> wn</span><br><span class="line"></span><br><span class="line">pairs = [(<span class="string">'car'</span>, <span class="string">'automobile'</span>), (<span class="string">'gem'</span>, <span class="string">'jewel'</span>), (<span class="string">'journey'</span>, <span class="string">'voyage'</span>), (<span class="string">'boy'</span>, <span class="string">'lad'</span>), (<span class="string">'coast'</span>, <span class="string">'shore'</span>), </span><br><span class="line">            (<span class="string">'asylum'</span>, <span class="string">'madhouse'</span>), (<span class="string">'magician'</span>, <span class="string">'wizard'</span>), (<span class="string">'midday'</span>, <span class="string">'noon'</span>), (<span class="string">'furnace'</span>, <span class="string">'stove'</span>), (<span class="string">'food'</span>, <span class="string">'fruit'</span>), </span><br><span class="line">            (<span class="string">'bird'</span>, <span class="string">'cock'</span>), (<span class="string">'bird'</span>, <span class="string">'crane'</span>), (<span class="string">'tool'</span>, <span class="string">'implement'</span>), (<span class="string">'brother'</span>, <span class="string">'monk'</span>), (<span class="string">'lad'</span>, <span class="string">'brother'</span>), </span><br><span class="line">            (<span class="string">'crane'</span>, <span class="string">'implement'</span>), (<span class="string">'journey'</span>, <span class="string">'car'</span>), (<span class="string">'monk'</span>, <span class="string">'oracle'</span>), (<span class="string">'cemetery'</span>, <span class="string">'woodland'</span>), (<span class="string">'food'</span>, <span class="string">'rooster'</span>), </span><br><span class="line">            (<span class="string">'coast'</span>, <span class="string">'hill'</span>), (<span class="string">'forest'</span>, <span class="string">'graveyard'</span>), (<span class="string">'shore'</span>, <span class="string">'woodland'</span>), (<span class="string">'monk'</span>, <span class="string">'slave'</span>), (<span class="string">'coast'</span>, <span class="string">'forest'</span>), </span><br><span class="line">            (<span class="string">'lad'</span>, <span class="string">'wizard'</span>), (<span class="string">'chord'</span>, <span class="string">'smile'</span>), (<span class="string">'glass'</span>, <span class="string">'magician'</span>), (<span class="string">'rooster'</span>, <span class="string">'voyage'</span>), (<span class="string">'noon'</span>, <span class="string">'string'</span>)]</span><br><span class="line">lch = []</span><br><span class="line">path = []</span><br><span class="line"><span class="keyword">for</span> word1, word2 <span class="keyword">in</span> pairs:</span><br><span class="line">    lch.append((word1, word2, wn.lch_similarity(wn.synsets(word1)[<span class="number">0</span>], wn.synsets(word2)[<span class="number">0</span>])))</span><br><span class="line">    path.append((word1, word2, wn.path_similarity(wn.synsets(word1)[<span class="number">0</span>], wn.synsets(word2)[<span class="number">0</span>])))</span><br><span class="line"></span><br><span class="line">print(sorted(lch, key=itemgetter(<span class="number">2</span>), reverse=<span class="keyword">True</span>))</span><br><span class="line">print(<span class="string">'----------\n'</span>)</span><br><span class="line">print(sorted(path, key=itemgetter(<span class="number">2</span>), reverse=<span class="keyword">True</span>))</span><br></pre></td></tr></table></figure>
      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
          
            <a href="/tags/Books/" rel="tag"># Books</a>
          
            <a href="/tags/Python/" rel="tag"># Python</a>
          
            <a href="/tags/Natural-Language-Processing/" rel="tag"># Natural Language Processing</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2015/09/17/♞「Books」NLP with Python - Chapter 3/" rel="prev" title="♞「Books」NLP with Python - Chapter 3">
                ♞「Books」NLP with Python - Chapter 3 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/images/avatar.png" alt="Randolph">
          <p class="site-author-name" itemprop="name">Randolph</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">32</span>
                <span class="site-state-item-name">Posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">13</span>
                <span class="site-state-item-name">Categories</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">15</span>
                <span class="site-state-item-name">Tags</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/RandolphVI" target="_blank" title="Github">
                  
                    <i class="fa fa-fw fa-github-alt"></i>
                  
                  Github
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.linkedin.com/in/威-黄-88060b74/" target="_blank" title="LinkedIn">
                  
                    <i class="fa fa-fw fa-linkedin"></i>
                  
                  LinkedIn
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://music.163.com/#/user/home?id=57901575" target="_blank" title="Music">
                  
                    <i class="fa fa-fw fa-music"></i>
                  
                  Music
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://steamcommunity.com/id/Chinawolfman/" target="_blank" title="Steam">
                  
                    <i class="fa fa-fw fa-steam"></i>
                  
                  Steam
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="https://www.tensorflow.org" title="TensorFlow" target="_blank">TensorFlow</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://www.kaggle.com" title="Kaggle" target="_blank">Kaggle</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://leetcode.com" title="LeetCode" target="_blank">LeetCode</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://weekly.codetengu.com" title="CodeTengu" target="_blank">CodeTengu</a>
                </li>
              
            </ul>
          </div>
        
        
        <div>
          <iframe id="iframer" frameborder="no" border="0" marginwidth="0" marginheight="0" width="320" height="150" src></iframe>
        </div>

        <script language="javascript" type="text/javascript">
          window.onload = function(){
            setTimeout(function () {
              var iframer = document.getElementById("iframer");
              iframer.setAttribute("src","//music.163.com/outchain/player?type=0&id=880407510&auto=0&height=90");
            }, 1000);
          }
        </script>
  
        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Related"><span class="nav-number">1.</span> <span class="nav-text">Related</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Key"><span class="nav-number">2.</span> <span class="nav-text">Key:</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#What’s-NLTK"><span class="nav-number">2.1.</span> <span class="nav-text">What’s NLTK?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Download-with-NLTK"><span class="nav-number">2.2.</span> <span class="nav-text">Download with NLTK</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#concordance-function"><span class="nav-number">2.3.</span> <span class="nav-text">concordance function</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Word-Sense-Disambiguation-amp-Pronoun-Resolution"><span class="nav-number">2.4.</span> <span class="nav-text">Word Sense Disambiguation &amp; Pronoun Resolution</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Text-Corpus-Structure"><span class="nav-number">2.5.</span> <span class="nav-text">Text Corpus Structure</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#WordNet"><span class="nav-number">2.6.</span> <span class="nav-text">WordNet</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Correct-errors-in-printing"><span class="nav-number">3.</span> <span class="nav-text">Correct errors in printing:</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Practice"><span class="nav-number">4.</span> <span class="nav-text">Practice:</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="motto">
  <span class="motto">「莫怕真理无穷 进一寸便有进一寸的欢喜」</span>
</div>

<div class="copyright">
  
  &copy;  2017 - 
  <span itemprop="copyrightYear">2019</span>
  
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  
  <span class="author" itemprop="copyrightHolder">Randolph</span>
  
</div>

<!--  -->
<!-- <div class="powered-by"> -->
<!--   Powered by <a class="theme-link" href="https://hexo.io">Hexo</a> -->
<!-- </div> -->
<!--  -->
<!-- <div class="theme-info"> -->
<!--   Theme - -->
<!--   <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next"> -->
<!--     NexT.Mist -->
<!--   </a> -->
<!-- </div> -->


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  

  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  

    
      <script id="dsq-count-scr" src="https://randolphvi.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://randolph.pro/2015/09/11/♞「Books」NLP with Python - Chapter 1 & 2/';
          this.page.identifier = '2015/09/11/♞「Books」NLP with Python - Chapter 1 & 2/';
          this.page.title = '♞「Books」NLP with Python - Chapter 1 & 2';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://randolphvi.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  








  




  
  
  
  <link rel="stylesheet" href="/lib/algolia-instant-search/instantsearch.min.css">

  
  
  <script src="/lib/algolia-instant-search/instantsearch.min.js"></script>
  

  <script src="/js/src/algolia-search.js?v=5.1.1"></script>



  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("rlX1ugcCzQRlB8ljks0eiIKp-gzGzoHsz", "kpFrsFctrAimlBvhHvlgWnhV");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



  

  

  
  


  

  

</body>
</html>
