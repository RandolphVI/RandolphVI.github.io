<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="baidu-site-verification" content="IYvqjZ3csg" />
<meta name="google-site-verification" content="o9GDuh4E6CmwFpEqUYW7VMmq_fysc1_3PpSQSNWSD8Y" />


  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-mac-osx.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Machine Learning,Python," />





  <link rel="alternate" href="/atom.xml" title="黃某人" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="本文是关于周志华「Machine Learning」这本书的 Chapter 2 的学习笔记。">
<meta name="keywords" content="Machine Learning,Python">
<meta property="og:type" content="article">
<meta property="og:title" content="♞「Machine Learning」 Chapter 2">
<meta property="og:url" content="http://randolph.pro/2016/12/30/♞「Machine Learning」 Chapter 2/index.html">
<meta property="og:site_name" content="黃某人">
<meta property="og:description" content="本文是关于周志华「Machine Learning」这本书的 Chapter 2 的学习笔记。">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://farm5.staticflickr.com/4307/36174772306_62cfbc8cd6_o.jpg">
<meta property="og:image" content="https://farm1.staticflickr.com/445/31598501856_151da1837a_o.png">
<meta property="og:image" content="https://farm6.staticflickr.com/5556/31263252700_81d0f5a7d0_o.png">
<meta property="og:image" content="https://farm1.staticflickr.com/531/31635512885_c29ced14ac_o.png">
<meta property="og:image" content="https://farm5.staticflickr.com/4386/36563815415_834d585fb3_o.png">
<meta property="og:image" content="https://farm6.staticflickr.com/5567/31598563736_1791303905_o.png">
<meta property="og:image" content="https://farm1.staticflickr.com/141/31490389422_1b83a2b146_o.png">
<meta property="og:image" content="https://farm1.staticflickr.com/256/31490416932_57f610e40d_o.png">
<meta property="og:image" content="https://farm6.staticflickr.com/5762/31637147675_4ebdb0d453_o.png">
<meta property="og:image" content="https://farm6.staticflickr.com/5585/30826966253_eff65097a8_o.png">
<meta property="og:image" content="https://farm1.staticflickr.com/595/30795620304_a815c4ccff_o.png">
<meta property="og:image" content="https://farm1.staticflickr.com/663/30795629194_9a7a48bc13_o.png">
<meta property="og:image" content="https://farm1.staticflickr.com/733/31637250505_65b565e6c6_o.png">
<meta property="og:updated_time" content="2017-08-15T08:17:01.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="♞「Machine Learning」 Chapter 2">
<meta name="twitter:description" content="本文是关于周志华「Machine Learning」这本书的 Chapter 2 的学习笔记。">
<meta name="twitter:image" content="https://farm5.staticflickr.com/4307/36174772306_62cfbc8cd6_o.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"right","display":"hide","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: 'KGO9YVRPZZ',
      apiKey: 'dcf60767769bda7791ae195caf3dfb10',
      indexName: 'Randolph',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://randolph.pro/2016/12/30/♞「Machine Learning」 Chapter 2/"/>





  <title>♞「Machine Learning」 Chapter 2 | 黃某人</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?80985281ddae6899cfd57ad9d458b284";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->










</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-right page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">黃某人</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">痴</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  
  <div class="algolia-popup popup search-popup">
    <div class="algolia-search">
      <div class="algolia-search-input-icon">
        <i class="fa fa-search"></i>
      </div>
      <div class="algolia-search-input" id="algolia-search-input"></div>
    </div>

    <div class="algolia-results">
      <div id="algolia-stats"></div>
      <div id="algolia-hits"></div>
      <div id="algolia-pagination" class="algolia-pagination"></div>
    </div>

    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>




    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://randolph.pro/2016/12/30/♞「Machine Learning」 Chapter 2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Randolph">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="黃某人">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">♞「Machine Learning」 Chapter 2</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-plus-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-12-30T00:00:00+08:00">
                2016-12-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/Book-「Machine-Learning」/" itemprop="url" rel="index">
                    <span itemprop="name">Book:「Machine Learning」</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2016/12/30/♞「Machine Learning」 Chapter 2/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2016/12/30/♞「Machine Learning」 Chapter 2/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2016/12/30/♞「Machine Learning」 Chapter 2/" class="leancloud_visitors" data-flag-title="♞「Machine Learning」 Chapter 2">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-fire"></i>
               </span>
               <span class="leancloud-visitors-count"></span>
               <span>℃</span>
               <span class="post-meta-divider">|</span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                <span title="Words count in article">
                  7,274
                </span>
                <span> words </span>
                
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                <span title="Reading time">
                  26
                </span>
                <span> mins </span>
              
            </div>
          

          
              <div class="post-description">
                  本文是关于周志华「Machine Learning」这本书的 Chapter 2 的学习笔记。
              </div>
          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><img src="https://farm5.staticflickr.com/4307/36174772306_62cfbc8cd6_o.jpg" alt=""></p>
<p>有关该书的其他学习笔记系列：<a href="http://randolph.pro/categories/Machine-Learning/Book-「Machine-Learning」/">Book:「Machine Learning」</a></p>
<h1 id="Related"><a href="#Related" class="headerlink" title="Related"></a>Related</h1><ul>
<li><strong>过拟合与欠拟合</strong></li>
<li><strong>评估方法</strong><ul>
<li><strong>留出法</strong></li>
<li><strong>交叉验证法</strong></li>
<li><strong>自助法</strong></li>
</ul>
</li>
<li><strong>性能度量</strong><ul>
<li><strong>错误率与精度</strong></li>
<li><strong>查准率、查全率与 F1</strong></li>
<li><strong>ROC 与 AUC</strong></li>
<li><strong>代价敏感错误率与代价曲线</strong></li>
<li><strong>比较检验</strong></li>
<li><strong>偏差与方差（Bias-Variance）</strong></li>
</ul>
</li>
</ul>
<hr>
<h1 id="Key"><a href="#Key" class="headerlink" title="Key:"></a>Key:</h1><h2 id="过拟合与欠拟合"><a href="# 过拟合与欠拟合" class="headerlink" title="过拟合与欠拟合"></a>过拟合与欠拟合 </h2><p> 当学习器把训练样本学得“太好”了的时候，很可能已经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，这样就会导致泛化性能下降。这种现象就是“过拟合”（Overfitting）。</p>
<p>与“过拟合”相对的是“欠拟合”（Underfitting），这是指对训练样本的一般性质尚未学好。</p>
<p>下图形象生动地说明了过拟合、欠拟合的直观类比：</p>
<p><img src="https://farm1.staticflickr.com/445/31598501856_151da1837a_o.png" alt=""></p>
<p>欠拟合比较容易克服，例如在决策树学习中扩展分支、在神经网络学习中增加训练轮数等，而过拟合则很麻烦。然而过拟合是机器学习面临的关键障碍，各类学习算法都必然带有一些针对过拟合的措施，过拟合是无法彻底避免的，我们所能做的只是“缓解”，或者说减小其风险。</p>
<p><strong>机器学习面临的问题通常是 NP 难甚至更难，而有效的学习算法必然是在多项式时间内运行完成，若可以彻底避免过拟合，则通过经验误差最小化就能获得最优解，这就意味着我们构造性地证明了「 P=NP 」；因此，只要我们是相信「 P≠NP 」，过拟合就不可避免。</strong></p>
<hr>
<h2 id="评估方法"><a href="# 评估方法" class="headerlink" title="评估方法"></a>评估方法 </h2><p> 假设我们现有一个包含 $m$ 个样例的数据集 $D = \left \lbrace (x_1,y_1),(x_2,y_2),…,(x_m,y_m) \right \rbrace$ ，我们需要对数据集 $D$ 进行适当的处理，从中划分出训练集 $S$ 以及测试集 $T$ 。那么有以下几种划分方法：</p>
<h3 id="留出法 -hold-out"><a href="# 留出法 -hold-out" class="headerlink" title="留出法 (hold-out)"></a> 留出法(hold-out)</h3><ul>
<li><p>需要注意的是，训练 / 测试集的划分要尽可能保持数据分布的一致性，避免因数据划分过程引入额外的偏差而对最终结果产生影响。</p>
</li>
<li><p>单次使用留出法得到的估计结果往往不够稳定可靠谱，在使用留出法时，一般要采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果。例如进行 100 次随机划分，每次产生一个训练 / 测试集用于实验评估， 100 次后就得到 100 个结果，而留出法返回的则是这 100 个结果的平均值。</p>
</li>
<li><p>此外，我们希望评估的是用 $D$ 训练出的模型的性能，但留出法需划分训练 / 测试集，这就会导致一个窘境：若令训练集 $S$ 包含绝大多数样本，则训练出的模型可能更接近于用 $D$ 训练出的模型，但由于 $T$ 比较小，评估结果可能不够稳定准确；若令测试集 $T$ 多包含一些样本，则训练集 $S$ 与 $D$ 差别更大了，被评估的模型与用 $D$ 训练出的模型相比可能有较大差别，从而降低了评估结果的保真性（fidelity)。<strong>这个问题没有完美的解决方案，常见做法是将大约 2/3 ~ 4/5 的样本用于训练，剩余样本用于测试。</strong> </p>
</li>
<li><p>可从“偏差一方差”的角度来理解：测试集小时，评估结果的方差较大；训练集小时，评估结果的偏差较大。 </p>
</li>
<li><p>一般而言，测试集至少应含 30 个样例 「 Mitchell, 1997 」 。</p>
</li>
</ul>
<h3 id="交叉验证法 -cross-validation"><a href="# 交叉验证法 -cross-validation" class="headerlink" title="交叉验证法 (cross validation)"></a> 交叉验证法 (cross validation)</h3><p> 其做法是将数据集 $D$ 划分为 $k$ 个大小相似的互斥子集，即：</p>
<script type="math/tex; mode=display">
D=D_1 \cup  D_2 \cup ... \cup D_k, D_i \cap  D_j = \varnothing (i \neq j)</script><p>每个子集 $D$ 都尽可能保持数据分布的一致性，即从 $D$ 中通过分层采样得到。然后，每次用 $k-1$ 个子集的并集作为训练集，余下的那个子集作为测试集；这样就可获得 $k$ 组训练 / 测试集，从而可进行 $k$ 次训练和测试，最终返回的是这 $k$ 个测试结果的均值。</p>
<ul>
<li><strong>显然，交叉验证法评估结果的稳定性和保真性在很大程度上取决于 $k$ 的取值，为强调这一点，通常把交叉验证法称为“ $k$ 折交叉验证”($k$-fold cross validation)。</strong>  $k$ 最常用的取值是 10 ，此时称为 10 折交叉验证；其他常用的 $k$ 值有 5 、 20 等。下图是经典的 10 折交叉验证的示意图：</li>
</ul>
<p><img src="https://farm6.staticflickr.com/5556/31263252700_81d0f5a7d0_o.png" alt=""></p>
<p>与留出法相似，将数据集 $D$ 划分为 $k$ 个子集同样存在多种划分方式。为减小因样本划分不同而引入的差别， $k$ 折交叉验证通常要随机使用不同的划分重复 $p$ 次，最终的评估结果是这 $p$ 次 $k$ 折交叉验证结果的均值，例如常见的有 “ 10 次 10 折交叉验证”。</p>
<p>“ 10 次 10 折交又验证法”与“ 100 次留出法”都是进行了 100 次训练 / 测试。</p>
<h3 id="留一法 -Leave-One-Out"><a href="# 留一法 -Leave-One-Out" class="headerlink" title="留一法 (Leave-One-Out)"></a> 留一法 (Leave-One-Out)</h3><p> 假定数据集 $D$ 中包含 $m$ 个样本，若令 $k=m$ 。则得到了交叉验证法的一个特例：留一法（Leave-One-Out，简称 LOO )。显然，留一法不受随机样本划分方式的影响，因为 $m$ 个样本只有唯一的方式划分为 $m$ 个子集，每个子集包含一个样本。</p>
<p>留一法使用的训练集与初始数据集相比只少了一个样本，这就使得在绝大多数情况下，留一法中被实际评估的模型与期望评估的用 $D$ 训练出的模型很相似。<strong>因此，留一法的评估结果往往被认为比较准确 </strong>（优点）。然而，留一法也有其缺陷：<strong> 在数据集比较大时，训练 $m$ 个模型的计算开销可能是难以忍受的（例如数据集包含一百万个样本，则需训练一百万个模型），而这还是在未考虑算法调参的情况下</strong>（缺点）。另外，留一法的估计结果也未必永远比其他评估方法准确；“没有免费的午餐”定理对实验评估方法同样适用。</p>
<h3 id="自主法 -Bootstrapping"><a href="# 自主法 -Bootstrapping" class="headerlink" title="自主法 (Bootstrapping)"></a> 自主法 (Bootstrapping)</h3><p> 我们希望评估的是用 $D$ 训练出的模型。但在留出法和交叉验证法中，由于保留了一部分样本用于测试，因此实际评估的模型所使用的训练集比 $D$ 小，这必然会引入一些因训练样本规模不同而导致的估计偏差。留一法受训练样本规模变化的影响较小，但计算复杂度又太高了。有没有什么办法可以减少训练样本规模不同造成的影响，同时还能比较高效地进行实验估计呢？ </p>
<p>“自助法”是一个比较好的解决方案，它直接以自助采样法为基础「Efron and Tibshirani,1993」。给定包含 $m$ 个样本的数据集 $D$ ，我们对它进行采样产生数据集 $D’$ ：每次随机从 $D$ 中挑选一个样本，将其拷贝放入 $D’$ ，然后再将该样本放回初始数据集 $D$ 中，使得该样本在下次采样时仍有可能被采到；这个过程重复执行 $m$ 次后，我们就得到了包含了 $m$ 个样本的数据集 $D’$ ，这就是自助采样的结果。显然， $D$ 中有一部分样本会在 $D’$ 中多次出现，而另一部分样本不出现。可以做一个简单的估计，样本在 $m$ 次采样中始终不被采到的概率是 $(1-1/m)^m$ ，取极限得到</p>
<script type="math/tex; mode=display">
\lim_{m\rightarrow \infty}\left (1-\frac{1}{m}\right )^{m} \mapsto \frac{1}{e} \approx 0.368</script><p>($e$ 是自然常数。)</p>
<p>即通过自助采样，初始数据集 $D$ 中约有 36.8％ 的样本未出现在采样数据集 $D’$ 中。于是我们可将 $D’$ 用作训练集， $D-D’$ 用作测试集；这样，实际评估的模型与期望评估的模型都使用 $m$ 个训练样本，而我们仍有数据总量约 1/3 的、没在训练集中出现的样本用于测试。这样的测试结果，亦称 <strong>“包外估计”(out-of-bag estimate)</strong>. <strong> 自助法在数据集较小、难以有效划分训练 / 测试集时很有用 </strong>（优点）；此外，自助法能从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处。 <strong> 然而，自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差</strong>（缺点）。因此，在初始数据量足够时，留出法和交叉验证法更加常用一些。</p>
<hr>
<h2 id="性能度量"><a href="# 性能度量" class="headerlink" title="性能度量"></a>性能度量</h2><ul>
<li><p>性能度量是任务需求的体现，在对比不同模型的能力时，使用不同的性能度量往往会导致不同的评判结果，所以这以为这模型的“好坏”是相对的，什么样的模型是好的，其实不仅仅取决于算法和数据，更是取决于任务需求。</p>
</li>
<li><p>在预测任务中，给定样例集 $D = \left \lbrace (x_1,y_1),(x_2,y_2),…,(x_m,y_m) \right \rbrace$ ，其中 $y_i$ 是示例 $x_i$ 的真实标记要评估。学习器 $f$ 的性能，就要把学习器预测结果 $f(x)$ 与真实标记 $y$ 进行比较。 </p>
</li>
<li><p>在回归任务中，即预测连续值的问题，最常用的性能度量是<strong>“均方误差”（mean squared error）</strong>，很多的经典算法都是采用了 <strong>MSE</strong> 作为评价函数，想必大家都十分熟悉。</p>
<script type="math/tex; mode=display">
E(f;D) = \frac{1}{m}\sum_{i=1}^{m}m (f(x_i) - y_i )^2</script></li>
<li><p>更一般的，对于数据分布 $D$ 和概率密度函数 $p(·)$ ，均方误差可描述为：</p>
</li>
</ul>
<script type="math/tex; mode=display">
E(f;D) = \int_{x\sim D}  (f(x) - y)^2p(x)dx</script><h3 id="错误率与精度"><a href="# 错误率与精度" class="headerlink" title="错误率与精度"></a>错误率与精度</h3><ul>
<li><p>在分类任务中，即预测离散值的问题，最常用的是 <strong> 错误率 </strong> 和<strong>精度</strong>，错误率是分类错误的样本数占样本总数的比例，精度则是分类正确的样本数占样本总数的比例，易知：错误率 + 精度 = 1 。</p>
</li>
<li><p>错误率定义为：</p>
</li>
</ul>
<script type="math/tex; mode=display">
E(f;D) = \frac{1}{m}\sum_{i=1}^{m}\mathbb{I}(f(x_i) \neq y_i)</script><ul>
<li>精度则定义为：</li>
</ul>
<script type="math/tex; mode=display">
acc(f;D) = \frac{1}{m}\sum_{i=1}^{m}\mathbb{I}(f(x_{i}) = y_{i})=1-E(f;D)</script><h3 id="查准率、查全率与 -F1"><a href="# 查准率、查全率与 -F1" class="headerlink" title="查准率、查全率与 F1"></a>查准率、查全率与 F1</h3><p>错误率和精度虽然常用，但不能满足所有的需求，例如：在推荐系统中，我们只关心推送给用户的内容用户是否感兴趣（即 <strong> 查准率 </strong>），或者说所有用户感兴趣的内容我们推送出来了多少（即<strong> 查全率</strong>）。因此，使用查准 / 查全率更适合描述这类问题。对于二分类问题，分类结果混淆矩阵与查准 / 查全率定义如下：</p>
<p><img src="https://farm1.staticflickr.com/531/31635512885_c29ced14ac_o.png" alt=""></p>
<p>补上一个表，方便理解：</p>
<p><img src="https://farm5.staticflickr.com/4386/36563815415_834d585fb3_o.png" alt=""></p>
<ul>
<li>查准率：</li>
</ul>
<script type="math/tex; mode=display">
P = \frac{TP}{TP+FP}</script><ul>
<li>查全率：</li>
</ul>
<script type="math/tex; mode=display">
R = \frac{TP}{TP+FN}</script><p>正如天下“没有免费的午餐”理论所揭示的那样，查准率和查全率是一对矛盾的度量。例如我们想让推送的内容尽可能用户全都感兴趣，那只能推送我们把握高的内容，这样就漏掉了一些用户感兴趣的内容，查全率就低了；如果想让用户感兴趣的内容都被推送，那只有将所有内容都推送上，宁可错杀一千，不可放过一个，这样查准率就很低了。</p>
<p>“ P-R 曲线”正是描述查准 / 查全率变化的曲线，P-R 曲线定义如下：根据学习器的预测结果（一般为一个实值或概率）对测试样本进行排序，将最可能是“正例”的样本排在前面，最不可能是“正例”的排在后面，按此顺序逐个把样本作为“正例”进行预测，每次计算出当前的 P 值和 R 值，如下图所示：</p>
<p><img src="https://farm6.staticflickr.com/5567/31598563736_1791303905_o.png" alt=""></p>
<p>P-R 曲线如何评估呢？若一个学习器 A 的 P-R 曲线被另一个学习器 B 的 P-R 曲线完全包住，则称： B 的性能优于 A 。若 A 和 B 的曲线发生了交叉，则谁的曲线下的面积大，谁的性能更优。但一般来说，曲线下的面积是很难进行估算的，所以衍生出了<strong>“平衡点”</strong>（Break-Event Point，简称 BEP ），即当 P=R 时的取值，平衡点的取值越高，性能更优。</p>
<p>$P$ 和 $R$ 指标有时会出现矛盾的情况，这样就需要综合考虑他们，最常见的方法就是 F-Measure ，又称 F-Score 。F-Measure 是 $P$ 和 $R$ 的加权调和平均，即：</p>
<script type="math/tex; mode=display">
\frac{1}{F_{\beta}}  = \frac{1}{2}\cdot (\frac{1}{P}+\frac{1}{R})</script><p>也可以写成：</p>
<script type="math/tex; mode=display">
F1  = \frac{2\times P \times R}{P+R}=\frac{2\times TP}{N + TP -TN}</script><p>(其中 N 为样例总数)</p>
<ul>
<li>在一些应用中，对查准率和查全率的重视程度有所不同。例如在商品推荐系统中，为了尽可能少打扰用户，更希望推荐内容确是用户感兴趣的，此时查准率更重要；而在逃犯信息检索系统中，更希望尽可能少漏掉逃犯，此时查全率更重要。$F1$ 度量的一般形式— $F_\beta $ ，能让我们表达出对查准率／查全率的不同偏好，它定义为：</li>
</ul>
<script type="math/tex; mode=display">
F_{\beta}  = \frac{(1+\beta^2) \times P \times R}{(\beta^2 \times P) + R}</script><p><strong>其中 $\beta &gt; 0$ 度量了查全率对查准率的相对重要性「Van Rijsbergen, 1979」。</strong></p>
<p><strong>$\beta = 1$ 时退化为标准的 $F1$ ； $\beta &gt; 1$ 时查全率有更大影响； $\beta &lt; 1$ 时查准率有更大影响。</strong></p>
<p>有时候我们会有多个二分类混淆矩阵，例如：多次训练或者在多个数据集上训练，那么估算全局性能的方法有两种，分为宏观和微观。</p>
<ul>
<li>简单理解，宏观就是先算出每个混淆矩阵的 $P$ 值和 $R$ 值，然后取得平均 $P$ 值 $macro-P$ 和平均 $R$ 值 $macro-R$ ，再算出 $F_\beta $ 或 $F1$ ：</li>
</ul>
<script type="math/tex; mode=display">
\begin{array}{l}
macro-P = \frac{1}{n}\sum_{i=1}^{n}P_{i} \cr 
macro-R = \frac{1}{n}\sum_{i=1}^{n}R_{i} \cr
macro-F1 = \frac{2\times macro-P \times macro-R}{macro-P + macro-R}
\end{array}</script><ul>
<li>而微观则是计算出混淆矩阵的平均 $TP$ 、 $FP$ 、 $TN$ 、 $FN$ ，接着进行计算 $P$ 、 $R$ ，进而求出 $F_\beta$ 或 $F1$ ：</li>
</ul>
<script type="math/tex; mode=display">
\begin{array}{l}
micro-P = \frac{\overline{TP}}{\overline{TP}+\overline{FP}} \cr
micro-R = \frac{\overline{TP}}{\overline{TP}+\overline{FN}} \cr
micro-F1 = \frac{2\times micro-P \times micro-R}{micro-P + micro-R}
\end{array}</script><h3 id="ROC- 与 -AUC"><a href="#ROC- 与 -AUC" class="headerlink" title="ROC 与 AUC"></a>ROC 与 AUC</h3><p>如上所述：学习器对测试样本的评估结果一般为一个实值或概率，设定一个阈值，大于阈值为正例，小于阈值为负例，因此这个实值的好坏直接决定了学习器的泛化性能，若将这些实值排序，则排序的好坏决定了学习器的性能高低。ROC 曲线正是从这个角度出发来研究学习器的泛化性能，ROC 曲线与 P-R 曲线十分类似，都是按照排序的顺序逐一按照正例预测，不同的是 ROC 曲线以“真正例率”（True Positive Rate，简称 TPR ）为横轴，纵轴为“假正例率”（False Positive Rate，简称 FPR ），<strong>ROC 偏重研究基于测试样本评估值的排序好坏</strong>。</p>
<ul>
<li>TPR（True Positive Rate，真正例率）：<script type="math/tex; mode=display">
TPR = \frac{TP}{TP+FN}</script></li>
<li><p>FPR（False Positive Rate，假正例率）：</p>
<script type="math/tex; mode=display">
FPR = \frac{FP}{TN+FP}</script><p><img src="https://farm1.staticflickr.com/141/31490389422_1b83a2b146_o.png" alt=""></p>
</li>
<li><p>简单分析图像，可以得知：当 $FN=0$ 时，$TN$ 也必须为 $0$ ，反之也成立，我们可以画一个队列，试着使用不同的截断点（即阈值）去分割队列，来分析曲线的形状，$(0,0)$ 表示将所有的样本预测为负例，$(1,1)$ 则表示将所有的样本预测为正例，$(0,1)$ 表示正例全部出现在负例之前的理想情况，$(1,0)$ 则表示负例全部出现在正例之前的最差情况。</p>
</li>
</ul>
<p>现实中的任务通常都是有限个测试样本，因此只能绘制出近似 ROC 曲线。</p>
<p>绘制方法：首先根据测试样本的评估值对测试样本排序，接着按照以下规则进行绘制：</p>
<p>绘制出如图 (b) 所示的近似 ROC 曲线，给定 $m^+$ 个正例和 $m^-$ 个反例，根据学习器预测结果对样例进行排序，然后把分类阈值设为最大，即把所有样例均预测为反例，此时真正例率和假正例率均为 $0$，在坐标 $(0,0)$ 处 标记一个点然后，将分类阈值依次设为每个样例的预测值，即依次将每个样例划分为正例。设前一个标记点坐标为 $(x,y)$ ，当前若为真正例，则对应标记点的坐标为 $(x,y + \frac{1}{m^+})$ ：当前若为假正例，则对应标记点的坐标为 $(x + \frac{1}{m^-},y)$ ，然后用线段连接相邻点即得。</p>
<p>同样地，进行模型的性能比较时，若一个学习器 A 的 ROC 曲线被另一个学习器 B 的 ROC 曲线完全包住，则称 B 的性能优于 A 。若 A 和 B 的曲线发生了交叉，则谁的曲线下的面积大，谁的性能更优。ROC 曲线下的面积定义为<strong>AUC（Area Uder ROC Curve）</strong>，不同于 P-R 曲线下的面积，这里的 AUC 是可估算的，即 AOC 曲线下每一个小矩形的面积之和。易知：AUC 越大，证明排序的质量越好，AUC 为 1 时，证明所有正例排在了负例的前面，AUC 为 0 时，所有的负例排在了正例的前面。</p>
<script type="math/tex; mode=display">
AUC = \frac{1}{2}\sum_{i=1}^{m-1}(x_{i+1}-x_{i})\cdot (y_{i}+y_{i+1})</script><h3 id="代价敏感错误率与代价曲线"><a href="# 代价敏感错误率与代价曲线" class="headerlink" title="代价敏感错误率与代价曲线"></a>代价敏感错误率与代价曲线 </h3><p> 上面的方法中，将学习器的犯错同等对待，但在现实生活中，将正例预测成假例与将假例预测成正例的代价常常是不一样的，例如：将无疾病–&gt; 有疾病只是增多了检查，但有疾病–&gt; 无疾病却是增加了生命危险，二者的“代价”明显是不同的。以二分类为例，由此引入了<strong>“代价矩阵”（cost matrix）</strong>。</p>
<p><img src="https://farm1.staticflickr.com/256/31490416932_57f610e40d_o.png" alt=""></p>
<p>在非均等错误代价下，我们希望的是最小化“总体代价”，这样“代价敏感”的错误率为：</p>
<script type="math/tex; mode=display">
E(f;D;cost) = \frac{1}{m}(\sum_{x_{i}\in D^{+}}\mathbb(f(x_{i})\neq y_{i})\times cost_{01}+\sum_{x_{i}\in D^{-}}\mathbb(f(x_{i})\neq y_{i})\times cost_{10})</script><p>同样对于 ROC 曲线，在非均等错误代价下，演变成了<strong>“代价曲线”</strong>，代价曲线横轴是取值在 $[0,1]$ 之间的正例概率代价，式中 $p$ 表示正例的概率，纵轴是取值为 $[0,1]$ 的归一化代价。</p>
<script type="math/tex; mode=display">
P(+)cost = \frac{p \times cost_{01}}{p \times cost_{01}+ (1-p)\times cost_{10}}</script><script type="math/tex; mode=display">
cost_{norm} = \frac{FNR \times p \times cost_{01} + FPR \times (1-p) \times cost_{10}}{p \times cost_{01}+ (1-p)\times cost_{10}}</script><p>代价曲线的绘制很简单：设 ROC 曲线上一点的坐标为 $(TPR，FPR)$ ，则可相应计算出 $FNR$ ，然后在代价平面上绘制一条从 $(0，FPR)$ 到 $(1，FNR)$ 的线段，线段下的面积即表示了该条件下的期望总体代价；如此将 ROC 曲线土的每个点转化为代价平面上的一条线段，然后取所有线段的下界，围成的面积即为在所有条件下学习器的期望总体代价，如图所示：</p>
<p><img src="https://farm6.staticflickr.com/5762/31637147675_4ebdb0d453_o.png" alt=""></p>
<h3 id="代价敏感错误率与代价曲线 -1"><a href="# 代价敏感错误率与代价曲线 -1" class="headerlink" title="代价敏感错误率与代价曲线"></a>代价敏感错误率与代价曲线 </h3><h3 id="偏差与方差"><a href="# 偏差与方差" class="headerlink" title="偏差与方差"></a> 偏差与方差 </h3><p> 理解 Bias 与 Variance 之间的权衡，有监督学习中，预测误差的来源主要有两部分，分别为 <strong>Bias</strong> 与 <strong>Variance</strong>，模型的性能取决于 bias 与 variance 的 tradeoff，理解 bias 与 variance 有助于我们诊断模型的错误，避免 over-fitting 或者 under-fitting。</p>
<p>我们知道，同样的算法在不同的数据集上得到的模型结果很可能不同，尽管数据集来自于同一个分部。对于观测数据 $X$ 以及待预测的变量 $Y$ ，假设两者服从 $Y = f(X) + \varepsilon$ ， $\varepsilon$ 为噪声，其服从的 $N(0,\delta  _{\varepsilon}^2)$ ，预测任务中需要得到 $Y$ 值，首先在数据集上 $D$ 上通过算法学习一个近似 $f(X)$ 的模型 $\hat{f}(X)$ 来预测得到 $X$ 的输出。给定 $X$ 一个观测值 $x$ ，待预测变量 $y = f(x) + \varepsilon$ 。</p>
<ul>
<li>对于样本数量相同的不同训练集模型 $\hat{f}(X)$ 的期望输出为： $E[\hat{f}(X) ]$ 。</li>
<li>对于样本数量相同的不同训练集模型产生的方差为： $E[\hat{f}(X)-E[\hat{f}(X)]]^2$ 。</li>
</ul>
<p>将模型的误差分解，采用均方损失，模型 $\hat{f}(X)$ 在点 $x$ 的整体预测误差为真实值与模型预测值之间的误差：</p>
<script type="math/tex; mode=display">
E_{rr} (x)= E[(y-\hat{f}(x))^{2}]</script><p>这个式子其实等价于：</p>
<script type="math/tex; mode=display">
E_{rr} (x)= [E\hat{f}(x)-f(x)]^{2} + E([\hat{f}(x)-E\hat{f}(x)]^2)+\delta _{\varepsilon}^2</script><hr>
<p>这里为推导过程，先回忆几个公式：<br>$Var[X] = E[X^2] - E^2[X]$，且由于函数 $f(x)$ 是确定的，所以 $E[f(x)] = f(x)$，且有 $ \varepsilon \sim N(0,\delta_{\varepsilon}^2)$，再结合 $y = f(x) + \varepsilon$ 可以得到：</p>
<script type="math/tex; mode=display">
E(y) =  E[f(x) +  \varepsilon] = E[f(x)] + 0 = E[f(x)] \tag{1.1}</script><script type="math/tex; mode=display">
Var(y) = E[(y - E(y)^2] = E[(f(x) + \varepsilon - E[f(x)])^2] =  E[\varepsilon ^ 2] = \delta_{\varepsilon}^2 \tag{1.2}</script><hr>
<script type="math/tex; mode=display">
\begin{align}
E_{rr} (x) & = E[(y-\hat{f}(x))^{2}] = E[y^2-2y\hat{f}(x)+(\hat{f}(x))^2] \cr
& = E(y^2) {\color{Orchid}{- E^2(y) + E^2(y)}} -2E(y)E(\hat{f}(x)) + E(\hat{f^2}(x)) {\color{Orchid}{- E^2(\hat{f}(x)) + E^2(\hat{f}(x))}} \cr
& =  {\color{Red}{E^2(\hat{f}(x)) -2E(y)E(\hat{f}(x)) + E^2(y)}} + {\color{Green}{E(\hat{f^2}(x))-  E^2(\hat{f}(x))}} + {\color{Blue} {E(y^2)-  E^2(y) }}
\end{align}</script><p>结合上面两条式子：</p>
<script type="math/tex; mode=display">
\begin{align}
E_{rr}(x) & =  {\color{Red}{E^2(\hat{f}(x)) -2E(f(x))E(\hat{f}(x)) + E^2(f(x))}} + {\color{Blue}{E(\hat{f^2}(x))-  E^2(\hat{f}(x))}} + {\color{Green}{E(y^2)-  E^2(y) }} \cr
& =  {\color{Red}{[E(\hat{f}(x))-E(f(x))]^2}} + {\color{Blue}{E[(\hat{f}(x) - E\hat{f}(x))^2]}} + {\color{Green}{Var(y) }} \cr
& =  {\color{Red}{Bias^2[\hat{f}(x)]}} + {\color{Blue}{Var[\hat{f}(x)]}} + {\color{Green}{\delta _{\varepsilon}^{2}}}
\end{align}</script><hr>
<p>其中，$E(\hat{f}(X)) - E(f(x))$ 即为 Bias（偏差），$E[\hat{f}(X) - E\hat{f}(X)]^2$ 为 Variance（方差），$\delta_{\varepsilon}^2$ 即为模型无法避免的 Noise，所以现在对于一个预测模型的误差可以分为如下几部分：</p>
<script type="math/tex; mode=display">
Error = Bias^2 + Variance + Noises</script><p>对于预测模型问题，如果我们能够获得所有可能的数据集合，并在这个数据集合上将 $Error$ 最小化，这样学习到的模型就可以称之为“真实模型”，当然，我们是无论如何都不能获得并训练所有可能的数据的，所以“真实模型”肯定存在，但无法获得，我们的最终目标就是去学习一个模型使其更加接近这个真实模型。为了在有限的训练数据集上达到这个目标，就要使 $Error$ 最小了，$Error$ 分为 $Bias$ 、 $Variance$ 与 $Noise$ ：</p>
<p><strong>Bias</strong>：度量了学习算法的期望输出与真实结果的偏离程度, 刻画了算法的拟合能力，Bias 偏高表示预测函数与真实结果差异很大。</p>
<p><strong>Variance</strong>：则代表“同样大小的不同的训练数据集训练出的模型”与“这些模型的期望输出值”之间的差异。训练集变化导致性能变化， Variance 偏高表示模型很不稳定。</p>
<p><strong>Noise</strong>：刻画了当前任务任何算法所能达到的期望泛化误差的下界，即刻画了问题本身的难度。</p>
<p>由于 Noise 是无法避免的 所以要得到好的模型，就需要低 Bias 与低 Variance 下图给出一个 Bias 与 Variance 的示意图，明显可以看到低 Bias 与低 Variance 次次会命中靶心，而低 Bias 高 Variance 取均值后才会大多命中靶心，其他情况全打歪了。</p>
<p><img src="https://farm6.staticflickr.com/5585/30826966253_eff65097a8_o.png" alt=""></p>
<p>低 Bias 与低 Variance 才会得到低 Error，但低 Bias 与低 Variance 往往是不能兼得的。如果要降低模型的 Bias，就一定程度上会提高模型的 Variance，反之亦然。这里以 K-NN 为例，看一些 K-NN 中 Bias 与 Variance 与其参数 K 的关系，在 K-NN 中，误差形式如下：</p>
<script type="math/tex; mode=display">
Err(x) = [f(x)-\frac{1}{k}\sum_{i=1}^{k}f(x_{i})]^2 + \frac{\delta ^2}{k}+\delta ^2</script><p>这里 $x_{1}，x_{2}，…，x_{k}$ 是 $x$ 在训练数据集中最近的 $k$ 个邻居，当 $k$ 取值很小的时候，Bias 很低，但是 Variance 会比较高。但随着 $k$ 的增大，Bias 变高，Variance 降低，这种现象被称为 <strong> 偏差 - 方差窘境（bias-variance dilemma）</strong>。</p>
<p><strong>因为预测模型试图用有限的训练样本上去得到一个用来预测全数据集的模型，为了降低模型的误差率，就要尽量使模型在训练数据集上更加“准确”，这样做往往会增加 Model Complexity ，但却忽略模型在全数据集的泛化能力，模型在训练数据集的 Bias 减少了，但是对于训练数据集中没有出现的数据，模型对其预测就会很不稳定，这样就会造成高 Variance ，这也就是常说的 over-fitting ，为了避免 over-fitting，就不能完全依赖于有限的训练数据，这时可以加入一些先验信息，先验信息在模型求解的过程中会增加一些限制，提高模型的稳定程度，同时减少 Model Complexity，进而可以降低 Variance，但是由于“不信任”训练数据，会使模型的 Bias 增大, 或者训练不足时，模型拟合能力不够，训练数据的扰动不足以使模型拟合其真实情况，这时候 Bias 太大，模型对训练数据的预测能力就会下降，这便是 under-fitting 了，所以需要要 Bias 与 Variance 之间 寻找一个 tradeoff。</strong></p>
<p>因为 Noise 是不可避免的，这里忽略 Noise ，根据 Bias 、Variance 与 Model  Complexity 之间的关系，可以得到下图左所示的图形，该图表示在训练数据上几个量之间的关系，为了找到最优的模型，</p>
<p>在训练集中 Bias 下降与 Variance 上升的过程中来找到所谓的  tradeoff ，这时的 Model Complexity 是适中的，找到了这个 tradeoff ，在全数据集或者预测集上的预测集上的表现如下图右所示，所以 Bias 与 Variance 需要适中，才会得到在训练集与测试集误差都小的模型。</p>
<p><img src="https://farm1.staticflickr.com/595/30795620304_a815c4ccff_o.png" alt=""></p>
<p>最后谈一下 K-fold Cross Validation 与权衡 Bais-Variance 之间的关系。这个理解其实很简单，先看对于数据的划分:</p>
<p><img src="https://farm1.staticflickr.com/663/30795629194_9a7a48bc13_o.png" alt=""></p>
<p>每次留出一个 fold 用来做“验证集”来计算误差，当 K 设置很大时，每个 fold 都会有很少的数据，小数据集更容易有噪音，所以小的数据集会有大的 Bias ，同时 K 个 fold 代表 K 组数据分别训练一个模型，求平均后 Variance 会很小；相反如果 K 比较小的话，每个 fold 数据相对来说还是很多的，所以 Bias 相对较小，但是由于总模型数较小，所以 Variance 还是比较大的。</p>
<hr>
<h1 id="Correct-errors-in-printing"><a href="#Correct-errors-in-printing" class="headerlink" title="Correct errors in printing:"></a>Correct errors in printing:</h1><ul>
<li>暂无</li>
</ul>
<hr>
<h1 id="Practice"><a href="#Practice" class="headerlink" title="Practice:"></a>Practice:</h1><blockquote>
<p>2. 数据集包含 100 个样本，其中正、反例各一半，假定学习算法所产生的模型是将新样本预测为训练样本数较多的类别（训练样本数相同时进行随机猜测），试给出用 10 折交叉验证法和留一法分别对错误率进行评估所得的结果。</p>
</blockquote>
<ul>
<li><p>10 折交叉检验：由于每次训练样本中正反例数目一样，所以将结果判断为正反例的概率也是一样的，所以错误率的期望是 50% 。 </p>
</li>
<li><p>留一法：测试集为一个样本，训练集九十九个样本且有五十个与测试集真实类别不同，故测试集无法被划分到正确的类，所以错误率是 100% 。</p>
</li>
</ul>
<hr>
<blockquote>
<p>4. 试述真正例率（TPR）、假正例率（FPR）与查准率（P）、查全率（R）之间的联系。</p>
</blockquote>
<ul>
<li>查全率（R）： 真实正例被预测为正例的比例。 </li>
<li>真正例率（TPR）： 真实正例被预测为正例的比例。 </li>
</ul>
<p>（显然查全率与真正例率是相等的，即 $R=TPR$） </p>
<ul>
<li>查准率（P）：预测为正例的实例中真实正例的比例。</li>
<li>假正例率（FPR）： 真实反例被预测为正例的比例。</li>
</ul>
<p>（两者并没有直接的数值关系）</p>
<hr>
<blockquote>
<p>5. 试证明 $AUC = 1 − l_{rank}$ 。</p>
</blockquote>
<p>与 BEP 一样，学习器先将所有测试样本按预测概率排序，越可能是正的排在越前面。然后依次遍历，每扫描到一个位置，里面如果只有正例，则 ROC 曲线垂直向上，如果只有反例，曲线水平往右，如果既有正例也有反例，则斜向上。如图所示：</p>
<p><img src="https://farm1.staticflickr.com/733/31637250505_65b565e6c6_o.png" alt=""></p>
<p>由于 TPR 与 FPR 的分母是常数，所以这里按比例扩大了坐标（分别是真实正例和真实反例的数目倍），可以更好看出曲线走势。</p>
<p>可以看出一共有 20 个测试样本，10 个正，10 个反。学习器排序的结果是：</p>
<ul>
<li>, − , (+,+) , (+,−) , (+,−) , (+,+) , (−,−) , (+,+) , (−,−,−) , + , −。其中括号内的样本排在相同的位置。<br>&lt; (+,+,−,−) 与 (+,−) , (+,−) 是同样的效果 &gt;</li>
</ul>
<p>公式 <2.21> 累加了所有不在正例的反例数目，其中同样的位置标记为 0.5 ，在正例前面标记为 1 。从图中可以看出，折线每次向右 (右上) 延伸，表示扫描到了反例，折线上方对应的面积，就是该反例后面有多少个正例，每个正例是一个正方形，对应的面积是 1 。同位置上的正例是个三角形，对应的面积是 0.5 。计算出总面积后，由于 ROC 图的坐标是归一化的，所以总面积要除以一开始放大的倍数，也就是 <script type="math/tex">m_{+}  m_{-}</script> 。</2.21></p>
<hr>
<blockquote>
<p>6. 试述错误率与 ROC 曲线之间的关系。</p>
</blockquote>
<p>ROC 曲线每个点对应了一个 TPR 与 FPR ，此时对应了一个错误率。 </p>
<script type="math/tex; mode=display">
E_{cost} = \frac{m^+ \times (1-TPR) \times cost_{01}+m^- \times FPR \times cost_{10}}{m^+ + m^-}</script><p>学习器会选择错误率最小的位置作为截断点。</p>
<hr>
<blockquote>
<p>7. 试证明任意一条 ROC 曲线都有一条代价曲线与之对应，反之亦然。</p>
</blockquote>
<p>由定义可以知道 TPR 与 FPR 都是由 0 上升到 1 ，那么 FNR 则是由 1 下降到 0 。 </p>
<p>每条 ROC 曲线都会对应一条代价曲线，由于第一条代价线段的是 $(0,0)$ , $(1,1)$ ，最后是 $(0,1)$ , $(1,0)$ , 所有代价线段总会有一块公共区域，这个区域就是期望总体代价，而这块区域的边界就是代价曲线，且肯定从 $(0,0)$ 到 $(1,0)$ 。 </p>
<p>在有限个样本情况下，ROC 是一条折线，此时根据代价曲线无法还原 ROC 曲线。但若是理论上有无限个样本，ROC 是一条连续的折线，代价曲线也是连续的折线，每个点的切线可以求出 TPR 与 FNR，从而得到唯一的 ROC 曲线。</p>
<hr>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
          
            <a href="/tags/Python/" rel="tag"># Python</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/12/26/♞「Machine Learning」 Chapter 1/" rel="next" title="♞「Machine Learning」 Chapter 1">
                <i class="fa fa-chevron-left"></i> ♞「Machine Learning」 Chapter 1
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/01/03/♞「Machine Learning」 Clustering/" rel="prev" title="♞「Machine Learning」 Clustering">
                ♞「Machine Learning」 Clustering <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="Randolph" />
          <p class="site-author-name" itemprop="name">Randolph</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">20</span>
                <span class="site-state-item-name">Posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">11</span>
                <span class="site-state-item-name">Categories</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">9</span>
                <span class="site-state-item-name">Tags</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/RandolphVI" target="_blank" title="Github">
                  
                    <i class="fa fa-fw fa-github-alt"></i>
                  
                  Github
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.linkedin.com/in/威-黄-88060b74/" target="_blank" title="LinkedIn">
                  
                    <i class="fa fa-fw fa-linkedin"></i>
                  
                  LinkedIn
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://music.163.com/#/user/home?id=57901575" target="_blank" title="Music">
                  
                    <i class="fa fa-fw fa-music"></i>
                  
                  Music
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://steamcommunity.com/id/Chinawolfman/" target="_blank" title="Steam">
                  
                    <i class="fa fa-fw fa-steam"></i>
                  
                  Steam
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="https://www.tensorflow.org" title="TensorFlow" target="_blank">TensorFlow</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://www.kaggle.com" title="Kaggle" target="_blank">Kaggle</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://leetcode.com" title="LeetCode" target="_blank">LeetCode</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://weekly.codetengu.com" title="CodeTengu" target="_blank">CodeTengu</a>
                </li>
              
            </ul>
          </div>
        
        
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=320 height=150 src="//music.163.com/outchain/player?type=0&id=752986314&auto=1&height=90"></iframe>

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Related"><span class="nav-number">1.</span> <span class="nav-text">Related</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Key"><span class="nav-number">2.</span> <span class="nav-text">Key:</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#过拟合与欠拟合"><span class="nav-number">2.1.</span> <span class="nav-text">过拟合与欠拟合 </span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#评估方法"><span class="nav-number">2.2.</span> <span class="nav-text">评估方法 </span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#留出法 -hold-out"><span class="nav-number">2.2.1.</span> <span class="nav-text"> 留出法(hold-out)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#交叉验证法 -cross-validation"><span class="nav-number">2.2.2.</span> <span class="nav-text"> 交叉验证法 (cross validation)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#留一法 -Leave-One-Out"><span class="nav-number">2.2.3.</span> <span class="nav-text"> 留一法 (Leave-One-Out)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#自主法 -Bootstrapping"><span class="nav-number">2.2.4.</span> <span class="nav-text"> 自主法 (Bootstrapping)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#性能度量"><span class="nav-number">2.3.</span> <span class="nav-text">性能度量</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#错误率与精度"><span class="nav-number">2.3.1.</span> <span class="nav-text">错误率与精度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#查准率、查全率与 -F1"><span class="nav-number">2.3.2.</span> <span class="nav-text">查准率、查全率与 F1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ROC- 与 -AUC"><span class="nav-number">2.3.3.</span> <span class="nav-text">ROC 与 AUC</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#代价敏感错误率与代价曲线"><span class="nav-number">2.3.4.</span> <span class="nav-text">代价敏感错误率与代价曲线 </span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#代价敏感错误率与代价曲线 -1"><span class="nav-number">2.3.5.</span> <span class="nav-text">代价敏感错误率与代价曲线 </span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#偏差与方差"><span class="nav-number">2.3.6.</span> <span class="nav-text"> 偏差与方差 </span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Correct-errors-in-printing"><span class="nav-number">3.</span> <span class="nav-text">Correct errors in printing:</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Practice"><span class="nav-number">4.</span> <span class="nav-text">Practice:</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="motto" >
  <span class="motto">「莫怕真理无穷 进一寸便有进一寸的欢喜」</span>
</div>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  
  <span class="author" itemprop="copyrightHolder">Randolph</span>
  
</div>

<!--  -->
<!-- <div class="powered-by"> -->
<!--   Powered by <a class="theme-link" href="https://hexo.io">Hexo</a> -->
<!-- </div> -->
<!--  -->
<!-- <div class="theme-info"> -->
<!--   Theme - -->
<!--   <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next"> -->
<!--     NexT.Mist -->
<!--   </a> -->
<!-- </div> -->


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 鸿儒之顾
      <span class="stop">:</span>
      <span class="busuanzi-value" id="busuanzi_value_site_uv" style="display: inline;"></span>
      
    </span>
    
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 管中窥豹
      <span class="stop">:</span>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  

    
      <script id="dsq-count-scr" src="https://randolphvi.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://randolph.pro/2016/12/30/♞「Machine Learning」 Chapter 2/';
          this.page.identifier = '2016/12/30/♞「Machine Learning」 Chapter 2/';
          this.page.title = '♞「Machine Learning」 Chapter 2';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://randolphvi.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  








  




  
  
  
  <link rel="stylesheet" href="/lib/algolia-instant-search/instantsearch.min.css">

  
  
  <script src="/lib/algolia-instant-search/instantsearch.min.js"></script>
  

  <script src="/js/src/algolia-search.js?v=5.1.1"></script>



  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("rlX1ugcCzQRlB8ljks0eiIKp-gzGzoHsz", "kpFrsFctrAimlBvhHvlgWnhV");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



  

  

  
  


  

  

</body>
</html>
