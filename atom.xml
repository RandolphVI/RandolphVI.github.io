<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>黃某人</title>
  <subtitle>痴</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://randolph.pro/"/>
  <updated>2017-07-25T11:06:47.000Z</updated>
  <id>http://randolph.pro/</id>
  
  <author>
    <name>Randolph</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>「TensorFlow」 Use WeChat to Monitor Your Network</title>
    <link href="http://randolph.pro/2017/03/13/%3CTensorflow%3E%20Use%20WeChat%20to%20Monitor%20Your%20Network/"/>
    <id>http://randolph.pro/2017/03/13/&lt;Tensorflow&gt; Use WeChat to Monitor Your Network/</id>
    <published>2017-03-12T16:00:00.000Z</published>
    <updated>2017-07-25T11:06:47.000Z</updated>
    
    <content type="html"><![CDATA[<p> 大概的效果是：</p>
<p><img src="https://farm4.staticflickr.com/3767/32574547714_59711d3f0b_o.jpg" alt=""></p>
<p> 程序用到的主角是 Python 中的微信个人号接口 <strong>itchat</strong>。<a href="https://itchat.readthedocs.io/zh/latest/" target="_blank" rel="external">What’s itchat?</a> （itchat 的介绍及安装过程）</p>
<p> 这次，我们要监控的模型是先前提到过的 <a href="http://www.jianshu.com/p/b5caf4d5ce3e" target="_blank" rel="external"> 基于 MNIST 手写体数据集的「CNN」模型 </a>。</p>
<p> 注意：</p>
<ol>
<li> 文章要求读者事先下载安装好 itchat。</li>
<li> 文章不会详细介绍 TensorFlow 以及 Tensorboard 的知识。</li>
</ol>
<h2 id="Environment"><a href="#Environment" class="headerlink" title="Environment"></a>Environment</h2><p><strong>OS: macOS Sierra 10.12.x</strong></p>
<p><strong>Python Version: 3.4.x</strong></p>
<p><strong>TensorFlow: 1.0</strong></p>
<p><strong>itchat: 1.2.3</strong></p>
<h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><ul>
<li>Use WeChat to Monitor Your Network（tensorboard 绘图）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 基于 MNIST 数据集 的 「CNN」（tensorboard 绘图）</span></div><div class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> scipy</div><div class="line"></div><div class="line"><span class="comment"># Import itchat &amp; threading</span></div><div class="line"><span class="keyword">import</span> itchat</div><div class="line"><span class="keyword">import</span> threading</div><div class="line"></div><div class="line"><span class="comment"># Create a running status flag</span></div><div class="line">lock = threading.Lock()</div><div class="line">running = <span class="keyword">False</span></div><div class="line"></div><div class="line"><span class="comment"># Parameters</span></div><div class="line">learning_rate = <span class="number">0.001</span></div><div class="line">training_iters = <span class="number">200000</span></div><div class="line">batch_size = <span class="number">128</span></div><div class="line">display_step = <span class="number">10</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span></div><div class="line">	initial = tf.truncated_normal(shape, stddev = <span class="number">0.1</span>)</div><div class="line">	<span class="keyword">return</span> tf.Variable(initial)</div><div class="line">	</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape)</span>:</span></div><div class="line">	initial = tf.constant(<span class="number">0.1</span>, shape = shape)</div><div class="line">	<span class="keyword">return</span> tf.Variable(initial)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, W, strides=<span class="number">1</span>)</span>:</span></div><div class="line">	<span class="keyword">return</span> tf.nn.conv2d(x, W, strides=[<span class="number">1</span>, strides, strides, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span><span class="params">(x, k=<span class="number">2</span>)</span>:</span></div><div class="line">	<span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>, k, k, <span class="number">1</span>], strides=[<span class="number">1</span>, k, k, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</div><div class="line">	</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">variable_summaries</span><span class="params">(var)</span>:</span></div><div class="line">	<span class="string">"""Attach a lot of summaries to a Tensor (for TensorBoard visualization)."""</span></div><div class="line">	<span class="keyword">with</span> tf.name_scope(<span class="string">'summaries'</span>):</div><div class="line">		mean = tf.reduce_mean(var)</div><div class="line">		tf.summary.scalar(<span class="string">'mean'</span>, mean)</div><div class="line">		<span class="keyword">with</span> tf.name_scope(<span class="string">'stddev'</span>):</div><div class="line">			stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))</div><div class="line">		tf.summary.scalar(<span class="string">'stddev'</span>, stddev)</div><div class="line">		tf.summary.scalar(<span class="string">'max'</span>, tf.reduce_max(var))</div><div class="line">		tf.summary.scalar(<span class="string">'min'</span>, tf.reduce_min(var))</div><div class="line">		tf.summary.histogram(<span class="string">'histogram'</span>, var)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(input_tensor, weights_shape, biases_shape, layer_name, act = tf.nn.relu, flag = <span class="number">1</span>)</span>:</span></div><div class="line">	<span class="string">"""Reusable code for making a simple neural net layer.</span></div><div class="line"></div><div class="line">	It does a matrix multiply, bias add, and then uses relu to nonlinearize.</div><div class="line">	It also sets up name scoping so that the resultant graph is easy to read,</div><div class="line">	and adds a number of summary ops.</div><div class="line">"""</div><div class="line">	<span class="keyword">with</span> tf.name_scope(layer_name):</div><div class="line">		<span class="keyword">with</span> tf.name_scope(<span class="string">'weights'</span>):</div><div class="line">			weights = weight_variable(weights_shape)</div><div class="line">			variable_summaries(weights)</div><div class="line">		<span class="keyword">with</span> tf.name_scope(<span class="string">'biases'</span>):</div><div class="line">			biases = bias_variable(biases_shape)</div><div class="line">			variable_summaries(biases)</div><div class="line">		<span class="keyword">with</span> tf.name_scope(<span class="string">'Wx_plus_b'</span>):</div><div class="line">			<span class="keyword">if</span> flag == <span class="number">1</span>:</div><div class="line">				preactivate = tf.add(conv2d(input_tensor, weights), biases)</div><div class="line">			<span class="keyword">else</span>:</div><div class="line">				preactivate = tf.add(tf.matmul(input_tensor, weights), biases)</div><div class="line">			tf.summary.histogram(<span class="string">'pre_activations'</span>, preactivate)</div><div class="line">		<span class="keyword">if</span> act == <span class="keyword">None</span>:</div><div class="line">			outputs = preactivate</div><div class="line">		<span class="keyword">else</span>:</div><div class="line">			outputs = act(preactivate, name = <span class="string">'activation'</span>)</div><div class="line">			tf.summary.histogram(<span class="string">'activation'</span>, outputs)</div><div class="line">		<span class="keyword">return</span> outputs</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">nn_train</span><span class="params">(wechat_name, param)</span>:</span></div><div class="line">	<span class="keyword">global</span> lock, running</div><div class="line">	<span class="comment"># Lock</span></div><div class="line">	<span class="keyword">with</span> lock:</div><div class="line">		running = <span class="keyword">True</span>	</div><div class="line">	<span class="comment"># 参数 </span></div><div class="line">	learning_rate, training_iters, batch_size, display_step = param</div><div class="line">	</div><div class="line">	<span class="comment"># Import data</span></div><div class="line">	mnist_data_path = <span class="string">'MNIST_data/'</span></div><div class="line">	mnist = input_data.read_data_sets(mnist_data_path, one_hot = <span class="keyword">True</span>)</div><div class="line">	</div><div class="line">	<span class="comment"># Network Parameters</span></div><div class="line">	n_input = <span class="number">28</span>*<span class="number">28</span> <span class="comment"># MNIST data input (img shape: 28*28)</span></div><div class="line">	n_classes = <span class="number">10</span> <span class="comment"># MNIST total classes (0-9 digits)</span></div><div class="line">	dropout = <span class="number">0.75</span> <span class="comment"># Dropout, probability to keep units</span></div><div class="line">	</div><div class="line">	<span class="keyword">with</span> tf.name_scope(<span class="string">'Input'</span>):</div><div class="line">		x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_input], name = <span class="string">'input_x'</span>)</div><div class="line">		y_ = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_classes], name = <span class="string">'target_y'</span>)</div><div class="line">		keep_prob = tf.placeholder(tf.float32, name = <span class="string">'keep_prob'</span>) <span class="comment">#dropout (keep probability)</span></div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">cnn_net</span><span class="params">(x, weights, biases, dropout)</span>:</span></div><div class="line">		<span class="comment"># Reshape input picture</span></div><div class="line">		x_image = tf.reshape(x, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span> ,<span class="number">1</span>])</div><div class="line">		</div><div class="line">		<span class="comment"># First Convolutional Layer</span></div><div class="line">		conv_1 = add_layer(x_image, weights[<span class="string">'conv1_w'</span>], biases[<span class="string">'conv1_b'</span>], <span class="string">'First_Convolutional_Layer'</span>, flag = <span class="number">1</span>)</div><div class="line">		</div><div class="line">		<span class="comment"># First Pooling Layer</span></div><div class="line">		pool_1 = max_pool_2x2(conv_1)</div><div class="line">		</div><div class="line">		<span class="comment"># Second Convolutional Layer </span></div><div class="line">		conv_2 = add_layer(pool_1, weights[<span class="string">'conv2_w'</span>], biases[<span class="string">'conv2_b'</span>], <span class="string">'Second_Convolutional_Layer'</span>, flag = <span class="number">1</span>)</div><div class="line"></div><div class="line">		<span class="comment"># Second Pooling Layer </span></div><div class="line">		pool_2 = max_pool_2x2(conv_2)</div><div class="line"></div><div class="line">		<span class="comment"># Densely Connected Layer</span></div><div class="line">		pool_2_flat = tf.reshape(pool_2, [<span class="number">-1</span>, weight_variable(weights[<span class="string">'dc1_w'</span>]).get_shape().as_list()[<span class="number">0</span>]])</div><div class="line">		dc_1 = add_layer(pool_2_flat, weights[<span class="string">'dc1_w'</span>], biases[<span class="string">'dc1_b'</span>], <span class="string">'Densely_Connected_Layer'</span>, flag = <span class="number">0</span>) </div><div class="line">		</div><div class="line">		<span class="comment"># Dropout</span></div><div class="line">		dc_1_drop = tf.nn.dropout(dc_1, keep_prob)	</div><div class="line">		</div><div class="line">		<span class="comment"># Readout Layer</span></div><div class="line">		y = add_layer(dc_1_drop, weights[<span class="string">'out_w'</span>], biases[<span class="string">'out_b'</span>], <span class="string">'Readout_Layer'</span>, flag = <span class="number">0</span>)</div><div class="line">		</div><div class="line">		<span class="keyword">return</span> y</div><div class="line">	</div><div class="line">	<span class="comment"># Store layers weight &amp; bias</span></div><div class="line">	weights = &#123;</div><div class="line">		<span class="comment"># 5x5 conv, 1 input, 32 outputs</span></div><div class="line">		<span class="string">'conv1_w'</span>: [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>],</div><div class="line">		<span class="comment"># 5x5 conv, 32 inputs, 64 outputs</span></div><div class="line">		<span class="string">'conv2_w'</span>: [<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">64</span>],</div><div class="line">		<span class="comment"># fully connected, 7*7*64 inputs, 1024 outputs</span></div><div class="line">		<span class="string">'dc1_w'</span>: [<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>, <span class="number">1024</span>],</div><div class="line">		<span class="comment"># 1024 inputs, 10 outputs (class prediction)</span></div><div class="line">		<span class="string">'out_w'</span>: [<span class="number">1024</span>, n_classes]</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	biases = &#123;</div><div class="line">		<span class="string">'conv1_b'</span>: [<span class="number">32</span>],</div><div class="line">		<span class="string">'conv2_b'</span>: [<span class="number">64</span>],</div><div class="line">		<span class="string">'dc1_b'</span>: [<span class="number">1024</span>],</div><div class="line">		<span class="string">'out_b'</span>: [n_classes]</div><div class="line">	&#125;</div><div class="line">	</div><div class="line">	y = cnn_net(x, weights, biases, dropout)</div><div class="line">	</div><div class="line">	<span class="comment"># Optimizer</span></div><div class="line">	<span class="keyword">with</span> tf.name_scope(<span class="string">'cost'</span>):</div><div class="line">		cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_,</div><div class="line">						logits = y))</div><div class="line">		tf.summary.scalar(<span class="string">'cost'</span>, cost)</div><div class="line">		tf.summary.histogram(<span class="string">'cost'</span>, cost)</div><div class="line">	</div><div class="line">	<span class="comment"># Train</span></div><div class="line">	<span class="keyword">with</span> tf.name_scope(<span class="string">'train'</span>):</div><div class="line">		optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)</div><div class="line">	</div><div class="line">	<span class="comment"># Test</span></div><div class="line">	<span class="keyword">with</span> tf.name_scope(<span class="string">'accuracy'</span>):</div><div class="line">		<span class="keyword">with</span> tf.name_scope(<span class="string">'correct_prediction'</span>):</div><div class="line">			correct_prediction = tf.equal(tf.argmax(y, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</div><div class="line">		<span class="keyword">with</span> tf.name_scope(<span class="string">'accuracy'</span>):</div><div class="line">			accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</div><div class="line">		tf.summary.scalar(<span class="string">'accuracy'</span>, accuracy)</div><div class="line">		</div><div class="line">	sess = tf.InteractiveSession()</div><div class="line">	merged = tf.summary.merge_all()</div><div class="line">	train_writer = tf.summary.FileWriter(<span class="string">'train/'</span>, sess.graph)</div><div class="line">	test_writer = tf.summary.FileWriter(<span class="string">'test/'</span>)</div><div class="line">	tf.global_variables_initializer().run()</div><div class="line"></div><div class="line">	</div><div class="line">	<span class="comment"># Train the model, and also write summaries.</span></div><div class="line">	<span class="comment"># Every 10th step, measure test-set accuracy, and write test summaries</span></div><div class="line">	<span class="comment"># All other steps, run train_step on training data, &amp; add training summaries</span></div><div class="line">	</div><div class="line">	<span class="comment"># Keep training until reach max iterations</span></div><div class="line">	print(<span class="string">'Wait for lock'</span>)</div><div class="line">	<span class="keyword">with</span> lock:</div><div class="line">		run_state = running</div><div class="line">	print(<span class="string">'Start'</span>)</div><div class="line">	</div><div class="line">	step = <span class="number">1</span></div><div class="line">	<span class="keyword">while</span> step * batch_size &lt; training_iters <span class="keyword">and</span> run_state:</div><div class="line">		batch_x, batch_y = mnist.train.next_batch(batch_size)</div><div class="line">		<span class="comment"># Run optimization op (backprop)</span></div><div class="line">		sess.run(optimizer, feed_dict = &#123;x: batch_x, y_: batch_y, keep_prob: dropout&#125;)</div><div class="line">		<span class="keyword">if</span> step % display_step == <span class="number">0</span>:	<span class="comment"># Record execution stats</span></div><div class="line">			run_options = tf.RunOptions(trace_level = tf.RunOptions.FULL_TRACE)</div><div class="line">			run_metadata = tf.RunMetadata()</div><div class="line">			summary, _ = sess.run([merged, optimizer], feed_dict = </div><div class="line">									&#123;x: batch_x, y_: batch_y, keep_prob: <span class="number">1.</span>&#125;, </div><div class="line">									options = run_options, run_metadata = run_metadata)</div><div class="line">			train_writer.add_run_metadata(run_metadata, <span class="string">'step %d'</span> % step)</div><div class="line">			train_writer.add_summary(summary, step)</div><div class="line">			print(<span class="string">'Adding run metadata for'</span>, step)</div><div class="line"></div><div class="line">			summary, loss, acc = sess.run([merged, cost, accuracy], feed_dict = </div><div class="line">											&#123;x: batch_x, y_: batch_y, keep_prob: <span class="number">1.</span>&#125;)</div><div class="line">			print(<span class="string">"Iter"</span> + str(step*batch_size) + <span class="string">", Minibatch Loss="</span> + \</div><div class="line">				<span class="string">"&#123;:.6f&#125;"</span>.format(loss) + <span class="string">", Training Accuracy="</span> + \</div><div class="line">				<span class="string">"&#123;:.5f&#125;"</span>.format(acc))</div><div class="line">			itchat.send(<span class="string">"Iter"</span> + str(step*batch_size) + <span class="string">", Minibatch Loss="</span> + \</div><div class="line">				<span class="string">"&#123;:.6f&#125;"</span>.format(loss) + <span class="string">", Training Accuracy="</span> + \</div><div class="line">						<span class="string">"&#123;:.5f&#125;"</span>.format(acc), <span class="string">'filehelper'</span>)</div><div class="line">		<span class="keyword">else</span>:</div><div class="line">			summary, _ = sess.run([merged, optimizer], feed_dict = &#123;x: batch_x, y_: batch_y, keep_prob: <span class="number">1.</span>&#125;)</div><div class="line">			train_writer.add_summary(summary, step)</div><div class="line">		step += <span class="number">1</span></div><div class="line">		<span class="keyword">with</span> lock:</div><div class="line">			run_state = running</div><div class="line">	print(<span class="string">"Optimization Finished!"</span>)</div><div class="line">	itchat.send(<span class="string">"Optimization Finished!"</span>, <span class="string">'filehelper'</span>)</div><div class="line"></div><div class="line">	<span class="comment"># Calculate accuracy for 256 mnist test images</span></div><div class="line">	summary, acc = sess.run([merged, accuracy], feed_dict = </div><div class="line">							&#123;x: mnist.test.images[:<span class="number">256</span>], y_: mnist.test.labels[:<span class="number">256</span>], </div><div class="line">							keep_prob: <span class="number">1.</span>&#125; )</div><div class="line">	text_writer.add_summary(summary)</div><div class="line">	print(<span class="string">"Testing Accuracy:"</span>, acc)</div><div class="line">	itchat.send(<span class="string">"Testing Accuracy: %s"</span> % acc, wechat_name)</div><div class="line"></div><div class="line">				</div><div class="line"><span class="meta">@itchat.msg_register([itchat.content.TEXT])</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">chat_trigger</span><span class="params">(msg)</span>:</span></div><div class="line">	<span class="keyword">global</span> lock, running, learning_rate, training_iters, batch_size, display_step</div><div class="line">	<span class="keyword">if</span> msg[<span class="string">'Text'</span>] == <span class="string">u'开始'</span>:</div><div class="line">		print(<span class="string">'Starting'</span>)</div><div class="line">		<span class="keyword">with</span> lock:</div><div class="line">			run_state = running</div><div class="line">		<span class="keyword">if</span> <span class="keyword">not</span> run_state:</div><div class="line">			<span class="keyword">try</span>:</div><div class="line">				threading.Thread(target=nn_train, args=(msg[<span class="string">'FromUserName'</span>], (learning_rate, training_iters, batch_size, display_step))).start()</div><div class="line">			<span class="keyword">except</span>:</div><div class="line">				msg.reply(<span class="string">'Running'</span>)</div><div class="line">	<span class="keyword">elif</span> msg[<span class="string">'Text'</span>] == <span class="string">u'停止'</span>:</div><div class="line">		print(<span class="string">'Stopping'</span>)</div><div class="line">		<span class="keyword">with</span> lock:</div><div class="line">			running = <span class="keyword">False</span></div><div class="line">	<span class="keyword">elif</span> msg[<span class="string">'Text'</span>] == <span class="string">u'参数'</span>:</div><div class="line">		itchat.send(<span class="string">'lr=%f, ti=%d, bs=%d, ds=%d'</span>%(learning_rate, training_iters, batch_size, display_step),msg[<span class="string">'FromUserName'</span>])</div><div class="line">	<span class="keyword">else</span>:</div><div class="line">		<span class="keyword">try</span>:</div><div class="line">			param = msg[<span class="string">'Text'</span>].split()</div><div class="line">			key, value = param</div><div class="line">			print(key, value)</div><div class="line">			<span class="keyword">if</span> key == <span class="string">'lr'</span>:</div><div class="line">				learning_rate = float(value)</div><div class="line">			<span class="keyword">elif</span> key == <span class="string">'ti'</span>:</div><div class="line">				training_iters = int(value)</div><div class="line">			<span class="keyword">elif</span> key == <span class="string">'bs'</span>:</div><div class="line">				batch_size = int(value)</div><div class="line">			<span class="keyword">elif</span> key == <span class="string">'ds'</span>:</div><div class="line">				display_step = int(value)</div><div class="line">		<span class="keyword">except</span>:</div><div class="line">			<span class="keyword">pass</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">	itchat.auto_login(hotReload=<span class="keyword">True</span>)</div><div class="line">	itchat.run()</div></pre></td></tr></table></figure>
<p> 大家可以看到，我对先前的代码进行了一些修改。</p>
<p> 下面我会对代码中用到 itchat 的部分进行一些简短的说明。</p>
<ul>
<li> 代码部分截图：</li>
</ul>
<p><img src="https://farm4.staticflickr.com/3687/33417461155_a448845f98_o.png" alt=""></p>
<p> 说明：</p>
<ol>
<li> 首先我导入了 itchat 和 threading。</li>
<li> 在原先所有 <code>print</code> 消息的地方，都添加了 <code>itchat.send()</code> 来输出我们的模型训练日志。</li>
<li> 加了一个带锁的状态量 <code>running</code> 用来做为发送微信消息的运行开关。</li>
<li> 写了一个 itchat 的 handler（就是上图）。其作用就是当程序运行，我们需要在微信中，对自己的微信号发送「开始」，模型才会开始训练，为了防止信息阻塞，所以要用到 <code>threading</code> 将其放在另一个线程当中。在训练的过程中，如果我们觉得结果已到达我们自己的预期，可以微信发送「停止」来停止模型的训练过程。</li>
</ol>
<p><strong> 另外，脚本刚开始运行时，程序会弹出一个包含二维码的图片，我们需要通过微信来扫描该二维码，来登陆微信并启动 itchat 的服务。</strong></p>
<p> 程序是包含了 Tensorboard 绘图的，所以等模型训练好，我们依然是可以通过 Tensorboard 来更加详细地查看我们模型的训练过程。 </p>
<p> 至此，我们就可以一边通过微信来监控我们的模型训练过程，一边与身边的朋友们谈笑风生了。</p>
<p> 如果看过 itchat 那个连接的读者，可以了解到 itchat 同样是可以发送图片信息的，所以我们可以写额外的脚本在训练的过程中每隔 100 次迭代， plot 到目前为止 loss，acc 等指标的趋势图。在此，我就不再进行拓展了。</p>
<p> 关于各个模块的作用，以及各个变量的意义，我在此就不再赘述了。</p>
<p> 如果有读者对于 CNN 卷积神经网络有些陌生或者是遗忘，可以参考我的另外一篇文章 <a href="http://www.jianshu.com/p/95c79381ab4f" target="_blank" rel="external">CNN on TensorFlow</a>。</p>
<p> 如果读者对 Tensorboard 有所遗忘，可以参考我的另一篇文章 <a href="http://www.jianshu.com/p/b5caf4d5ce3e" target="_blank" rel="external">「TensorFlow 1.0」 Tensorboard</a>。</p>
]]></content>
    
    <summary type="html">
    
      平时，大家自己的机器模型在训练期间（特别是深度网络），训练时间通常几小时到十几小时不等，甚至可能会花上好几天，那么在这段时间，你们又会干些什么事情呢？作为程序员，这里提供一个「有趣的」方式，用你的微信来监控你的模型在训练期间的一举一动。
    
    </summary>
    
      <category term="TensorFlow" scheme="http://randolph.pro/categories/TensorFlow/"/>
    
    
      <category term="Python" scheme="http://randolph.pro/tags/Python/"/>
    
      <category term="TensorFlow" scheme="http://randolph.pro/tags/TensorFlow/"/>
    
      <category term="WeChat" scheme="http://randolph.pro/tags/WeChat/"/>
    
  </entry>
  
  <entry>
    <title>「Computer Vision」 JPEG Compression</title>
    <link href="http://randolph.pro/2016/04/15/%3CComputer%20Vision%3E%20JPEG%20Compression/"/>
    <id>http://randolph.pro/2016/04/15/&lt;Computer Vision&gt; JPEG Compression/</id>
    <published>2016-04-14T16:00:00.000Z</published>
    <updated>2017-07-25T12:12:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Related"><a href="#Related" class="headerlink" title="Related"></a>Related</h1><ul>
<li><strong>颜色模式转换: RBG to YUV</strong></li>
<li><strong>采样 &amp; 分块</strong></li>
<li><strong>DCT 离散余弦变换</strong></li>
<li><strong>量化</strong></li>
<li><strong>DPCM 差分编码（对 DC 系数）</strong></li>
<li><strong>RLE 游程编码（对 AC 系数）：Zig-Zag 扫描</strong></li>
<li><strong>熵编码：Huffman 编码</strong></li>
</ul>
<h1 id="颜色模式转换"><a href="# 颜色模式转换" class="headerlink" title="颜色模式转换"></a>颜色模式转换</h1><p>JPEG 采用的是 YCrCb 颜色空间，而 BMP 采用的是 RGB 颜色空间，要想对 BMP 图片进行压缩，首先需要进行颜色空间的转换。YCrCb 颜色空间中，$Y$ 代表亮度，$Cr$，$Cb$ 则代表色度和饱和度（也有人将 $Cb$，$Cr$ 两者统称为色度），三者通常以 $Y$，$U$，$V$ 来表示，即用 $U$ 代表 $Cb$，用 $V$ 代表 $Cr$。RGB 和 YCrCb 之间的转换关系如下所示：</p>
<script type="math/tex; mode=display">
\begin{align}
Y &= &0.299R &+ 0.587G + 0.114B \cr
Cb &= &-0.168R &- 0.331G + 0.500B  + 128 \cr
Cr &= &0.500R &- 0.418G - 0.081B  + 128 
\end{align}</script><h1 id="采样"><a href="# 采样" class="headerlink" title="采样"></a>采样 </h1><p> 研究发现，<strong>人眼对亮度变换的敏感度要比对色彩变换的敏感度高出很多</strong>。</p>
<p>因此，我们可以认为 Y 分量要比 Cb，Cr 分量重要的多。在 BMP 图片中，RGB 三个分量各采用一个字节进行采样，也就是我们常听到的 RGB-888 的模式；而 JPEG 图片中，通常采用两种采样方式：YUV-411 和 YUV-422，它们所代表的意义是 Y，Cb，Cr 三个分量的数据取样比例一般是 4：1：1 或者 4：2：2（4：1：1 含义就是：在 $2\times 2$ 的单元中，本应分别有 4 个 Y，4 个 U，4 个 V 值，用 12 个字节进行存储。经过 4:1:1 采样处理后，每个单元中的值分别有 4 个 Y、1 个 U、1 个 V，只要用 6 个字节就可以存储了）</p>
<p>这样的采样方式，虽然损失了一定的精度但也在人眼不太察觉到的范围内减小了数据的存储量。当然，JPEG 格式里面也允许将每个点的 U，V 值都记录下来。</p>
<h1 id="分块"><a href="# 分块" class="headerlink" title="分块"></a>分块 </h1><p> 由于后面的 DCT 变换是是对 $8 \times 8$ 的子块进行处理的，因此，在进行 DCT 变换之前必须把源图象数据进行分块。源图象中每点的 3 个分量是交替出现的，先要把这 3 个分量分开，存放到 3 张表中去。然后由左及右，由上到下依次读取 $8 \times 8$ 的子块，存放在长度为 64 的表中，即可以进行 DCT 变换。</p>
<p>注意，编码时，程序从源数据中读取一个 $8 \times 8$ 的数据块后，进行 DCT 变换，量化，编码，然后再读取、处理下一个 $8 \times 8$ 的数据块。</p>
<p><strong>JPEG 编码是以每 $8 \times 8$ 个点为一个单位进行处理的. 所以如果原始图片的长宽不是 8 的倍数， 都需要先补成 8 的倍数， 使其可以进行一块块的处理。将原始图像数据分为 $8 \times 8$ 的数据单元矩阵之后，还必须将每个数值减去 128，然后一一带入 DCT 变换公式，即可达到 DCT 变换的目的。图像的数据值必须减去 128，是因为 DCT 公式所接受的数字范围是 -128 到 127 之间。</strong></p>
<h2 id="DCT- 离散余弦变化"><a href="#DCT- 离散余弦变化" class="headerlink" title="DCT 离散余弦变化"></a>DCT 离散余弦变化</h2><p>DCT（Discrete Cosine Transform，离散余弦变换），是码率压缩中常用的一种变换编码方法。任何连续的实对称函数的傅里叶变换中只含有余弦项，因此，余弦变换同傅里叶变换一样具有明确的物理意义。DCT 是先将整体图像分成 $N \times N$ 的像素块，然后针对 $N \times N$ 的像素块逐一进行 DCT 操作。需要提醒的是，JPEG 的编码过程需要进行正向离散余弦变换，而解码过程则需要反向离散余弦变换。</p>
<h3 id="二维 -DCT- 变换公式："><a href="# 二维 -DCT- 变换公式：" class="headerlink" title="二维 DCT 变换公式："></a>二维 DCT 变换公式：</h3><script type="math/tex; mode=display">
F(u,v)=c(u)c(v)\sum_{i=0}^{N-1}\sum_{j=0}^{N-1}f(i,j)\cos \left[\frac{(i+0.5)\pi}{N}u\right]\cos \left[\frac{(j+0.5)\pi}{N}v\right]</script><script type="math/tex; mode=display">
c(u)=
\begin{cases}
\sqrt{\frac 1N},& u = 0 \cr
\sqrt{2 \over N},& u \neq 0 \cr
\end{cases}</script><h3 id="二维 -DCT- 逆变换公式："><a href="# 二维 -DCT- 逆变换公式：" class="headerlink" title="二维 DCT 逆变换公式："></a>二维 DCT 逆变换公式：</h3><script type="math/tex; mode=display">
f(i,j)=\sum_{u=0}^{N-1}\sum_{v=0}^{N-1}c(u)c(v)F(u,v)\cos \left[\frac{(i+0.5)\pi}{N}u\right]\cos \left[\frac{(j+0.5)\pi}{N}v\right]</script><script type="math/tex; mode=display">
c(u)=
\begin{cases}
\sqrt{\frac 1N},& u = 0 \cr
\sqrt{2 \over N},& u \neq 0 \cr
\end{cases}</script><p>这里的 N 是水平、垂直方向的像素数目，一般取值为 8。$8 \times 8$ 的二维像素块经过 DCT 操作之后，就得到了 $8 \times 8$ 的变换系数矩阵。这些系数，都有具体的物理含义。</p>
<p>例如，$U=0$，$V=0$ 时的 $F(0,0)$ 是原来的 64 个数据的均值，相当于直流分量，也有人称之为 DC 系数或者直流系数。随着 $U$，$V$ 的增加，相另外的 63 个系数则代表了水平空间频率和垂直空间频率分量（高频分量）的大小，多半是一些接近于 0 的正负浮点数，我们称之为交流系数 AC。</p>
<p>DCT 变换后的 $8 \times 8$ 的系数矩阵中，低频分量集中在矩阵的左上角。高频成分则集中在右下角。这里，我们暂时先只考虑水平方向上一行数据（8 个像素）的情况时的 DCT 变换，从而来说明其物理意义。如下图所示：</p>
<p><img src="https://farm6.staticflickr.com/5342/31519596181_839559fe8c_o.png" alt=""></p>
<p>原始的图像信号（最左边的波形）经过 DCT 变换之后变成了 8 个波，其中第一个波为直流成分，其余 7 个为交流成分。可见图像信号被分解为直流成分和一些从低频到高频的各种余弦成分。而 DCT 系数只表示了该种成分所占原图像信号的份额大小。显然，恢复图像信息可以表示为下面的式子：</p>
<script type="math/tex; mode=display">
F(n) = C(n) \cdot E(n)</script><p>这里，$E(n)$ 是一个基底，$C(n)$ 是 DCT 系数，$F(n)$ 则是图像信号；如果考虑垂直方向的变化，那就需要一个二维的基底。大学里面的信号处理，傅里叶变换等课程上也讲过，任何信号都可以被分解为基波和不同幅度的谐波的组合，而 DCT 变换的物理意义也正是如此。</p>
<p><strong>由于大多数图像的高频分量比较小，相应的图像高频分量的 DCT 系数经常接近于 0，再加上高频分量中只包含了图像的细微的细节变化信息，而人眼对这种高频成分的失真不太敏感，所以，可以考虑将这一些高频成分予以抛弃，从而降低需要传输的数据量。这样一来，传送 DCT 变换系数的所需要的编码长度要远远小于传送图像像素的编码长度。到达接收端之后通过反离散余弦变换就可以得到原来的数据，虽然这么做存在一定的失真，但人眼是可接受的，而且对这种微小的变换是不敏感的。所谓 JPEG 的有损压缩，损的是量化过程中的高频部分，romove 50% 的高频信息可能对于编码信息只损失了 5%。</strong></p>
<h1 id="量化"><a href="# 量化" class="headerlink" title="量化"></a>量化 </h1><p> 图像数据转换为 DCT 频率系数之后，还要进行量化阶段，才能进入编码过程。量化阶段需要两个 $8 \times 8$ 量化矩阵数据，将频率系数除以量化矩阵的值之后取整，即完成了量化过程。</p>
<p>简而言之，所谓量化就是用像素值除以量化表对应值所得的结果。</p>
<p>由于量化表左上角的值较小，右下角的值较大，这样就起到了保持低频分量，抑制高频分量的目的。JPEG 使用的颜色是 YUV 格式。我们提到过，$Y$ 分量代表了亮度信息，$UV$ 分量代表了色差信息。相比而言，$Y$ 分量更重要一些。我们可以对  $Y$ 采用细量化，对 $UV$ 采用粗量化，可进一步提高压缩比。所以上面所说的量化表通常有两张，一个是专门处理亮度的频率系数，另一个则是针对色度的频率系数，即一张是针对 $Y$ 的，而另一张是针对 $UV$ 的。<strong>当频率系数经过量化之后，将频率系数由浮点数转变为整数，这才便于执行最后的编码。不难发现，经过量化阶段之后，所有的数据只保留了整数近似值，也就再度损失了一些数据内容。在 JPEG 算法中，由于对亮度和色度的精度要求不同，分别对亮度和色度采用不同的量化表。</strong></p>
<p>下图给出 JPEG 的亮度量化表和色度量化表，该量化表是从广泛的实验中得出的。当然，你也可以自定义量化表。</p>
<h2 id="JPEG- 亮度量化表"><a href="#JPEG- 亮度量化表" class="headerlink" title="JPEG 亮度量化表"></a>JPEG 亮度量化表</h2><script type="math/tex; mode=display">
\begin{array}{|c|c|c|c|c|c|c|c|c|}
\hline
16 & 11 & 10 & 16 & 24 & 40 & 51 & 61 \cr
\hline
12 & 12 & 14 & 19 & 26 & 58 & 60 & 55 \cr
\hline
14 & 13 & 16 & 24 & 40 & 57 & 69 & 56 \cr
\hline
14 & 17 & 22 & 29 & 51 & 87 & 80 & 62 \cr
\hline
18 & 22 & 37 & 56 & 68 & 109 & 103 & 77 \cr
\hline
24 & 35 & 55 & 64 & 81 & 104 & 113 & 92 \cr
\hline
49 & 64 & 78 & 87 & 103 & 121 & 120 & 101 \cr
\hline
72 & 92 & 95 & 98 & 112 & 100 & 103 & 99 \cr
\hline
\end{array}</script><h2 id="JPEG- 色度量化表"><a href="#JPEG- 色度量化表" class="headerlink" title="JPEG 色度量化表"></a>JPEG 色度量化表</h2><script type="math/tex; mode=display">
\begin{array}{|c|c|c|c|c|c|c|c|c|}
\hline
17 & 18 & 24 & 47 & 99 & 99 & 99 & 99 \cr
\hline
18 & 21 & 26 & 66 & 99 & 99 & 99 & 99 \cr
\hline
24 & 26 & 56 & 99 & 99 & 99 & 99 & 99 \cr
\hline
47 & 66 & 99 & 99 & 99 & 99 & 99 & 99 \cr
\hline
99 & 99 & 99 & 99 & 99 & 99 & 99 & 99 \cr
\hline
99 & 99 & 99 & 99 & 99 & 99 & 99 & 99 \cr
\hline
99 & 99 & 99 & 99 & 99 & 99 & 99 & 99 \cr
\hline
99 & 99 & 99 & 99 & 99 & 99 & 99 & 99 \cr
\hline
\end{array}</script><p>这两张表依据心理视觉阀制作, 对 8 bit 的亮度和色度的图象的处理效果不错。</p>
<p><strong>量化表是控制 JPEG 压缩比的关键，这个步骤除掉了一些高频量, 损失了很多细节信息。但事实上人眼对高频信号的敏感度远没有低频信号那么敏感。</strong></p>
<p>所以处理后的视觉损失很小，从上面的量化表也可以看出，低频部分采用了相对较短的量化步长，而高频部分则采用了相对较长的量化步长，这样做，也是为了在一定程度上得到相对清晰的图像和更高的压缩率。另一个重要原因是所有的图片的点与点之间会有一个色彩过渡的过程，而大量的图象信息被包含在低频率空间中，经过 DCT 处理后, 在高频率部分, 将出现大量连续的零。</p>
<h1 id="DPCM- 差分编码（对 -DC- 系数）-amp-RLE- 游程编码（对 -AC- 系数）"><a href="#DPCM- 差分编码（对 -DC- 系数）-amp-RLE- 游程编码（对 -AC- 系数）" class="headerlink" title="DPCM 差分编码（对 DC 系数）&amp; RLE 游程编码（对 AC 系数）"></a>DPCM 差分编码（对 DC 系数）&amp; RLE 游程编码（对 AC 系数）</h1><p>DCT 将一个 $8 \times 8$ 的数组变换成另一个 $8 \times 8$ 的数组. 编码信息分两类，一类是每个 $8 \times 8$ 格子 $F(0,0)$ 位置上元素，这是 DC（直流分量），代表 $8 \times 8$ 个子块的平均值，JPEG 中对 $F(0,0)$ 单独编码，由于两个相邻的 $8 \times 8$ 子块的 DC 系数相差很小，所以对它们采用 <strong> 差分编码 DPCM （Difference Pulse Code Modulation）</strong>，可以提高压缩比，也就是说 <strong> 对相邻的子块 DC 系数的差值进行编码。</strong>另一类是 $8 \times 8$ 块的其它 63 个子块，即交流（AC）系数，采用 <strong> 行程编码 RLE （Run-length encode）</strong>。</p>
<p>那么，现在问题来了：这 63 个系数应该按照怎么样的顺序排列？为了保证低频分量先出现，高频分量后出现，以增加行程中连续 “0” 的个数，这 63 个元素采用了 “之” 字型（Zig-Zag）的排列方法，如下图所示：</p>
<p><img src="https://farm1.staticflickr.com/42/31635280065_4468d99a85_o.png" alt=""></p>
<p>举个例子，现在在一个 $ 8\times 8$ 的 block 中：</p>
<script type="math/tex; mode=display">
\left[\begin{array}{cccccccc}
0 & 1 & 5 & 6 & 14 & 15 & 27 & 28 \cr
2 & 4 & 7 & 13 & 16 & 26 & 29 & 42 \cr
3 & 8 & 12 & 17 & 25 & 30 & 41 & 43 \cr
9 & 11 & 18 & 24 & 31 & 40 & 44 & 53 \cr
10 & 19 & 23 & 32 & 39 & 45 & 52 & 54 \cr
20 & 22 & 33 & 38 & 46 & 51 & 55 & 60 \cr
21 & 34 & 37 & 47 & 50 & 56 & 59 & 61 \cr
35 & 36 & 48 & 49 & 57 & 58 & 62 & 63 \cr
\end{array}
\right]</script><p>进行 DCT 余弦离散变换之后，对其进行 Zig-Zag 扫描排序的过程：</p>
<script type="math/tex; mode=display">
\left[\begin{array}{cccccccc}
-26 & -3 & -6 & 2 & 2 & -1 & 0 & 0 \cr
0 & -3 & -4 & 1 & 1 & 0 & 0 & 0 \cr
-3 & 1 & 5 & -1 & -1 & 0 & 0 & 0 \cr
-4 & 1 & 2 & -1 & 0 & 0 & 0 & 0 \cr
1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \cr
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \cr
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \cr
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \cr
\end{array}
\right]</script><h2 id="DC- 系数的差分脉冲调制编码"><a href="#DC- 系数的差分脉冲调制编码" class="headerlink" title="DC 系数的差分脉冲调制编码"></a>DC 系数的差分脉冲调制编码</h2><p>$8\times 8$ 的图像块经过 DCT 变换之后得到的 DC 系数有两个特点：</p>
<ol>
<li>系数的数值比较大；</li>
<li>相邻的 $8\times 8$ 图像块的 DC 系数值变化不大；</li>
</ol>
<p>根据这两个特点，DC 系数一般采用差分脉冲调制编码 DPCM（Difference Pulse Code Modulation），即：取同一个图像分量中每个 DC 值与前一个 DC 值的差值来进行编码。对差值进行编码所需要的位数会比对原值进行编码所需要的位数少了很多。假设某一个 $8\times 8$ 图像块的 DC 系数值为 15，而上一个 $8\times 8$ 图像块的 DC 系数为 12，则两者之间的差值为 3。</p>
<h2 id="DC- 系数的中间格式计算"><a href="#DC- 系数的中间格式计算" class="headerlink" title="DC 系数的中间格式计算"></a>DC 系数的中间格式计算</h2><p>JPEG 中为了更进一步节约空间，并不直接保存数据的具体数值，而是将数据按照位数分为 16 组，保存在表里面。这也就是所谓的变长整数编码 VLI。即，第 0 组中保存的编码位数为 0，其编码所代表的数字为 0；第 1 组中保存的编码位数为 1，编码所代表的数字为 -1 或者 1 ……，如下面的表格所示, 暂且称其为 VLI 编码表：</p>
<script type="math/tex; mode=display">
\begin{array}{|c|c|c|}
\hline
\text{数值} & \text{组} & \text{实际保存值} \cr
\hline
0 & 0 & - \cr
\hline
-1, 1 & 1 & 0,1 \cr
\hline
-3,-2,2,3 & 2 & 00,01,10,11 \cr
\hline
-7,-6,-5,-4,4,5,6,7 & 3 & 000,001,010,011,100,101,110,111 \cr
\hline
-15,..,-8,8,..,15 & 4 & 0000,..,0111,1000,..,1111 \cr
\hline
-31,..,-16,16,..,31 & 5 & 00000,..,01111,10000,..,11111 - \cr
\hline
-63,..,-32,32,..,63 & 6 & . \cr
\hline
-127,..,-64,64,..,127 & 7 & . \cr
\hline
-255,..,-128,128,..,255 & 8 & . \cr
\hline
-511,..,-256,256,..,511 & 9 & . \cr
\hline
-1023,..,-512,512,..,1023 & 10 & . \cr
\hline
-2047,..,-1024,1024,..,2047 & 11 & . \cr
\hline
-4095,..,-2048,2048,..,4095 & 12 & . \cr
\hline
-8191,..,-4096,4096,..,8191 & 13 & . \cr
\hline
-16383,..,-8192,8192,..,16383 & 14 & . \cr
\hline
-32767,..,-16384,16384,..,32767 & 15 & . \cr
\hline
\end{array}</script><p>前面提到的那个 DC 差值为 3 的数据，通过查找 VLI 可以发现，整数 3 位于 VLI 表格的第 2 组，因此，可以写成 $(2)(3)$ 的形式，该形式，称之为 DC 系数的中间格式。</p>
<h2 id="AC- 系数的行程长度编码（RLC）"><a href="#AC- 系数的行程长度编码（RLC）" class="headerlink" title="AC 系数的行程长度编码（RLC）"></a>AC 系数的行程长度编码（RLC）</h2><p>量化之后的 AC 系数的特点是，63 个系数中含有很多值为 0 的系数。因此，可以采用行程编码 RLC（Run Length Coding）来更进一步降低数据的传输量。利用该编码方式，可以将一个字符串中重复出现的连续字符用两个字节来代替，其中，第一个字节代表重复的次数，第二个字节代表被重复的字符串。例如，$(4, 6)$ 就代表字符串 “6666”。</p>
<p>但是，在 JPEG 编码中，RLC 的含义就同其原有的意义略有不同。在 JPEG 编码中，假设 RLC 编码之后得到了一个 $(M,N)$ 的数据对，其中 M 是两个非零 AC 系数之间连续的 0 的个数（即，行程长度），N 是下一个非零的 AC 系数的值。采用这样的方式进行表示，是因为 AC 系数当中有大量的 0，而采用 Zigzag 扫描也会使得 AC 系数中有很多连续的 0 的存在，如此一来，便非常适合于用 RLC 进行编码。</p>
<p>例如，现有一个字符串，如下所示：</p>
<script type="math/tex; mode=display">
57, 45, 0, 0, 0, 0, 23, 0, -30, -8, 0, 0, 1, 0 0 0 .....</script><p>经过 RLC 之后，将呈现出以下的形式：</p>
<script type="math/tex; mode=display">
 (0, 57) ; (0, 45) ; (4, 23) ; (1, -30) ; (0, -8) ; (2, 1) ; (0, 0)</script><p><strong>注意，如果 AC 系数之间连续 0 的个数超过 16，则用一个扩展字节 (15, 0) 来表示 16 连续的 0。</strong></p>
<h2 id="AC 系数的中间格式"><a href="#AC 系数的中间格式" class="headerlink" title="AC 系数的中间格式"></a>AC 系数的中间格式 </h2><p> 根据前面提到的 VLI 表格，对于前面的字符串：</p>
<script type="math/tex; mode=display">
 (0, 57) ; (0, 45) ; (4, 23) ; (1, -30) ; (0, -8) ; (2, 1) ; (0, 0)</script><p>只处理每对数右边的那个数据，对其进行 VLI 编码: 查找上面的 VLI 编码表格，可以发现，57 在第 6 组当中，因此，可以将其写成 $(0,6),57$ 的形式，该形式，称之为 AC 系数的中间格式。<br>同样的 $(0, 45)$ 的中间格式为：$(0, 6), 45$；$(1, -30)$ 的中间格式为：$(1, 5), -30$；</p>
<h1 id="熵编码：Huffman- 编码"><a href="# 熵编码：Huffman- 编码" class="headerlink" title="熵编码：Huffman 编码"></a>熵编码：Huffman 编码 </h1><p> 在得到 DC 系数的中间格式和 AC 系数的中间格式之后，为进一步压缩图象数据，有必要对两者进行熵编码。<strong>JPEG 标准具体规定了两种熵编码方式：Huffman 编码和算术编码。</strong>JPEG 基本系统规定采用 Huffman 编码（因为不存在专利问题），但 JPEG 标准并没有限制 JPEG 算法必须用 Huffman 编码方式或者算术编码方式。 </p>
<h2 id="Huffman- 编码"><a href="#Huffman- 编码" class="headerlink" title="Huffman 编码"></a>Huffman 编码 </h2><p> 对出现概率大的字符分配字符长度较短的二进制编码，对出现概率小的字符分配字符长度较长的二进制编码，从而使得字符的平均编码长度最短。Huffman 编码的原理请参考数据结构中的 Huffman 树或者最优二叉树。</p>
<p><strong>Huffman 编码时 DC 系数与 AC 系数分别采用不同的 Huffman 编码表，对于亮度和色度也采用不同的 Huffman 编码表。</strong>因此，需要 4 张 Huffman 编码表才能完成熵编码的工作。具体的 Huffman 编码采用查表的方式来高效地完成。然而，在 JPEG 标准中没有定义缺省的 Huffman 表，用户可以根据实际应用自由选择，也可以使用 JPEG 标准推荐的 Huffman 表。或者预先定义一个通用的 Huffman 表，也可以针对一副特定的图像，在压缩编码前通过搜集其统计特征来计算 Huffman 表的值。</p>
<p>下面我们举例来说明 $8\times 8$ 图像子块经过 DCT 及量化之后的处理过程：<br>假设一个图像块经过量化以后得到以下的系数矩阵：</p>
<script type="math/tex; mode=display">
\left[\begin{array}{cccccccc}
15 & 0 & -1 & 0 & 0 & 0 & 0 & 0 \cr
-2 & -1 & 0 & 0 & 0 & 0 & 0 & 0 \cr
-1 & -1 & 0 & 0 & 0 & 0 & 0 & 0 \cr
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \cr
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \cr
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \cr
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \cr
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \cr
\end{array}
\right]</script><p>显然，DC 系数为 15，假设前一个 $8\times 8$ 的图像块的 DC 系数量化值为 12，则当前 DC 系统同上一个 DC 系数之间的差值为 3，通过查找 VLI 编码表，可以得到 DC 系数的中间格式为 $(2)(3)$，这里的 2 代表后面的数字 $(3)$ 的编码长度为 2 位；之后，通过 Zigzag 扫描之后，遇到第一个非 0 的 AC 系数为 -2，遇到 0 的个数为 1，AC 系数经过 RLC 编码后可表示为 $(1, -2)$，通过查找 VLI 表发现，-2 在第 2 组，因此，该 AC 系数的中间格式为 $(1, 2) , -2$；其余的点类似，可以求得这个 $ 8\times 8$ 子块熵编码的中间格式为:</p>
<script type="math/tex; mode=display">
\begin{array}{c|c}
DC & (2)(3) \cr
\hline
AC & (1,2)(-2),(0,1)(-1),(0,1)(-1),(0,1)(-1),(2,1)(-1),(EOB)(0,0)
\end{array}</script><ul>
<li>对于 DC 系数的中间格式 $(2)(3)$ 而言，数字 2 查 DC 亮度 Huffman 表得到 011，数字 3 通过查找 VLI 编码表得到其被编码为 11；</li>
<li>对于 AC 系数的中间格式 $(1, 2)(-2)$ 而言，$(1, 2)$ 查 AC 亮度 Huffman 表得到 11011，-2 通过查找 VLI 编码表得到其被编码为 01；</li>
<li>对于 AC 系数的中间格式 $(0, 1)(-1)$ 而言，$(0, 1)$ 查 AC 亮度 Huffman 表得到 00，数字 -1 通过查找 VLI 编码表得到其被编码为 0；</li>
<li>对于 AC 系数的中间格式 $(2, 1)(1)$ 而言，$(2, 1)$ 查 AC 亮度 Huffman 表得到 11100，数字 -1 通过查找 VLI 编码表得到其被编码为 0；</li>
<li>对于 AC 系数的中间格式 $(0, 0)$ 而言，查 AC 亮度 Huffman 表得到 1010；</li>
</ul>
<p>因此，最后这个 $8\times 8$ 子块亮度信息压缩后的数据流为 01111，1101101，000，000，000，111000，1010。总共 31 比特，其压缩比是 $ \frac{64 \times 8}{31} =16.5$，大约每个像素用半个比特。</p>
]]></content>
    
    <summary type="html">
    
      本文介绍了关于信息隐藏中的图像 JPEG 压缩标准方法，JPEG 是一种针对照片视频而广泛使用的一种「有损压缩」标准方法。
    
    </summary>
    
      <category term="Computer Vision" scheme="http://randolph.pro/categories/Computer-Vision/"/>
    
    
      <category term="Python" scheme="http://randolph.pro/tags/Python/"/>
    
      <category term="Computer Vision" scheme="http://randolph.pro/tags/Computer-Vision/"/>
    
  </entry>
  
  <entry>
    <title>♞「Programming Collective Intelligence」 Chapter 3</title>
    <link href="http://randolph.pro/2016/03/19/%3CProgramming%20Collective%20Intelligence%3E%20Chapter%203/"/>
    <id>http://randolph.pro/2016/03/19/&lt;Programming Collective Intelligence&gt; Chapter 3/</id>
    <published>2016-03-18T16:00:00.000Z</published>
    <updated>2017-07-25T13:35:42.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fhu94m6p9zj30t612ah7b.jpg" alt=""></p>
<p>关于该书的其他学习笔记系列：<a href="http://randolph.pro/categories/Machine-Learning/Book-「Programming-Collective-Intelligence」/">「Programming Collective Intelligence」</a></p>
<h1 id="Related"><a href="#Related" class="headerlink" title="Related"></a>Related</h1><ul>
<li>皮尔逊相关系数</li>
<li>分级聚类</li>
<li>K- 均值聚类</li>
<li>针对偏好的聚类</li>
<li>多维缩放</li>
<li>EM 聚类</li>
</ul>
<hr>
<h1 id="Key"><a href="#Key" class="headerlink" title="Key:"></a>Key:</h1><h2 id="皮尔逊相关系数："><a href="# 皮尔逊相关系数：" class="headerlink" title="皮尔逊相关系数："></a>皮尔逊相关系数：</h2><p>定义：两个变量之间的皮尔逊相关系数定义为 <strong>（两个变量之间的协方差）</strong> 和<strong>（两个变量标准差的积）</strong>的商。</p>
<script type="math/tex; mode=display">
\rho_{x,y} = \frac{cov(X,Y)}{\sigma_{X}\sigma_{Y}}=\frac{E[(X-E(X))\cdot (Y-E(Y))]}{\sigma_{X}\sigma_{Y}}=\frac{E(XY)-E(X)E(Y)}{\sigma_{X}\sigma_{Y}}</script><p>公式进一步推导：</p>
<script type="math/tex; mode=display">
\rho_{x,y} = \frac{\sum XY - \frac{\sum X \sum Y}{N}}{\sqrt{(\sum X-\frac{(\sum X)^2}{N})(\sum Y-\frac{(\sum Y)^2}{N})}}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> math <span class="keyword">import</span> *</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">pearson</span><span class="params">(v1, v2)</span>:</span></div><div class="line">    sum1 = sum(v1)</div><div class="line">    sum2 = sum(v2)</div><div class="line"></div><div class="line">    <span class="comment"># 求平方和</span></div><div class="line">    sum1_Sq = sum([pow(v, <span class="number">2</span>) <span class="keyword">for</span> v <span class="keyword">in</span> v1])</div><div class="line">    sum2_Sq = sum([pow(v, <span class="number">2</span>) <span class="keyword">for</span> v <span class="keyword">in</span> v2])</div><div class="line"></div><div class="line">    <span class="comment"># 求乘积之和</span></div><div class="line">    pSum = sum([v1[i]*v2[i] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(v1))])</div><div class="line"></div><div class="line">    num = pSum-(sum1*sum2/len(v1))</div><div class="line">    den = sqrt((sum1_Sq-pow(sum1, <span class="number">2</span>)/len(v1))*(sum2_Sq-pow(sum2, <span class="number">2</span>)/len(v2)))</div><div class="line"></div><div class="line">    <span class="keyword">if</span> den == <span class="number">0</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">0</span></div><div class="line">    <span class="keyword">return</span> <span class="number">1.0</span> - num/den</div></pre></td></tr></table></figure>
<ul>
<li>皮尔逊相关度的计算结果在两者完全匹配的情况下为 1.0，而在两者毫无关系的情况下则为 0.0。此段代码的最后一行，返回的是以 1.0 减去皮尔逊相关度之后的结果，这样的目的是为了让相似度越大的两个元素之间的距离变得更小（做了一个小处理）。</li>
</ul>
<hr>
<h2 id="分级聚类："><a href="# 分级聚类：" class="headerlink" title="分级聚类："></a>分级聚类：</h2><p>分级聚类通过连续不断地将最为相似的群组两两合并，来构造出一个群组的层级结构。其中的每个群组都是从单一元素开始的。在每次迭代的过程，分级聚类算法会计算每两个群组间的距离，并将距离最近的两个群组合并成一个新的群组。这一过程会一直重复下去，直到只剩一个群组为止。<br><img src="https://farm1.staticflickr.com/591/30827330683_718ddf881c_o.png" alt=""></p>
<p>直接使用 <strong>blogdata.txt</strong> 博客数据集，不要用书上前面的代码来下载一系列博客的订阅源，从而构造这样一个数据集，因为书上的代码无法使用，一些库的模块功能已经过时，运行会出错。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">readfile</span><span class="params">(filename)</span>:</span></div><div class="line">    lines = [line <span class="keyword">for</span> line <span class="keyword">in</span> file(filename)]</div><div class="line"></div><div class="line">    colnames = lines[<span class="number">0</span>].strip().split(<span class="string">'\t'</span>)[<span class="number">1</span>:]</div><div class="line"></div><div class="line">    rownames = []</div><div class="line">    data = []</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> lines[<span class="number">1</span>:]:</div><div class="line">        p = line.strip().split(<span class="string">'\t'</span>)</div><div class="line">        rownames.append(p[<span class="number">0</span>])</div><div class="line">        data.append([float(x) <span class="keyword">for</span> x <span class="keyword">in</span> p[<span class="number">1</span>:]])</div><div class="line"></div><div class="line">    <span class="keyword">return</span> colnames, rownames, data</div></pre></td></tr></table></figure>
<ul>
<li>colnames = [‘china’, ‘kids’, …, ‘book’]为所有博客中出现的单词的单词表。</li>
<li>rownames = [‘$blog_1$’, ‘$blog_2$’, …, ‘$blog_n$’]为所有博客的名字表。</li>
<li>data = [[0,0, 1.0, 3.0, …],[2.0, 3.0, 0.0, …], …,[4.0, 5.0, 3.0, …]]为各个博客在单词表中各个单词出现的次数的表。</li>
</ul>
<p>很容易想到用树结构来表示聚类这样的结构关系。分级聚类算法中的每一个聚类，可以是树中的枝节点，也可以是与数据集中实际数据行相对应的叶节点。没一个聚类还包含了指示器位置的信息，这一信息可以是来自叶节点的行数据，也可以是来自枝节点的经合并后的数据。我们可以新建一个 bicluster 类，将所有这些属性存放其中，并以此来描述这棵层级树。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">bicluster</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vec, left = None, right = None, distance = <span class="number">0.0</span>, id = None)</span>:</span></div><div class="line">        self.left = left</div><div class="line">        self.right = right</div><div class="line">        self.vec = vec</div><div class="line">        self.id = id</div><div class="line">        self.distance = distance</div></pre></td></tr></table></figure>
<p>分级聚类算法以一组对应于原始数据项的聚类开始。函数的主循环部分会尝试每一组可能的配对并计算它们的相关度，以此来找出最佳配对。最佳配对的两个聚类会被合并成一个新的聚类。新生成的聚类中所包含的数据，等于将两个旧聚类的数据求均值之后得到的结果。这一过程会一直重复下去，知道只剩下一个聚类为止。由于整个计算过程可能会非常耗时，我们需要将每个配对的相关度计算结果保存起来以便优化执行速度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">hcluster</span><span class="params">(rows, distance = pearson)</span>:</span></div><div class="line">    distances = &#123;&#125;</div><div class="line">    currentclustid = <span class="number">-1</span></div><div class="line">    <span class="comment"># 最开始的聚类就是数据集中的行</span></div><div class="line">    clust = [bicluster(rows[i], id = i) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(rows))]</div><div class="line"></div><div class="line">    <span class="keyword">while</span> len(clust) &gt; <span class="number">1</span>:</div><div class="line">        lowestpair = (<span class="number">0</span>, <span class="number">1</span>)</div><div class="line">        closest = distance(clust[<span class="number">0</span>].vec, clust[<span class="number">1</span>].vec)</div><div class="line">        <span class="comment"># 遍历每一个配对，寻找最小距离</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(clust)):</div><div class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>, len(clust)):</div><div class="line">                <span class="comment"># 用 distances 来缓存距离的计算值</span></div><div class="line">                <span class="keyword">if</span> (clust[i].id, clust[j].id) <span class="keyword">not</span> <span class="keyword">in</span> distances:</div><div class="line">                    distances[(clust[i].id, clust[j].id)] = distance(clust[i].vec, clust[j].vec)</div><div class="line">                d = distances[(clust[i].id, clust[j].id)]</div><div class="line">                <span class="keyword">if</span> d &lt; closest:</div><div class="line">                    closest = d</div><div class="line">                    lowestpair = (i, j)</div><div class="line">        <span class="comment"># 计算两个聚类的平均值</span></div><div class="line">        mergevec = [(clust[lowestpair[<span class="number">0</span>]].vec[i] + clust[lowestpair[<span class="number">1</span>]].vec[i])/<span class="number">2.0</span></div><div class="line">                    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(clust[<span class="number">0</span>].vec))]</div><div class="line">        <span class="comment"># 建立新的聚类，聚类后的新聚类的 vec 更新为两个原先聚类的均值</span></div><div class="line">        newcluster = bicluster(mergevec, left = clust[lowestpair[<span class="number">0</span>]],</div><div class="line">                               right = clust[lowestpair[<span class="number">1</span>]],</div><div class="line">                               distance = closest, id = currentclustid)</div><div class="line">        <span class="comment"># 去除原先的两个初始聚类，将新聚类添加至 clust，然后递归重复过程</span></div><div class="line">        currentclustid -= <span class="number">1</span></div><div class="line">        <span class="keyword">del</span> clust[lowestpair[<span class="number">1</span>]]</div><div class="line">        <span class="keyword">del</span> clust[lowestpair[<span class="number">0</span>]]</div><div class="line">        clust.append(newcluster)</div><div class="line"></div><div class="line">    <span class="keyword">return</span> clust[<span class="number">0</span>]</div></pre></td></tr></table></figure>
<p>其中 distance = pearson 表示的是采用皮尔逊相关系数来度量变量之间的距离，也可以构造其他距离度量函数（比如曼哈顿距离或者欧式距离）。</p>
<p>接下来就是直观地展现最终的聚类结果，就是绘制树状图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageDraw</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getheight</span><span class="params">(clust)</span>:</span></div><div class="line">    <span class="keyword">if</span> clust.left == <span class="keyword">None</span> <span class="keyword">and</span> clust.right == <span class="keyword">None</span>:  <span class="keyword">return</span> <span class="number">1</span></div><div class="line">    <span class="keyword">return</span>  getheight(clust.left) + getheight(clust.right)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getdepth</span><span class="params">(clust)</span>:</span></div><div class="line">    <span class="keyword">if</span> clust.left == <span class="keyword">None</span> <span class="keyword">and</span> clust.right == <span class="keyword">None</span>:  <span class="keyword">return</span> <span class="number">0</span></div><div class="line">    <span class="keyword">return</span> max(getdepth(clust.left), getdepth(clust.right)) + clust.distance</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">drawdendrogram</span><span class="params">(clust, labels, jpeg = <span class="string">'clusters.jpg'</span>)</span>:</span></div><div class="line">    h = getheight(clust)*<span class="number">20</span></div><div class="line">    w = <span class="number">1200</span></div><div class="line">    depth = getdepth(clust)</div><div class="line"></div><div class="line">    scaling = float(w - <span class="number">150</span>)/depth</div><div class="line"></div><div class="line">    img = Image.new(<span class="string">'RGB'</span>, (w, h), (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>))</div><div class="line">    draw = ImageDraw.Draw(img)</div><div class="line"></div><div class="line">    draw.line((<span class="number">0</span>, h/<span class="number">2</span>, <span class="number">10</span>, h/<span class="number">2</span>), fill = (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>))</div><div class="line"></div><div class="line">    drawnode(draw, clust, <span class="number">10</span>, (h/<span class="number">2</span>), scaling, labels)</div><div class="line">    img.save(jpeg, <span class="string">'JPEG'</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">drawnode</span><span class="params">(draw, clust, x, y, scaling, labels)</span>:</span></div><div class="line">    <span class="keyword">if</span> clust.id &lt; <span class="number">0</span>:</div><div class="line">        h1 = getheight(clust.left)*<span class="number">20</span></div><div class="line">        h2 = getheight(clust.right)*<span class="number">20</span></div><div class="line">        top = y - (h1 + h2)/<span class="number">2</span></div><div class="line">        bottom = y + (h1 + h2)/<span class="number">2</span></div><div class="line"></div><div class="line">        l1 = clust.distance * scaling</div><div class="line"></div><div class="line">        draw.line((x, top + h1/<span class="number">2</span>, x, bottom - h2/<span class="number">2</span>), fill = (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>))</div><div class="line">        draw.line((x, top + h1/<span class="number">2</span>, x + l1, top + h1/<span class="number">2</span>), fill = (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>))</div><div class="line">        draw.line((x, bottom - h2/<span class="number">2</span>, x + l1, bottom - h2/<span class="number">2</span>), fill = (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>))</div><div class="line"></div><div class="line">        drawnode(draw, clust.left, x + l1, top + h1/<span class="number">2</span>, scaling, labels)</div><div class="line">        drawnode(draw, clust.right, x + l1, bottom - h2/<span class="number">2</span>, scaling, labels)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        draw.text((x + <span class="number">5</span>, y - <span class="number">7</span>), labels[clust.id], (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>))</div></pre></td></tr></table></figure>
<p>输入以下命令，就可以看到最终的博客聚类情况的树状图：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; import clusters</div><div class="line">&gt;&gt;&gt; words, blognames, data = clusters.readfile(<span class="string">'blogdata.txt'</span>)</div><div class="line">&gt;&gt;&gt; clust = clusters.hcluster(data)</div><div class="line">&gt;&gt;&gt; clusters.drawdendrogram(clust, blogname, jpeg = <span class="string">'blogclust'</span>.jpg)</div></pre></td></tr></table></figure></p>
<hr>
<h2 id="K- 均值聚类："><a href="#K- 均值聚类：" class="headerlink" title="$K$- 均值聚类："></a>$K$- 均值聚类：</h2><p>分级聚类有个缺点就是，我们必须计算每两个配对项之间的关系，并且在合并项之后，这些关系还需要重新计算，所以在处理很大规模的数据集时，分级聚类算法的运行速度会非常缓慢。</p>
<p>而 $K$- 均值聚类，完全不同于分级聚类，因为我们会预先告诉算法希望生成的聚类数量，然后算法会根据数据的结构状况来确定聚类的大小。</p>
<p>$K$- 均值聚类算法首先会随机确定 $k$ 个中心位置（位于空间中代表聚类中心的点），然后将各个数据项分配给最临近的中心点。待分配完成之后，聚类中心就会移到分配给该聚类的所有节点的平均位置处，然后整个分配过程重新开始。这一过程会一直重复下去，直到分配过程不再产生变化为止。</p>
<p><img src="https://farm1.staticflickr.com/380/31521742461_dcb281b151_o.png" alt=""></p>
<p>实现 $K$- 均值聚类算法的函数与分级聚类算法的一样，接受相同的数据行作为输入，此外它还接受一个调用者期望返回的聚类数（$k$）作为参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">kcluster</span><span class="params">(rows, distance = pearson, k = <span class="number">4</span>)</span>:</span></div><div class="line">    <span class="comment"># 确定每个点的最小值和最大值</span></div><div class="line">    ranges = [(min([row[i] <span class="keyword">for</span> row <span class="keyword">in</span> rows]), max([row[i] <span class="keyword">for</span> row <span class="keyword">in</span> rows]))</div><div class="line">              <span class="keyword">for</span> i <span class="keyword">in</span> range(len(rows[<span class="number">0</span>]))]</div><div class="line">    </div><div class="line">    <span class="comment"># 随机创建 k 个中心点</span></div><div class="line">    clusters = [[random.random()*(ranges[i][<span class="number">1</span>] - ranges[i][<span class="number">0</span>]) + ranges[i][<span class="number">0</span>]</div><div class="line">                 <span class="keyword">for</span> i <span class="keyword">in</span> range(len(rows[<span class="number">0</span>]))] <span class="keyword">for</span> j <span class="keyword">in</span> range(k)]</div><div class="line">    lastmatches = <span class="keyword">None</span></div><div class="line"></div><div class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">100</span>):</div><div class="line">        print(<span class="string">'Iteration %d'</span> % t)</div><div class="line">        bestmatches = [[] <span class="keyword">for</span> i <span class="keyword">in</span> range(k)]</div><div class="line"></div><div class="line">        <span class="comment"># 在每一行中寻找距离最近的中心点</span></div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(rows)):</div><div class="line">            row = rows[j]</div><div class="line">            bestmatch = <span class="number">0</span></div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</div><div class="line">                d = distance(clusters[i], row)</div><div class="line">                <span class="keyword">if</span> d &lt; distance(clusters[bestmatch], row):</div><div class="line">                    bestmatch = i</div><div class="line">            bestmatches[bestmatch].append(j)</div><div class="line"></div><div class="line">        <span class="comment"># 如果结果与上一次相同，则整个过程结束</span></div><div class="line">        <span class="keyword">if</span> bestmatches == lastmatches:  <span class="keyword">break</span></div><div class="line">        lastmatches = bestmatches</div><div class="line"> </div><div class="line">        <span class="comment"># 把中心点移到其所有成员的平均位置处</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</div><div class="line">            avgs = [<span class="number">0.0</span>]*len(rows[<span class="number">0</span>])</div><div class="line">            <span class="keyword">if</span> len(bestmatches[i]) &gt; <span class="number">0</span>:</div><div class="line">                <span class="keyword">for</span> rowid <span class="keyword">in</span> bestmatches[i]:</div><div class="line">                    <span class="keyword">for</span> m <span class="keyword">in</span> range(len(rows[rowid])):</div><div class="line">                        avgs[m] += rows[rowid][m]</div><div class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> range(len(avgs)):</div><div class="line">                    avgs[j] /= len(bestmatches[i])</div><div class="line">                clusters[i] = avgs</div><div class="line"></div><div class="line">    <span class="keyword">return</span> bestmatches</div></pre></td></tr></table></figure>
<p>上述代码在每个变量的值域范围内随机构造了一组聚类。当每次迭代进行的时候，算法会将每一行数据分配给某个中心点，然后再将中心点的数据更新为分配给它的所有项的平均位置。当分配情况与前一次相同的时候，迭代过程就结束了，同时算法会返回 k 组序列，其中每个序列代表一个聚类。与分级聚类相比，该算法为产生最终结果所须迭代的次数是非常少的。</p>
<p><strong>由于函数选用随机的中心点作为开始，所以返回结果的顺序几乎总是不同的。根据中心点初始位置的不同，最终聚类中所包含的内容也可能会有所不同。</strong></p>
<p>我们可以针对博客数据集试验一下该函数。算法的执行速度应该会比分级聚类更快一些：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> clusters</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>words, blognames, data = clusters.readfile(<span class="string">'blogdata.txt'</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>kclust = clusters.kcluster(data, k = <span class="number">10</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>[blognames[r] <span class="keyword">for</span> r <span class="keyword">in</span> kclust[<span class="number">0</span>]]</div><div class="line">[<span class="string">'Online Marketing Report'</span>, <span class="string">"Sifry's Alerts"</span>, <span class="string">'Treehugger'</span>, <span class="string">'Oilman'</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>[blognames[r] <span class="keyword">for</span> r <span class="keyword">in</span> kclust[<span class="number">1</span>]]</div><div class="line">[<span class="string">'Mashable!'</span>, <span class="string">'Signum sine tinnitu--by Guy Kawasaki'</span>, <span class="string">'TechCrunch'</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>[blognames[r] <span class="keyword">for</span> r <span class="keyword">in</span> kclust[<span class="number">2</span>]]</div><div class="line">[<span class="string">"The Superficial - Because You're Ugly"</span>, <span class="string">'Wonkette'</span>, <span class="string">'Eschaton'</span>, <span class="string">'we make money not art'</span>, <span class="string">'Joho the Blog'</span>, <span class="string">"Neil Gaiman's Journal"</span>, <span class="string">'Signal vs. Noise'</span>, <span class="string">'lifehack.org'</span>, <span class="string">'Kotaku'</span>, <span class="string">'Daily Kos'</span>, <span class="string">'Deadspin'</span>, <span class="string">'Go Fug Yourself'</span>, <span class="string">'Gizmodo'</span>, <span class="string">'Gothamist'</span>, <span class="string">'The Viral Garden'</span>, <span class="string">'SpikedHumor'</span>, <span class="string">'flagrantdisregard'</span>, <span class="string">'Techdirt'</span>, <span class="string">'Schneier on Security'</span>, <span class="string">'Scobleizer - Tech Geek Blogger'</span>, <span class="string">'Little Green Footballs'</span>, <span class="string">"Dave Shea's mezzoblue"</span>, <span class="string">'kottke.org'</span>, <span class="string">'MetaFilter'</span>, <span class="string">'ongoing'</span>, <span class="string">'Instapundit.com'</span>, <span class="string">"Joi Ito's Web"</span>, <span class="string">'Joel on Software'</span>, <span class="string">'PerezHilton.com'</span>, <span class="string">'Derek Powazek'</span>, <span class="string">"Jeremy Zawodny's blog"</span>, <span class="string">'plasticbag.org'</span>, <span class="string">'Gawker'</span>, <span class="string">'WWdN: In Exile'</span>, <span class="string">"Seth's Blog"</span>, <span class="string">'The Huffington Post | Raw Feed'</span>]</div></pre></td></tr></table></figure></p>
<p>现在，kclust 中应该包含了一组代表聚类的 ID 序列。<br>kclust 应该是一个这样的东西：</p>
<script type="math/tex; mode=display">
[[rowid_1,rowid_2,…,rowid_n]_{(聚类_1)} ,[rowid_1,rowid_2,...,rowid_n]_{(聚类_2)} ,...,[rowid_1,rowid_2,...,rowid_n]_{(聚类_k)}]</script><p>$K$- 均值聚类的最佳特质就是各簇在本质上呈紧致的球状分布，且总会收敛到某个解：<br><img src="https://farm1.staticflickr.com/732/31600482456_67bececb29_o.png" alt=""></p>
<p>$K$- 均值聚类中的距离度量方式除了上述的皮尔逊相关系数，针对具体任务（不同的数据集）可以采用不同的距离度量方式。<strong>但是 $K$- 均值聚类算法的缺陷是各簇之间必须存在一个“硬”边界，这意味着每个数据点只能属于一个簇，无法跨越两个簇之间的界限。此外，$K$- 均值聚类算法适合于呈球状分布的数据，因为大多数情况下人们采用的都是欧式距离。在像上述图中这样的数据分布（位于中间的那些点实际上可以属于两个簇的任意一个），这些缺陷非常明显。</strong></p>
<hr>
<h2 id="针对偏好的聚类："><a href="# 针对偏好的聚类：" class="headerlink" title="针对偏好的聚类："></a>针对偏好的聚类：</h2><p>直接使用 <strong>zebo.txt</strong> 数据集，虽然书上的网站无法访问导致我们无法构建数据集。但是其中使用 BeautifulSoup 这一函数库，以及其中对于网页内容的处理，我们可以学习一下代码。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> BeautifulSoup <span class="keyword">import</span> BeautifulSoup</div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"><span class="keyword">import</span> re</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">fuck</span><span class="params">()</span>:</span></div><div class="line">    chare = re.compile(<span class="string">r'[!-\.&amp;]'</span>)</div><div class="line">    itemowners = &#123;&#125;</div><div class="line"></div><div class="line">    <span class="comment"># 想要去除的单词</span></div><div class="line">    dropwords = [<span class="string">'a'</span>, <span class="string">'new'</span>, <span class="string">'some'</span>, <span class="string">'more'</span>, <span class="string">'my'</span>, <span class="string">'own'</span>, <span class="string">'the'</span>, <span class="string">'many'</span>, <span class="string">'other'</span>, <span class="string">'another'</span>]</div><div class="line"></div><div class="line">    currentuser = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">51</span>):</div><div class="line">        <span class="comment"># 搜索想要的对应 URL</span></div><div class="line">        c = urllib2.urlopen(</div><div class="line">            <span class="string">'http://member.zebo.com/Main?event_key=USERSEARCH&amp;wiowiw=wiw&amp;keyword=car&amp;page=%d'</span></div><div class="line">            % (i))</div><div class="line">        soup = BeautifulSoup(c.read())</div><div class="line">        <span class="keyword">for</span> td <span class="keyword">in</span> soup(<span class="string">'td'</span>):</div><div class="line">            <span class="comment"># 寻找带有 bgverdanasmall 类的表格单元格</span></div><div class="line">            <span class="keyword">if</span> (<span class="string">'class'</span> <span class="keyword">in</span> dict(td.attrs) <span class="keyword">and</span> td[<span class="string">'class'</span>] == <span class="string">'bgverdanasmall'</span>):</div><div class="line">                items = [re.sub(chare, <span class="string">''</span>, str(a.contents[<span class="number">0</span>]).lower()).strip() <span class="keyword">for</span> a <span class="keyword">in</span> td(<span class="string">'a'</span>)]</div><div class="line">                <span class="keyword">for</span> item <span class="keyword">in</span> items:</div><div class="line">                    <span class="comment"># 去除多余的单词</span></div><div class="line">                    txt = <span class="string">' '</span>.join([t <span class="keyword">for</span> t <span class="keyword">in</span> item.split(<span class="string">' '</span>) <span class="keyword">if</span> t <span class="keyword">not</span> <span class="keyword">in</span> dropwords])</div><div class="line">                    <span class="keyword">if</span> len(txt) &lt; <span class="number">2</span>: <span class="keyword">continue</span></div><div class="line">                    itemowners.setdefault(txt, &#123;&#125;)</div><div class="line">                    itemowners[txt][currentuser] = <span class="number">1</span></div><div class="line">                currentuser += <span class="number">1</span></div><div class="line"></div><div class="line">    out = file(<span class="string">'zebo.txt'</span>, <span class="string">'w'</span>)</div><div class="line">    out.write(<span class="string">'Item'</span>)</div><div class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> range(<span class="number">0</span>, currentuser): out.write(<span class="string">'\tU%d'</span> % user)</div><div class="line">    out.write(<span class="string">'\n'</span>)</div><div class="line">    <span class="keyword">for</span> item, owners <span class="keyword">in</span> itemowners.items():</div><div class="line">        <span class="comment"># 寻找超过 10 个人都希望拥有的物品</span></div><div class="line">        <span class="keyword">if</span> len(owners) &gt; <span class="number">10</span>:</div><div class="line">            out.write(item)</div><div class="line">            <span class="keyword">for</span> user <span class="keyword">in</span> range(<span class="number">0</span>, currentuser):</div><div class="line">                <span class="keyword">if</span> user <span class="keyword">in</span> owners:</div><div class="line">                    out.write(<span class="string">'\t1'</span>)</div><div class="line">                <span class="keyword">else</span>:</div><div class="line">                    out.write(<span class="string">'\t0'</span>)</div><div class="line">            out.write(<span class="string">'\n'</span>)</div><div class="line">            </div><div class="line">fuck()</div></pre></td></tr></table></figure></p>
<ul>
<li>其中 <strong>range(1, 51)</strong> 表示我们会处理其中的前五十个页面，当然我们也可以自定义。</li>
<li>由于所有的物品的文字都是随意输入的，所以需要进行大量的处理工作，其中包括去除像 <strong>dropwords</strong> 中“a”、“some”、“new”等这样的单词，去除 <strong>chare</strong> 标点符号，以及将所有文本转换成小写。</li>
</ul>
<p>在 <strong>zebo.txt</strong> 文件当中，如果一个人希望拥有某件物品，那么我们将其标记为 1，否则就标记为 0。皮尔逊相关度很适合于博客数据集，改数据集中所包含的是单词的实际统计值。而在此处，数据集只有 1 和 0 两种取值，分别代表着有或无。并且，假如我们对同时希望拥有两件物品的人在物品方面互有重叠的情况进行度量，那或许是一件更有意义上的事情。</p>
<p>为此，我们采用一种被称为 <strong>Tanimoto 系数</strong> 的度量方法，它代表的是交集（只包含那些在两个集合中都出现的项）与并集（包含所有出现于任一集合中的项）的比率。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">tanimoto</span><span class="params">(v1, v2)</span>:</span></div><div class="line">    c1, c2, shr = <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span></div><div class="line"></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(v1)):</div><div class="line">        <span class="keyword">if</span> v1[i] != <span class="number">0</span>:  c1 += <span class="number">1</span></div><div class="line">        <span class="keyword">if</span> v2[i] != <span class="number">0</span>:  c2 += <span class="number">1</span></div><div class="line">        <span class="keyword">if</span> v1[i] != <span class="number">0</span> <span class="keyword">and</span> v2[i] != <span class="number">0</span>:   shr += <span class="number">1</span></div><div class="line"></div><div class="line">    <span class="keyword">return</span> <span class="number">1.0</span> - (float(shr)/(c1 + c2 - shr))</div></pre></td></tr></table></figure>
<p>上述代码将返回一个介于 1.0 和 0.0 之间的值。其中 1.0 代表不存在同时喜欢两件物品的人，而 0.0 则代表所有人都同时喜欢两个向量中的物品。</p>
<p>因为数据的格式与先前所用的相同，所以我们可以利用同样的函数来生成和绘制分级聚类。利用上面的函数并相应传入两个向量，我们很容易就可以实现聚类的功能。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> clusters</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>users, items, data = clusters.readfile(<span class="string">'zebo.txt'</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>clust = clusters.hcluster(data)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>clust = clusters.hcluster(data, distance = clusters.tanimoto)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>clusters.drawdendrogram(clust, items, jpeg = <span class="string">'itemsclusters.jpg'</span>)</div></pre></td></tr></table></figure></p>
<hr>
<h2 id="多维缩放："><a href="# 多维缩放：" class="headerlink" title="多维缩放："></a>多维缩放：</h2><p>由于在大多数真是生活的例子中，我们所要聚类的内容都不只包含两个数值，所以我们不可能按照前面的方法来采集数据并以二维的形式将其绘制出来。但是为了要弄明白物品之间的关系，将它们绘制在一个二维的平面上，两两之间的距离远近表达的是两者之间的相似程度。而 <strong> 多维缩放 </strong> 目的就是根据每对数据项之间的相似情况，将其表现在一个二维平面上。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">scaledown</span><span class="params">(data, distance = pearson, rate = <span class="number">0.01</span>)</span> :</span></div><div class="line">    n = len(data)</div><div class="line"></div><div class="line">    <span class="comment"># 每一对数据项之间的真实距离</span></div><div class="line">    realdist = [[distance(data[i], data[j]) <span class="keyword">for</span> j <span class="keyword">in</span> range(n)]</div><div class="line">                 <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, n)]</div><div class="line"></div><div class="line">    <span class="comment"># 随机初始化节点在二维空间中的初始位置</span></div><div class="line">    loc = [[random.random(), random.random()] <span class="keyword">for</span> i <span class="keyword">in</span> range(n)]</div><div class="line">    fakedist = [[<span class="number">0.0</span> <span class="keyword">for</span> j <span class="keyword">in</span> range(n)] <span class="keyword">for</span> i <span class="keyword">in</span> range(n)]</div><div class="line"></div><div class="line">    lasterror = <span class="keyword">None</span></div><div class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">1000</span>) :</div><div class="line">        <span class="comment"># 寻找投影后的距离</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</div><div class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</div><div class="line">                fakedist[i][j] = sqrt(sum([pow(loc[i][x] - loc[j][x], <span class="number">2</span>)</div><div class="line">                                                <span class="keyword">for</span> x <span class="keyword">in</span> range(len(loc[i]))]))</div><div class="line"></div><div class="line">        <span class="comment"># 移动节点</span></div><div class="line">        grad = [[<span class="number">0.0</span>, <span class="number">0.0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> range(n)]</div><div class="line"></div><div class="line">        totalerror = <span class="number">0</span></div><div class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(n):</div><div class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</div><div class="line">                <span class="keyword">if</span> j == k: <span class="keyword">continue</span></div><div class="line">                <span class="comment"># 误差值等于目标距离与当前距离之间差值的百分比</span></div><div class="line">                errorterm = (fakedist[j][k] - realdist[j][k]) / realdist[j][k]</div><div class="line"></div><div class="line">                <span class="comment"># 每个节点都需要根据误差的多少，按照比例移离或者移向其他节点</span></div><div class="line">                <span class="comment"># point in proportion to how much error it has</span></div><div class="line">                grad[k][<span class="number">0</span>] += ((loc[k][<span class="number">0</span>] - loc[j][<span class="number">0</span>]) / fakedist[j][k]) * errorterm</div><div class="line">                grad[k][<span class="number">1</span>] += ((loc[k][<span class="number">1</span>] - loc[j][<span class="number">1</span>]) / fakedist[j][k]) * errorterm</div><div class="line"></div><div class="line">                <span class="comment"># 记录总的误差值</span></div><div class="line">                totalerror += abs(errorterm)</div><div class="line">        <span class="keyword">print</span> totalerror</div><div class="line"></div><div class="line">        <span class="comment"># 如果节点移动之后的情况变得更糟，则 break 程序结束</span></div><div class="line">        <span class="keyword">if</span> lasterror <span class="keyword">and</span> lasterror &lt; totalerror: <span class="keyword">break</span></div><div class="line">        lasterror = totalerror</div><div class="line"></div><div class="line">        <span class="comment"># 根据 rate 参数与 grad 值相乘的结果，移动每一个节点</span></div><div class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(n):</div><div class="line">            loc[k][<span class="number">0</span>] -= rate * grad[k][<span class="number">0</span>]</div><div class="line">            loc[k][<span class="number">1</span>] -= rate * grad[k][<span class="number">1</span>]</div><div class="line"></div><div class="line">    <span class="keyword">return</span> loc</div></pre></td></tr></table></figure>
<p>根据 scaledown()函数得到的 loc，我们可以利用 PIL 在生成一张二维图，根据新的坐标值 loc，在图上标出所有数据项的位置以及对应的标签。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw2d</span><span class="params">(data, labels, jpeg=<span class="string">'mds2d.jpg'</span>)</span>:</span></div><div class="line">    img = Image.new(<span class="string">'RGB'</span>, (<span class="number">2000</span>, <span class="number">2000</span>), (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>))</div><div class="line">    draw = ImageDraw.Draw(img)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</div><div class="line">        x = (data[i][<span class="number">0</span>] + <span class="number">0.5</span>)*<span class="number">1000</span></div><div class="line">        y = (data[i][<span class="number">1</span>] + <span class="number">0.5</span>)*<span class="number">1000</span></div><div class="line">        draw.text((x, y), labels[i], (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>))</div><div class="line">    img.save(jpeg, <span class="string">'JPEG'</span>)</div></pre></td></tr></table></figure></p>
<p>在命令行中输入：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> clusters</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>words, blognames, data = clusters.readfile(<span class="string">'blogname.txt'</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>coords = clusters.scaledown(data)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>clusters.draw2d(coords, blognames, jpeg = <span class="string">'blogs2d.jpg'</span>)</div></pre></td></tr></table></figure></p>
<p>得到的 <strong>blog2d.jpg</strong> 反映就是博客数据集中 blog 之间的相似关系，当然我们也可以通过 rotatematrix()函数来转置矩阵 data，得到 rdata，再根据 rdata 画出单词表中的单词的相似度（误差有点大）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> clusters</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>words, blognames, data = clusters.readfile(<span class="string">'blogname.txt'</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>rdata = clusters.rotatematrix(data)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>coords = clusters.scaledown(rdata)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>clusters.draw2d(coords, words, jpeg = <span class="string">'words2d.jpg'</span>)</div></pre></td></tr></table></figure></p>
<p>既可以得到单词之间的相似关系<strong>words2d.jpg</strong>。</p>
<p>同样，我们可以将其用于我们的欲望物品数据集，距离度量使用 <strong>tanimoto 系数</strong>，但是要修改<strong>tanimoto()</strong> 与<strong>scaledown()</strong>几处代码，即需要判断分母为 0 的时候的返回值。修改完之后，调用 scaledown()与 draw2d()，画出欲望物品之间的相似关系图<strong>items2d.jpg</strong>。（同样也可以通过转置 data 矩阵，画出用户之间的相似关系图<strong>users2d.jpg</strong>）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> clusters</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>users, items, data = clusters.readfile(<span class="string">'zebo.txt'</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>coords = clusters.scaledown(rdata, distance = tanimoto)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>clusters.draw2d(coords, items, jpeg = <span class="string">'items2d.jpg'</span>)</div></pre></td></tr></table></figure></p>
<p>当然，我们还可以根据需要修改 <strong>rate</strong> 等诸多参数的值来调整算法，在此不再赘述。</p>
<hr>
<h2 id="EM 聚类："><a href="#EM 聚类：" class="headerlink" title="EM 聚类："></a>EM 聚类：</h2><p>EM 聚类算法的重点不是像 K- 均值聚类那样找到一个质心，然后找到与其相关的数据点，而是求解另一个不同的问题。比如我们希望一个数据集分为两部分：簇 1 与簇 2。<strong>EM 聚类算法的目的是，我们希望得到一个关于数据是否存在某个簇中的良好估计，但并不用关心其中是否存在模糊性。我们真正希望获得的是一个数据点属于各簇的概率值，而非分配结果。</strong></p>
<p>与专注于确定各簇之间边界的 $K$- 均值聚类算法不同，EM 聚类对于可能同属于多个簇的数据点具有一定的稳健性。EM 聚类算法非常适用于对不存在明确边界的数据进行分类。</p>
<hr>
<h1 id="orrect-errors-in-printing"><a href="#orrect-errors-in-printing" class="headerlink" title="orrect errors in printing:"></a>orrect errors in printing:</h1><ul>
<li>P46</li>
</ul>
<blockquote>
<pre><code>... 代码首先会构造一个列表，其中包含的是超过 5 个人都希望拥有的物品....
</code></pre><p>  需要更正为：</p>
<pre><code>... 代码首先会构造一个列表，其中包含的是超过 10 个人都希望拥有的物品....
</code></pre></blockquote>
]]></content>
    
    <summary type="html">
    
      本文是关于「Programming Collective Intelligence」这本书的 Chapter 3的学习笔记。
    
    </summary>
    
      <category term="Machine Learning" scheme="http://randolph.pro/categories/Machine-Learning/"/>
    
      <category term="Book:「Programming Collective Intelligence」" scheme="http://randolph.pro/categories/Machine-Learning/Book-%E3%80%8CProgramming-Collective-Intelligence%E3%80%8D/"/>
    
    
      <category term="Python" scheme="http://randolph.pro/tags/Python/"/>
    
      <category term="Machine Learning" scheme="http://randolph.pro/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>♞「Programming Collective Intelligence」 Chapter 1 &amp; 2</title>
    <link href="http://randolph.pro/2016/03/12/%3CProgramming%20Collective%20Intelligence%3E%20Chapter%201%20&amp;%202/"/>
    <id>http://randolph.pro/2016/03/12/&lt;Programming Collective Intelligence&gt; Chapter 1 &amp; 2/</id>
    <published>2016-03-11T16:00:00.000Z</published>
    <updated>2017-07-25T13:23:55.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fhu94m6p9zj30t612ah7b.jpg" alt=""></p>
<p>关于该书的其他学习笔记系列：<a href="http://randolph.pro/categories/Machine-Learning/Book-「Programming-Collective-Intelligence」/">「Programming Collective Intelligence」</a></p>
<h1 id="Related"><a href="#Related" class="headerlink" title="Related"></a>Related</h1><ul>
<li>欧几里得距离评价</li>
<li>皮尔逊相关度评价</li>
</ul>
<blockquote>
<ul>
<li>The formula for this is more complicated than the Euclidean distance score, but it tends to give better results in situations where the data isn’t well normalized—for example, if critics’ movie rankings are routinely more harsh than average. 它相比于欧几里德距离评价更加复杂，但其在数据不是很规范的时候（比如，影评者对影片的评价总是相对于平均水平偏离很大的时候），会给出更好的结果。      </li>
<li>If one critic is inclined to give higher scores than the other, there can still be perfect correlation if the difference between their scores is consistent. The Euclidean distance score described earlier will say that two critics are dissimilar because one is consistently harsher than the other, even if their tastes are very similar. 如果某人总是倾向于给出比另一个人更高的分值，而两者的分值之差又始终保持一致，则他们依然可能会存在很好的相关性。而欧几里德距离评价会因为一个人的评价之中比另外一个人的更为“严格”（从而导致评价始终相对偏低），从而得出两者不相近的结论，即使他们的品位很相似也是如此。</li>
</ul>
</blockquote>
<ul>
<li>其他相似度计算函数（Minkowski 距离、Mahalanobis 距离等）</li>
</ul>
<hr>
<h1 id="Key"><a href="#Key" class="headerlink" title="Key:"></a>Key:</h1><p>在「推荐物品」的模块中，提到了一种方法：</p>
<ol>
<li>通过函数找出与自己有相似品味的影评者，并按相似度从大到小排序。</li>
<li>对于自己未看过的影片，建立一张表，表的内容包括：品位相似的影评者以及其对应的相似度，对于自己未看过影片的评分（影评者可以看过也可以没有看过）。</li>
<li>对于某一个未看过的电影，影评者的相似度（可理解为权值，不同评论者的权值不同，相似度越高，权值越高）乘以其对该电影的评分，其他影评者也得到一个值（如果没有看过，则为零），然后累加，记为其他影评者对于该电影者的评价总和，之后总和需要除以所有对该电影评过分的影评者的相似度之和。</li>
<li>最后得到的结果，表示为自己对于没有看过的电影，通过自己品位相似的影评者得到的预测评分，根据预测评分，来给出决策。</li>
</ol>
<hr>
<h1 id="Need-to-know"><a href="#Need-to-know" class="headerlink" title="Need to know:"></a>Need to know:</h1><p>在「构建一个基于 del.icio.us 的链接推荐系统」的模块中：<br>首先我们需要下载 <strong>pydelicious</strong> 这一个 package。<strong>［这个 package 不支持 python3.x］</strong></p>
<p>我的尝试：</p>
<ol>
<li>通过 Pycharm 自带的“便利”package 下载。出错，原因：无法找到对应的版本。</li>
<li>通过命令行输入<code>sudo pip install pydelicious</code>。出错，原因：Could not find a version that satisfies the requirement pydelicious (from versions:)No matching distribution found for pydelicious。</li>
<li>通过命令行输入<code>sudo pip install pydelicious --allow-external pydelicious --allow-unverified pydelicious</code>。出错，原因：Could not find a version that satisfies the requirement pydelicious (from versions:)No matching distribution found for pydelicious。</li>
</ol>
<hr>
<p>初次尝试失败之后，在 Stackoverflow 寻找解决办法：</p>
<ol>
<li>首先，按照书本提供的下载地址：<a href="https://code.google.com/archive/p/pydelicious/downloads" target="_blank" rel="external">the pydelicious download page</a>［需要翻墙］下载 <strong>pydelicious-0.5.0.zip</strong> 文件。解压之后得到文件夹。</li>
<li>命令行 cd 到解压后的文件夹，然后输入 <code>sudo python setup.py install</code>，错误提示：Feedparser not available, no RSS parsing。<strong> 意思是缺少 feedparser 这一 package 依赖库，需要安装 feedparser</strong>。</li>
<li>安装 feedparser, 下载地址：<a href="http://download.csdn.net/download/dixin28/5271130" target="_blank" rel="external">the feedparser download page</a>［需要积分］，或者<a href="https://github.com/kurtmckee/feedparser" target="_blank" rel="external">the feedparser download page</a>［需要翻墙］，下载文件夹。</li>
<li>命令行 cd 到 feedparser 的文件夹，然后输入<code>sudo python setup.py install</code>，feedparser 安装完成。</li>
<li>命令行 cd 回到 pydelicious 文件夹，再次输入<code>sudo python setup.py install</code>，此时会发现 pydelicious 安装成功。</li>
<li>测试 pydelicious 此 package 是否能够导入，命令行输入 python 之后，再输入<code>import pydelicious</code>，如果没有报错，这说明 pydelicious 安装成功。</li>
</ol>
<ul>
<li>2016.11.28 补充：如果按照书本上下载的 pydelicious-0.5.0 版本，是可以正常运行书本上的代码的而不报错的，但是会出现无论我如何修改 tag 的值，返回的内容都是一样的，原因在后面解释了。但是如果我们下载的是<a href="https://github.com/dotmpe/python-delicious" target="_blank" rel="external">github 上更新后的 pydelicious 版本</a>，会遇到如下问题，解决办法是需要修改__init__.py 文件中的几处代码，但是仍然会出现 tag 值的问题。</li>
</ul>
<hr>
<p>本以为问题得到了解决，可以按照书上的代码继续进行:</p>
<p>命令行输入 python:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; import pydelicious</div><div class="line">&gt;&gt;&gt; pydelicious.get_popular(tag=<span class="string">'python'</span>)</div></pre></td></tr></table></figure></p>
<p>此时会报错，无论是否翻墙，显示获取失败。</p>
<hr>
<p>我在 stackoverflow.com 上找到了原因：<a href="http://stackoverflow.com/questions/29543799/pydelicious-get-popularprogramming-doesnt-return-any-valid-url" target="_blank" rel="external">the answer</a><strong>［需要翻墙］</strong><br>仔细看提问者的问题，重点是后面提出解决办法的几个回答。</p>
<blockquote>
<p><strong>You should modify the __init__.py to:rss =http_request(‘<a href="http://feeds.delicious.com/v2/rss" target="_blank" rel="external">http://feeds.delicious.com/v2/rss</a>‘) .read()</strong></p>
</blockquote>
<p>所以解决的办法是：<br>打开 pydelicious 的文件夹，找到子文件夹 pydelicious 下的__init__.py 文件，修改三处地方：</p>
<ul>
<li><strong>DLCS_RSS = ‘<a href="http://feeds.delicious.com/v2/rss/" target="_blank" rel="external">http://feeds.delicious.com/v2/rss/</a>‘</strong></li>
<li><strong>rss = http_request(‘<a href="http://feeds.delicious.com/v2/rss" target="_blank" rel="external">http://feeds.delicious.com/v2/rss</a>‘). read()</strong></li>
<li><strong>def get_popular(tag =””):return getrss(tag = tag, popular =0)</strong></li>
</ul>
<p>命令行 cd 到 pydelicious 安装总文件夹，重新输入 sudo python setup.py install。<br>命令行输入 python:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; import pydelicious</div><div class="line">&gt;&gt;&gt; pydelicious.get_popular(tag=<span class="string">'python'</span>)</div></pre></td></tr></table></figure>
<p>此时会发现成功获取到了内容（注意检查网络，如果仍然无法获取，记得翻墙）。</p>
<hr>
<p>本以为到此终于告一段落，但是实际上：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; import pydelicious</div><div class="line">&gt;&gt;&gt; pydelicious.get_popular(tag=<span class="string">'python'</span>)</div><div class="line">&gt;&gt;&gt; pydelicious.get_popular(tag=<span class="string">'xxx'</span>)</div></pre></td></tr></table></figure>
<p>意思是无论我如何更改 tag 的值，返回的内容会发现是一样。这个问题，stackoverflow 老外也同样遇到了：</p>
<blockquote>
<p><strong>I see the resource code again. Maybe it is wrong. Because If you edit the code, the procedural answer always remain unchanged…I’m studing…</strong></p>
</blockquote>
<p>我个人觉得可能是 DLCS_RSS 的网址还需要更改一下（因为这本书在刚出来的时候，pydelicious 还是支持原 del.icio.us 的网站，是不需要去更改__init__.py 的文件等，后来是 unspported，所以需要更改__init__.py 文件中的 RSS 订阅源，也许可能这个订阅源还不是最新的，反正是坑…），或者说是 <code>get_popular()</code> 这个 function 有误（这个不太可能），总而言之，折腾了一下晚上，感觉是遇到了坑，不过好歹也算是解决出来了。</p>
<p>貌似有 <strong>deliciousapi</strong> 这个 package 作为替代，我也尝试过，但运行说明文档中的几个函数，发现会报错，希望如果有人知道如何用 <strong>deliciousapi</strong> 替代 pydelicious 完成第二章后续的几个模块，请务必告诉我！</p>
<p>注意：新手实践这本书的时候，完全可以跳过这个坑，因为没有必要，只需要 get 第二章几个重要的算法或者是思想就可以了。</p>
<hr>
<h1 id="Correct-errors-in-printing"><a href="#Correct-errors-in-printing" class="headerlink" title="Correct errors in printing:"></a>Correct errors in printing:</h1><ul>
<li>P13</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 如果两者没有共同之处，则返回 1</span></div><div class="line"><span class="keyword">if</span> n==<span class="number">0</span>: <span class="keyword">return</span> <span class="number">1</span></div></pre></td></tr></table></figure>
<blockquote>
<p>  需要更正为：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 如果两者没有共同之处，则返回 0</span></div><div class="line"><span class="keyword">if</span> n==<span class="number">0</span>: <span class="keyword">return</span> <span class="number">0</span></div></pre></td></tr></table></figure>
<hr>
<h1 id="Practice"><a href="#Practice" class="headerlink" title="Practice:"></a>Practice:</h1><ul>
<li><strong>暂无</strong></li>
</ul>
<hr>
<h1 id="Still-have-Question"><a href="#Still-have-Question" class="headerlink" title="Still have Question:"></a>Still have Question:</h1><ul>
<li>皮尔逊相关度理论的学习（已完成）</li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文是关于「Programming Collective Intelligence」这本书的 Chapter 1 &amp; 2 的学习笔记。
    
    </summary>
    
      <category term="Machine Learning" scheme="http://randolph.pro/categories/Machine-Learning/"/>
    
      <category term="Book:「Programming Collective Intelligence」" scheme="http://randolph.pro/categories/Machine-Learning/Book-%E3%80%8CProgramming-Collective-Intelligence%E3%80%8D/"/>
    
    
      <category term="Python" scheme="http://randolph.pro/tags/Python/"/>
    
      <category term="Machine Learning" scheme="http://randolph.pro/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>♞「NLP with Python」 Chapter 3</title>
    <link href="http://randolph.pro/2015/09/17/%3CNatural%20Language%20Processing%20with%20Python%3E%20Chapter%203/"/>
    <id>http://randolph.pro/2015/09/17/&lt;Natural Language Processing with Python&gt; Chapter 3/</id>
    <published>2015-09-16T16:00:00.000Z</published>
    <updated>2017-07-25T13:23:30.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fhu96awavpj30yg1cp1kx.jpg" alt=""></p>
<p>关于该书的其他学习笔记系列：<a href="http://randolph.pro/categories/NLP/Book-「NLP-with-Python」/">「NLP with Python」</a></p>
<h1 id="Related"><a href="#Related" class="headerlink" title="Related"></a>Related</h1><ul>
<li><strong>The NLP Pipeline</strong></li>
<li><strong>Basic Operations with Strings</strong></li>
<li><strong>Regular Expressions for Detecting Word Patterns</strong></li>
<li><strong>Finding Word Stems</strong></li>
<li><strong>Searching Tokenized Text</strong></li>
<li><strong>Normalizing Text</strong></li>
<li><strong>Word Segmentation</strong></li>
<li><strong>Formatting: From Lists to Strings</strong></li>
</ul>
<hr>
<h1 id="Key"><a href="#Key" class="headerlink" title="Key:"></a>Key:</h1><h2 id="The-NLP-Pipeline"><a href="#The-NLP-Pipeline" class="headerlink" title="The NLP Pipeline"></a>The NLP Pipeline</h2><p>NLP 的处理流程：我们打开一个 URL 代码读取里面 HTML 格式的内容，去除标记，并选择字符的切片，然后分词，是否转换为 nltk.Text 对象是可选择的。我们也可以将所有词汇小写并提取成词汇表（Vocab）。</p>
<p><img src="https://farm1.staticflickr.com/645/30825223223_8abc614f13_o.png" alt=""></p>
<hr>
<h2 id="Basic-Operations-with-Strings"><a href="#Basic-Operations-with-Strings" class="headerlink" title="Basic Operations with Strings"></a>Basic Operations with Strings</h2><p>有时候字符串跨好几行。Python 提供了多种方式表示它们。在下面的例子中，一个包含两个字符串的序列被连接为一个字符串。我们需要使用 <strong> 反斜杠 </strong> 或者 <strong> 括号</strong>，这样解释器就知道第一行的表达式不完整了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; couplet = &quot;Shall I compare thee to a Summer&apos;s day?&quot;\</div><div class="line">...           &quot;Thou are more lovely and more temperate:&quot;</div><div class="line">&gt;&gt;&gt; print couplet</div><div class="line">Shall I compare thee to a Summer&apos;s day?Thou are more lovely and more temperate:</div><div class="line">&gt;&gt;&gt; couplet = (&quot;Rough winds do shake the darling buds of May,&quot;</div><div class="line">...           &quot;And Summer&apos;s lease hath all too short a date:&quot;)</div><div class="line">&gt;&gt;&gt; print couplet</div><div class="line">Rough winds do shake the darling buds of May,And Summer&apos;s lease hath all too short a date:</div></pre></td></tr></table></figure>
<p>不幸的是，这些方法并没有展现给我们十四行诗中两行之间的换行。为此，我们可以使用如下所示的三重引号的字符串。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; couplet = &quot;&quot;&quot;Shall I compare thee to a Summer&apos;s day?</div><div class="line">... Thou are more lovely and more temperate:&quot;&quot;&quot;</div><div class="line">&gt;&gt;&gt; print couplet</div><div class="line">Shall I compare thee to a Summer&apos;s day?</div><div class="line">Thou are more lovely and more temperate:</div><div class="line">&gt;&gt;&gt; couplet = &apos;&apos;&apos;Rough winds do shake the darling buds of May,</div><div class="line">... And Summer&apos;s lease hath all too short a date:&apos;&apos;&apos;</div><div class="line">&gt;&gt;&gt; print couplet</div><div class="line">Rough winds do shake the darling buds of May,</div><div class="line">And Summer&apos;s lease hath all too short a date:</div></pre></td></tr></table></figure>
<hr>
<h2 id="Regular-Expressions-for-Detecting-Word-Patterns"><a href="#Regular-Expressions-for-Detecting-Word-Patterns" class="headerlink" title="Regular Expressions for Detecting Word Patterns"></a>Regular Expressions for Detecting Word Patterns</h2><p>正则表达式基本元字符，其中包括通配符、范围和闭包：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Operator</th>
<th>Behavior</th>
</tr>
</thead>
<tbody>
<tr>
<td>.</td>
<td>Wildcard, matches any character</td>
</tr>
<tr>
<td>^abc</td>
<td>Matches some pattern abc at the start of a string</td>
</tr>
<tr>
<td>abc$</td>
<td>Matches some pattern abc at the end of a string</td>
</tr>
<tr>
<td>[abc]</td>
<td>Matches one of a set of characters</td>
</tr>
<tr>
<td>[A-Z0-9]</td>
<td>Matches one of a range of characters</td>
</tr>
<tr>
<td>ed/ing/s</td>
<td>Matches one of the specified strings (disjunction)</td>
</tr>
<tr>
<td>*</td>
<td>Zero or more of previous item, e.g.,a<em>,[a-z]</em>(also known as Kleene Closure)</td>
</tr>
<tr>
<td>+</td>
<td>One or more of previous item, e.g.,a+,[a-z]+</td>
</tr>
<tr>
<td>?</td>
<td>Zero or one of the previous item (i.e., optional), e.g.,a?,[a-z]?</td>
</tr>
<tr>
<td>{n}</td>
<td>Exactly n repeats where n is a non-negative integer</td>
</tr>
<tr>
<td>{n,}</td>
<td>At least n repeats</td>
</tr>
<tr>
<td>{,n}</td>
<td>No more than n repeats</td>
</tr>
<tr>
<td>{m,n}</td>
<td>At least m and no more than n repeats</td>
</tr>
<tr>
<td>a(b/c)+</td>
<td>Parentheses that indicate the scope of the operators</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><p>正则表达式是用来指定模式的一种强大而灵活的方法。只要导入了 <strong>re</strong> 模块，就可以使用 <code>re.findall()</code> 找到一个字符串中匹配一个模式的所有子字符串。</p>
</li>
<li><p>如果正则表达式字符串包含反斜杠，应该使用原始字符串与 r 前缀：<code>r&#39;regexp&#39;</code>，告诉 Python 不要预处理这个字符串。</p>
</li>
</ul>
<hr>
<h2 id="Finding-Word-Stems"><a href="#Finding-Word-Stems" class="headerlink" title="Finding Word Stems"></a>Finding Word Stems</h2><p>书中提到的，抽出一个词的词干的方法，是直接去掉任何看起来像后缀的字符。听起来很棒，但是仍然存在一个问题。比如这个词 <strong>processes</strong>：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; re.findall(r<span class="string">'^(.*)(ing|ly|ed|ious|ies|ive|es|s|ment)$'</span>, <span class="string">'processes'</span>)</div><div class="line">[(<span class="string">'processe'</span>, <span class="string">'s'</span>)]</div></pre></td></tr></table></figure></p>
<p>正则表达式错误的找到了后缀 ‘-s’，而不是后缀 ‘-es’。这表明另一个微妙之处：<br><code>*</code> 操作符是“贪婪的”，所以表达式的 <code>.*</code> 部分试图尽可能多地匹配输入的字符串。如果使用“非贪婪”版本的 <code>*</code> 操作符，写成 <code>*?</code> 操作符，就得到想要的结果。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; re.findall(r<span class="string">'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)$'</span>, <span class="string">'processes'</span>)</div><div class="line">[(<span class="string">'process'</span>, <span class="string">'es'</span>)]</div></pre></td></tr></table></figure></p>
<p>还可以通过将第二个括号中的内容变成可选来得到空后缀。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; re.findall(r<span class="string">'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)$'</span>, <span class="string">'language'</span>)</div><div class="line">[(<span class="string">'language'</span>, <span class="string">''</span>)]</div></pre></td></tr></table></figure></p>
<p>（虽然以上方法还有许多问题…）</p>
<hr>
<h2 id="Searching-Tokenized-Text"><a href="#Searching-Tokenized-Text" class="headerlink" title="Searching Tokenized Text"></a>Searching Tokenized Text</h2><p>可以使用一种特殊的正则表达式搜索一个文本中多个词。例如，在大型文本语料库中搜索 ‘x and other ys’ 形式的表达式来发现上位词。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; from nltk.corpus import brown</div><div class="line">&gt;&gt;&gt; hobbies_learned = nltk.Text(brown.words(categories=[<span class="string">'hobbies'</span>, <span class="string">'learned'</span>]))</div><div class="line">&gt;&gt;&gt; hobbies_learned.findall(r<span class="string">"&lt;\w*&gt; &lt;and&gt; &lt;other&gt; &lt;\w*s&gt;"</span>)</div><div class="line">speed and other activities; water and other liquids; tomb and other</div><div class="line">landmarks; Statues and other monuments; pearls and other jewels;</div><div class="line">charts and other items; roads and other features; figures and other</div><div class="line">objects; military and other areas; demands and other factors;</div><div class="line">abstracts and other compilations; iron and other metals</div></pre></td></tr></table></figure></p>
<hr>
<h2 id="Normalizing-Text"><a href="#Normalizing-Text" class="headerlink" title="Normalizing Text"></a>Normalizing Text</h2><h3 id="Stemmers"><a href="#Stemmers" class="headerlink" title="Stemmers"></a>Stemmers</h3><p><strong>词干提取器</strong>。NLTK 中包括了一些现成的词干提取器，如果需要使用词干提取器，应该优先使用它们中的一个，而不是使用正则表达式制作自己的词干提取器，因为 NLTK 中的词干提取器能处理的不规则情况很广泛。Porter 和 Lancaster 词干提取器按照它们自己的规则剥离词缀。下面的例子表明 Porter 词干提取器正确处理了词 lying（将它映射为 lie），而 Lancaster 词干提取器并没有处理好。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; porter = nltk.PorterStemmer()</div><div class="line">&gt;&gt;&gt; lancaster = nltk.LancasterStemmer()</div><div class="line">&gt;&gt;&gt; [porter.stem(t) <span class="keyword">for</span> t <span class="keyword">in</span> tokens]</div><div class="line">[<span class="string">'DENNI'</span>, <span class="string">':'</span>, <span class="string">'Listen'</span>, <span class="string">','</span>, <span class="string">'strang'</span>, <span class="string">'women'</span>, <span class="string">'lie'</span>, <span class="string">'in'</span>, <span class="string">'pond'</span>,</div><div class="line"><span class="string">'distribut'</span>, <span class="string">'sword'</span>, <span class="string">'is'</span>, <span class="string">'no'</span>, <span class="string">'basi'</span>, <span class="string">'for'</span>, <span class="string">'a'</span>, <span class="string">'system'</span>, <span class="string">'of'</span>, <span class="string">'govern'</span>,</div><div class="line"><span class="string">'.'</span>, <span class="string">'Suprem'</span>, <span class="string">'execut'</span>, <span class="string">'power'</span>, <span class="string">'deriv'</span>, <span class="string">'from'</span>, <span class="string">'a'</span>, <span class="string">'mandat'</span>, <span class="string">'from'</span>,</div><div class="line"><span class="string">'the'</span>, <span class="string">'mass'</span>, <span class="string">','</span>, <span class="string">'not'</span>, <span class="string">'from'</span>, <span class="string">'some'</span>, <span class="string">'farcic'</span>, <span class="string">'aquat'</span>, <span class="string">'ceremoni'</span>, <span class="string">'.'</span>]</div><div class="line">&gt;&gt;&gt; [lancaster.stem(t) <span class="keyword">for</span> t <span class="keyword">in</span> tokens]</div><div class="line">[<span class="string">'den'</span>, <span class="string">':'</span>, <span class="string">'list'</span>, <span class="string">','</span>, <span class="string">'strange'</span>, <span class="string">'wom'</span>, <span class="string">'lying'</span>, <span class="string">'in'</span>, <span class="string">'pond'</span>, <span class="string">'distribut'</span>,</div><div class="line"><span class="string">'sword'</span>, <span class="string">'is'</span>, <span class="string">'no'</span>, <span class="string">'bas'</span>, <span class="string">'for'</span>, <span class="string">'a'</span>, <span class="string">'system'</span>, <span class="string">'of'</span>, <span class="string">'govern'</span>, <span class="string">'.'</span>, <span class="string">'suprem'</span>,</div><div class="line"><span class="string">'execut'</span>, <span class="string">'pow'</span>, <span class="string">'der'</span>, <span class="string">'from'</span>, <span class="string">'a'</span>, <span class="string">'mand'</span>, <span class="string">'from'</span>, <span class="string">'the'</span>, <span class="string">'mass'</span>, <span class="string">','</span>, <span class="string">'not'</span>,</div><div class="line"><span class="string">'from'</span>, <span class="string">'som'</span>, <span class="string">'farc'</span>, <span class="string">'aqu'</span>, <span class="string">'ceremony'</span>, <span class="string">'.'</span>]</div></pre></td></tr></table></figure></p>
<p>词干提取过程没有明确定义，通常选择最合适应用的词干提取器。<br>书本上的例子不错，使用词干提取器索引文本：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">IndexedText</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, stemmer, text)</span>:</span></div><div class="line">        self._text = text</div><div class="line">        self._stemmer = stemmer</div><div class="line">        self._index = nltk.Index((self._stem(word), i)</div><div class="line">                                 <span class="keyword">for</span> (i, word) <span class="keyword">in</span> enumerate(text))</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">concordance</span><span class="params">(self, word, width=<span class="number">40</span>)</span>:</span></div><div class="line">        key = self._stem(word)</div><div class="line">        wc = width/<span class="number">4</span>                <span class="comment"># words of context</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> self._index[key]:</div><div class="line">            lcontext = <span class="string">''</span>.join(self._text[i-wc:i])</div><div class="line">            rcontext = <span class="string">' '</span>.join(self._text[i:i+wc])</div><div class="line">            ldisplay = <span class="string">'%*s'</span>  % (width, lcontext[-width:])</div><div class="line">            rdisplay = <span class="string">'%-*s'</span> % (width, rcontext[:width])</div><div class="line">            <span class="keyword">print</span> ldisplay, rdisplay</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_stem</span><span class="params">(self, word)</span>:</span></div><div class="line">        <span class="keyword">return</span> self._stemmer.stem(word).lower()</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; porter = nltk.PorterStemmer()</div><div class="line">&gt;&gt;&gt; grail = nltk.corpus.webtext.words(&apos;grail.txt&apos;)</div><div class="line">&gt;&gt;&gt; text = IndexedText(porter, grail)</div><div class="line">&gt;&gt;&gt; text.concordance(&apos;lie&apos;)</div><div class="line">r king ! DENNIS : Listen , strange women lying in ponds distributing swords is no</div><div class="line"> beat a very brave retreat . ROBIN : All lies ! MINSTREL : [singing] Bravest of</div><div class="line">       Nay . Nay . Come . Come . You may lie here . Oh , but you are wounded !</div><div class="line">doctors immediately ! No , no , please ! Lie down . [clap clap] PIGLET : Well</div><div class="line">ere is much danger , for beyond the cave lies the Gorge of Eternal Peril , which</div><div class="line">   you . Oh ... TIM : To the north there lies a cave -- the cave of Caerbannog --</div><div class="line">h it and lived ! Bones of full fifty men lie strewn about its lair . So , brave k</div><div class="line">not stop our fight &apos; til each one of you lies dead , and the Holy Grail returns t</div></pre></td></tr></table></figure>
<hr>
<h2 id="Formatting-From-Lists-to-Strings"><a href="#Formatting-From-Lists-to-Strings" class="headerlink" title="Formatting: From Lists to Strings"></a>Formatting: From Lists to Strings</h2><h3 id="from-Lists-to-Strings"><a href="#from-Lists-to-Strings" class="headerlink" title="from Lists to Strings"></a>from Lists to Strings</h3><p>从链表到字符串。用于文本处理最简单的结构化对象是词链表。当需要把这些输出到显示器或者文件中时，必须把这些词的链表转换成字符串。在 Python 中，使用 <code>join()</code> 方法，并制定作为“胶水”使用的字符串。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; silly = [<span class="string">'We'</span>, <span class="string">'called'</span>, <span class="string">'him'</span>, <span class="string">'Tortoise'</span>, <span class="string">'because'</span>, <span class="string">'he'</span>, <span class="string">'taught'</span>, <span class="string">'us'</span>, <span class="string">'.'</span>]</div><div class="line">&gt;&gt;&gt; <span class="string">''</span>.join(silly)</div><div class="line"><span class="string">'We called him Tortoise because he taught us .'</span></div><div class="line">&gt;&gt;&gt; <span class="string">';'</span>.join(silly)</div><div class="line"><span class="string">'We;called;him;Tortoise;because;he;taught;us;.'</span></div><div class="line">&gt;&gt;&gt; <span class="string">''</span>.join(silly)</div><div class="line"><span class="string">'WecalledhimTortoisebecausehetaughtus.'</span></div></pre></td></tr></table></figure></p>
<ul>
<li>书本提到了 <strong> 间接地提供占位符的值</strong>。例子：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; template = <span class="string">'Lee wants a %s right now'</span></div><div class="line">&gt;&gt;&gt; menu = [<span class="string">'sandwich'</span>, <span class="string">'spam fritter'</span>, <span class="string">'pancake'</span>]</div><div class="line">&gt;&gt;&gt; <span class="keyword">for</span> snack <span class="keyword">in</span> menu:</div><div class="line">...     <span class="built_in">print</span> template % snack</div><div class="line">...</div><div class="line">Lee wants a sandwich right now</div><div class="line">Lee wants a spam fritter right now</div><div class="line">Lee wants a pancake right now</div></pre></td></tr></table></figure>
<hr>
<h1 id="Need-to-Know"><a href="#Need-to-Know" class="headerlink" title="Need to Know:"></a>Need to Know:</h1><p>在 Python 2.x 当中是可以使用：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> urlopen</div></pre></td></tr></table></figure></p>
<p>如果使用的是 Python 3.x 的话，需要更改为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</div></pre></td></tr></table></figure></p>
<hr>
<p>在「处理 HTML」的模块中：</p>
<p>书本提到从 HTML 中提取文本，采用辅助函数 <code>nltk.clean_html()</code> 将 HTML 字符串作为参数，返回原始文本。</p>
<p>然而，现在这个辅助函数已不支持。为了实现这一目的，我们可以下载<strong>Beautiful Soup 4</strong>。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install beautifulsoup4</div></pre></td></tr></table></figure></p>
<p>随后在代码部分中，调用 BeautifulSoup：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> nltk, re, pprint</div><div class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> *</div><div class="line"></div><div class="line">url = <span class="string">"http://youraddress"</span></div><div class="line">html = urlopen(url).read()</div><div class="line">soup = BeautifulSoup(html)</div><div class="line">raw = soup.get_text()</div><div class="line">tokens = nltk.word_tokenize(raw)</div></pre></td></tr></table></figure></p>
<hr>
<p>在 [分词] 的模块中：</p>
<blockquote>
<p>Now the segmentation task becomes a search problem: find the bit string that causes the text string to be correctly segmented into words.<br>现在分词的任务变成一个搜索问题：找到能将文本字符串正确地分割成词汇的字位串。</p>
<p><strong>We assume the learner is acquiring words and storing them in an internal lexicon. Given a suitable lexicon, it is possible to reconstruct the source text as a sequence of lexical items.</strong></p>
<p>假定学习者接受字词，并将它们存储在一个内部的词典当中。给定一个合适的词典，我们是能够使用词典中的词的序列来进行重构文本的。</p>
<p>Following (Brent &amp; Cart- wright, 1995), we can define an <strong>objective function</strong>, a scoring function whose value we will try to optimize, based on the size of the lexicon and the amount of information needed to reconstruct the source text from the lexicon.<br>为了衡量我们这个词典的优劣，这里我们需要定义一个目标函数（Brent &amp; Cart-wright 在 1995 提出的方法），即一个打分函数，依据两个因素，第一个因素是词典的大小，第二个是使用词典来重构原文本所需的信息量。</p>
</blockquote>
<p><img src="https://farm1.staticflickr.com/767/31488720242_48aae8823f_o.png" alt=""></p>
<p>计算目标函数：给定一个假设的源文本的分词（左），推导出一个词典和推导表，它能让源文本重构，然后合计每个词项（包括边界标志）与推导表的字符数，作为分词质量的得分；得分值越小表明分词越好。</p>
<p>用代码来实现这个目标函数，计算存储词典和重构源文本的成本：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(text, segs)</span>:</span></div><div class="line">    words = segment(text, segs)</div><div class="line">    text_size = len(words)</div><div class="line">    lexicon_size = len(<span class="string">''</span>.join(list(set(words))))</div><div class="line">    <span class="keyword">return</span> text_size + lexicon_size</div></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; text = <span class="string">"doyouseethekittyseethedoggydoyoulikethekittylikethedoggy"</span></div><div class="line">&gt;&gt;&gt; seg1 = <span class="string">"0000000000000001000000000010000000000000000100000000000"</span></div><div class="line">&gt;&gt;&gt; seg2 = <span class="string">"0100100100100001001001000010100100010010000100010010000"</span></div><div class="line">&gt;&gt;&gt; seg3 = <span class="string">"0000100100000011001000000110000100010000001100010000001"</span></div><div class="line">&gt;&gt;&gt; segment(text, seg3)</div><div class="line">[<span class="string">'doyou'</span>, <span class="string">'see'</span>, <span class="string">'thekitt'</span>, <span class="string">'y'</span>, <span class="string">'see'</span>, <span class="string">'thedogg'</span>, <span class="string">'y'</span>, <span class="string">'doyou'</span>, <span class="string">'like'</span>,</div><div class="line"> <span class="string">'thekitt'</span>, <span class="string">'y'</span>, <span class="string">'like'</span>, <span class="string">'thedogg'</span>, <span class="string">'y'</span>]</div><div class="line">&gt;&gt;&gt; evaluate(text, seg3)</div><div class="line">46</div><div class="line">&gt;&gt;&gt; evaluate(text, seg2)</div><div class="line">47</div><div class="line">&gt;&gt;&gt; evaluate(text, seg1)</div><div class="line">63</div></pre></td></tr></table></figure>
<hr>
<h2 id="Simulated-Annealing-SA"><a href="#Simulated-Annealing-SA" class="headerlink" title="Simulated Annealing(SA)"></a>Simulated Annealing(SA)</h2><p><strong>模拟退火算法 </strong>。在提到模拟退火算法之前，我来先介绍一下<strong> 爬山算法（Hill Climbing）</strong>。爬山算法是一种简单的贪心搜索算法，该算法每次从当前的临近解空间中选择一个最优解作为当前解，直到达到一个局部最优解。<br>爬山算法实现很简单，其主要的缺点就是会陷入局部最优解而不一定能搜索到全局最优解。如图所示，假设 C 点为当前解，爬山算法搜索到 A 点这个局部最优解就会停止搜索，因为 A 点无论向哪个方向小幅度移动都不能得到更优的解。</p>
<p><img src="https://farm1.staticflickr.com/768/31263141960_9e2f2a7c44_o.png" alt=""></p>
<p>爬山算法是完完全全的贪心算法，每一次都是鼠目寸光地选择一个当前最优解，因此只能搜索到局部的最有值。模拟退火其实也是一种贪心算法，但是它的搜索过程引入了随机因素。模拟退火算法 <strong> 以一定的概率 </strong> 来接受一个比当前解要差的解，因此 <strong> 有可能 </strong> 会跳出这个局部的最优解，达到全局的最优解。如上图为例，模拟退火算法在搜索到局部最优解 A 后，会以 <strong> 一定的概率 </strong> 接受向 E 的移动。也许经过几次这样的不是局部最优的移动后会到达 D 点，于是就跳出了局部最大值 A。<br>模拟退火算法描述：</p>
<ul>
<li><p>若 $ J(Y(i+1)) \geqslant  J(Y(i)) $  (即移动后得到更优解)，则总是接受该移动</p>
</li>
<li><p>若 $ J(Y(i+1)) &lt;  J(Y(i)) $  (即移动后的解比当前解要差)，则以一定的概率接受移动，而且这个概率随着时间推移逐渐降低（逐渐降低才能趋向稳定）</p>
</li>
</ul>
<p><strong>这里的“一定的概率”的计算参考了金属冶炼的退火过程，这也是模拟退火算法名称的由来。</strong></p>
<p>根据热力学的原理，在温度为 <strong><em>T</em></strong> 时，出现能量差为 <strong><em>dE</em></strong> 的降温的概率为<strong><em>P(dE)</em></strong>，表示为：</p>
<script type="math/tex; mode=display">
P(\mathrm{d} E) = exp(\mathrm{d}E/kT)</script><p>其中 <strong><em>k</em></strong> 是一个常数，<strong><em>exp</em></strong>表示自然指数，且 <strong><em>dE&lt;0</em></strong>。这条公式说白了就是：温度越高，出现一次能量差为<strong><em>dE</em></strong> 的降温的概率就越大；温度越低，则出现降温的概率就越小。又由于 <strong><em>dE</em></strong> 总是小于 0（否则就不叫退火了），因此 <strong><em>dE/kT &lt; 0</em></strong>，所以<strong><em>P(dE)</em></strong> 的函数取值范围是(0,1) 。</p>
<p>　　随着温度 <strong><em>T</em></strong> 的降低，<strong><em>P(dE)</em></strong>会逐渐降低。</p>
<p>我们将一次向较差解的移动看做一次温度跳变过程，我们以概率 <strong><em>P(dE)</em></strong> 来接受这样的移动。</p>
<p>关于爬山算法与模拟退火，有一个有趣的比喻：</p>
<p>爬山算法：兔子朝着比现在高的地方跳去。它找到了不远处的最高山峰。但是这座山不一定是珠穆朗玛峰。这就是爬山算法，它不能保证局部最优值就是全局最优值。</p>
<p>模拟退火：兔子喝醉了。它随机地跳了很长时间。这期间，它可能走向高处，也可能踏入平地。但是，它渐渐清醒了并朝最高方向跳去。这就是模拟退火。</p>
<hr>
<p>接着，让我们使用带有模拟退火算法思想的非确定性搜索，来确定构建分词最好的词典：</p>
<ol>
<li>一开始仅搜索短语分词；</li>
<li>随机扰动 0 和 1，它们与“温度”成一定比例；</li>
<li>每次迭代温度都会降低，扰动边界会减少。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> random <span class="keyword">import</span> randint</div><div class="line"></div><div class="line"><span class="comment">#flip()函数，随机扰动 0 和 1</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">flip</span><span class="params">(segs, pos)</span>:</span></div><div class="line">    <span class="keyword">return</span> segs[:pos] + str(<span class="number">1</span>-int(segs[pos])) + segs[pos+<span class="number">1</span>:]</div><div class="line"></div><div class="line"><span class="comment">#flip_n()函数，n 为迭代次数</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">flip_n</span><span class="params">(segs, n)</span>:</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</div><div class="line">        segs = flip(segs, randint(<span class="number">0</span>,len(segs)<span class="number">-1</span>))</div><div class="line">    <span class="keyword">return</span> segs</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">anneal</span><span class="params">(text, segs, iterations, cooling_rate)</span>:</span>    <span class="comment">#cooling_rate“降温”的快慢</span></div><div class="line">    temperature = float(len(segs))    <span class="comment"># 初始温度</span></div><div class="line">    <span class="keyword">while</span> temperature &gt; <span class="number">0.5</span>:</div><div class="line">        <span class="comment"># 每一次“降温”的结果，若由于前一次，则会更改 segs 的值并进行下一次“降温”</span></div><div class="line">        best_segs, best = segs, evaluate(text, segs)</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(iterations):</div><div class="line">            guess = flip_n(segs, int(round(temperature)))</div><div class="line">            score = evaluate(text, guess)</div><div class="line">            <span class="keyword">if</span> score &lt; best:</div><div class="line">                best, best_segs = score, guess</div><div class="line">        score, segs = best, best_segs</div><div class="line">        temperature = temperature / cooling_rate</div><div class="line">        <span class="keyword">print</span> evaluate(text, segs), segment(text, segs)</div><div class="line">    <span class="keyword">print</span></div><div class="line">    <span class="keyword">return</span> segs</div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; text = <span class="string">"doyouseethekittyseethedoggydoyoulikethekittylikethedoggy"</span></div><div class="line">&gt;&gt;&gt; seg1 = <span class="string">"0000000000000001000000000010000000000000000100000000000"</span></div><div class="line">&gt;&gt;&gt; anneal(text, seg1, 5000, 1.2)</div><div class="line">60 [<span class="string">'doyouseetheki'</span>, <span class="string">'tty'</span>, <span class="string">'see'</span>, <span class="string">'thedoggy'</span>, <span class="string">'doyouliketh'</span>, <span class="string">'ekittylike'</span>, <span class="string">'thedoggy'</span>]</div><div class="line">58 [<span class="string">'doy'</span>, <span class="string">'ouseetheki'</span>, <span class="string">'ttysee'</span>, <span class="string">'thedoggy'</span>, <span class="string">'doy'</span>, <span class="string">'o'</span>, <span class="string">'ulikethekittylike'</span>, <span class="string">'thedoggy'</span>]</div><div class="line">56 [<span class="string">'doyou'</span>, <span class="string">'seetheki'</span>, <span class="string">'ttysee'</span>, <span class="string">'thedoggy'</span>, <span class="string">'doyou'</span>, <span class="string">'liketh'</span>, <span class="string">'ekittylike'</span>, <span class="string">'thedoggy'</span>]</div><div class="line">54 [<span class="string">'doyou'</span>, <span class="string">'seethekit'</span>, <span class="string">'tysee'</span>, <span class="string">'thedoggy'</span>, <span class="string">'doyou'</span>, <span class="string">'likethekittylike'</span>, <span class="string">'thedoggy'</span>]</div><div class="line">53 [<span class="string">'doyou'</span>, <span class="string">'seethekit'</span>, <span class="string">'tysee'</span>, <span class="string">'thedoggy'</span>, <span class="string">'doyou'</span>, <span class="string">'like'</span>, <span class="string">'thekitty'</span>, <span class="string">'like'</span>, <span class="string">'thedoggy'</span>]</div><div class="line">51 [<span class="string">'doyou'</span>, <span class="string">'seethekittysee'</span>, <span class="string">'thedoggy'</span>, <span class="string">'doyou'</span>, <span class="string">'like'</span>, <span class="string">'thekitty'</span>, <span class="string">'like'</span>, <span class="string">'thedoggy'</span>]</div><div class="line">42 [<span class="string">'doyou'</span>, <span class="string">'see'</span>, <span class="string">'thekitty'</span>, <span class="string">'see'</span>, <span class="string">'thedoggy'</span>, <span class="string">'doyou'</span>, <span class="string">'like'</span>, <span class="string">'thekitty'</span>, <span class="string">'like'</span>, <span class="string">'thedoggy'</span>]</div><div class="line"><span class="string">'0000100100000001001000000010000100010000000100010000000'</span></div></pre></td></tr></table></figure>
<p>有了足够的数据，就可能以一个较为合理的准确度自动将文本分割成词汇。</p>
<p>这种方法可用于那些词的边界没有任何视觉表示的书写系统分词。</p>
<hr>
<h1 id="Correct-errors-in-printing"><a href="#Correct-errors-in-printing" class="headerlink" title="Correct errors in printing:"></a>Correct errors in printing:</h1><ul>
<li>暂无</li>
</ul>
<hr>
<h1 id="Practice"><a href="#Practice" class="headerlink" title="Practice:"></a>Practice:</h1><blockquote>
<p>5.○ What happens if you ask the interpreter to evaluate <strong><code>monty[::-1]</code></strong>? Explain why this is a reasonable result.</p>
</blockquote>
<ul>
<li>逆序输出。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; a=<span class="string">'python'</span></div><div class="line">&gt;&gt;&gt; a[::-1]</div><div class="line"><span class="string">'nohtyp'</span></div></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>6.○ Describe the class of strings matched by the following regular expressions: </p>
<ol>
<li>[a-zA-Z]+</li>
<li>[A-Z][a-z]*</li>
<li>p[aeiou]{,2}t</li>
<li>\d+(\.\d+)?</li>
<li>([^aeiou][aeiou][^aeiou])</li>
<li>\w+|[^\w\s]+</li>
</ol>
<p>Test your answers using <strong><code>nltk.re_show()</code></strong>.</p>
</blockquote>
<ol>
<li>字母字符串</li>
<li>开头大写后小写字母不限（小写字母可有可没有）</li>
<li>p 开头 t 结尾，中间有少于 2 个的元音字母</li>
<li>整数或者带小数的整数（整数与浮点数）</li>
<li>（（非元音）（元音）（非元音））（可有可没有） 例如’pot’</li>
<li>要么是字母一个或多个，要么不是字母、空格一个或多个</li>
</ol>
<hr>
<blockquote>
<p>7.○ Write regular expressions to match the following classes of strings:</p>
<ol>
<li>A single determiner (assume that <strong><em>a</em></strong>, <strong><em>an</em></strong>, and <strong><em>the</em></strong> are the only determiners)</li>
<li>An arithmetic expression using integers, addition, and multiplication, such as <strong>2*3+8</strong></li>
</ol>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">1. nltk.re_show(&apos;an?|the&apos;, &apos;thesisiaishihsthean&apos;, left=&apos;&#123;&apos;, right=&apos;&#125;&apos;)</div><div class="line">2. nltk.re_show(&apos;\d+\*\d+\+\d+&apos;, &apos;2*3+8&apos;, left=&apos;&#123;&apos;, right=&apos;&#125;&apos;)</div></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>9.○ Save some text into a file corpus.txt. Define a function <strong><code>load(f)</code></strong> that reads from the file named in its sole argument, and returns a string containing the text of the file.</p>
<ol>
<li>Use <strong><code>nltk.regexp_tokenize()</code></strong>to create a tokenizer that tokenizes the various kinds of punctuation in this text. Use one multiline regular expression inline comments, using the verbose flag<strong><code>(?x)</code></strong>.</li>
<li>Use <strong><code>nltk.regexp_tokenize()</code></strong> to create a tokenizer that tokenizes the following kinds of expressions: monetary amounts; dates; names of people and organizations.    </li>
</ol>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="number">1.</span> &gt;&gt;&gt; pattern = <span class="string">r'''(?x)</span></div><div class="line">       [][.,;"'?()=-_`]</div><div class="line">       '''</div><div class="line">   &gt;&gt;&gt; nltk.regexp_tokenize(text, pattern)</div><div class="line"></div><div class="line"><span class="number">2.</span> &gt;&gt;&gt; pattern = <span class="string">r'''(?x)</span></div><div class="line">       ([A-Z]\.)+    # eg.  U.S.A</div><div class="line">       |([A-Z][a-z]*\s[A-Z][a-z]*)    # words with optional internal</div><div class="line">       |\$?\d+(\.\d+)?%    # currency and percentages eg. $12.40, 82%</div><div class="line">       |\d+-\d+-\d+</div><div class="line">       '''</div><div class="line">   &gt;&gt;&gt; nltk.regexp_tokenize(text, pattern)</div></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>20.◑ Write code to access a favorite web page and extract some text from it. For example, access a weather site and extract the forecast top temperature for your town or city today.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">test20</span><span class="params">()</span>:</span></div><div class="line">    <span class="comment"># search weather</span></div><div class="line">    url = <span class="string">'http://en.weather.com.cn/weather/101220101.shtml'</span></div><div class="line">    html = urlopen(url).read()</div><div class="line">    soup = BeautifulSoup(html, <span class="string">"lxml"</span>)</div><div class="line">    raw = soup.get_text()</div><div class="line">    tokens = nltk.word_tokenize(raw)</div><div class="line">    text = nltk.Text(tokens)</div><div class="line">    print(text)</div><div class="line">    <span class="keyword">print</span></div><div class="line">    print(text.concordance(<span class="string">'Hefei'</span>))</div></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>21.◑ Write a function <strong><code>unknown()</code></strong> that takes a URL as its argument, and returns a list of unknown words that occur on that web page. In order to do this, extract all substrings consisting of lowercase letters (using <strong><code>re.findall()</code></strong>) and remove any items from this set that occur in the Words Corpus (<strong>nltk.corpus.words</strong>). Try to categorize these words manually and discuss your findings.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">test21</span><span class="params">()</span>:</span></div><div class="line">    url = <span class="string">"http://www.bbc.co.uk/news/world-middle-east-18650775"</span></div><div class="line">    wordsres = []</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">unknown</span><span class="params">(url)</span>:</span></div><div class="line">        html = urlopen(url).read()</div><div class="line">        soup = BeautifulSoup(html)</div><div class="line">        raw = soup.get_text()</div><div class="line">        words = re.findall(<span class="string">r'[a-z]+'</span>, raw)</div><div class="line">        wordlist = [w <span class="keyword">for</span> w <span class="keyword">in</span> nltk.corpus.words.words(<span class="string">'en'</span>) <span class="keyword">if</span> w.islower()]</div><div class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> words:</div><div class="line">            <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> wordlist:</div><div class="line">                wordsres.append(word)</div><div class="line">        <span class="keyword">return</span> wordsres</div><div class="line">    wordsres = unknown(url)</div><div class="line">    print(wordsres)</div></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>25.◑ <strong><em>Pig Latin</em></strong> is a simple transformation of English text. Each word of the text is converted as follows: move any consonant (or consonant cluster) that appears at the start of the word to the end, then append <strong><em>ay</em></strong>, e.g., <strong><em>string</em></strong> → <strong><em>ingstray</em></strong>, <strong><em>idle</em></strong> → <strong><em>idleay</em></strong> (see <em><a href="http://en.wikipedia.org/wiki/Pig_Latin" target="_blank" rel="external">http://en.wikipedia.org/wiki/Pig_Latin</a></em>).</p>
<ol>
<li>Write a function to convert a word to Pig Latin.</li>
<li>Write code that converts text, instead of individual words.</li>
<li>Extend it further to preserve capitalization, to keep <strong>qu</strong> together (so that <strong>quiet</strong> becomes <strong>ietquay</strong>, for example), and to detect when <strong>y</strong> is used as a consonant (e.g., <strong>yellow</strong>) versus a vowel (e.g., <strong>style</strong>).</li>
</ol>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">test25</span><span class="params">()</span>:</span></div><div class="line">    <span class="comment"># Pig Latin</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pig_latin</span><span class="params">(word)</span>:</span></div><div class="line">        result = []</div><div class="line">        <span class="keyword">if</span> <span class="string">'qu'</span> <span class="keyword">in</span> word.lower():</div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(word)):</div><div class="line">                <span class="keyword">if</span> word[i] <span class="keyword">in</span> <span class="string">'[AEIOUaeiou]'</span>:</div><div class="line">                    pig_word = [word[i+<span class="number">1</span>:], word[:i+<span class="number">1</span>], <span class="string">'ay'</span>]</div><div class="line">                    result = <span class="string">''</span>.join(pig_word)</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(word)):</div><div class="line">                <span class="keyword">if</span> word[i] <span class="keyword">in</span> <span class="string">'[AEIOUaeiou]'</span>:</div><div class="line">                    pig_word = [word[i:], word[:i], <span class="string">'ay'</span>]</div><div class="line">                    result = <span class="string">''</span>.join(pig_word)</div><div class="line">        <span class="keyword">return</span> result</div><div class="line"></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">translate</span><span class="params">()</span>:</span></div><div class="line">        object = open(<span class="string">'text25.txt'</span>)</div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            text = object.read()</div><div class="line">        <span class="keyword">finally</span>:</div><div class="line">            object.close()</div><div class="line">        words = nltk.word_tokenize(text)</div><div class="line">        result = []</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(words)):</div><div class="line">            result.append(pig_latin(words[i]))</div><div class="line">        <span class="keyword">return</span> result</div><div class="line">    result = translate()</div><div class="line">    print(result)</div><div class="line">    print(pig_latin(<span class="string">'quiet'</span>))</div><div class="line">    print(pig_latin(<span class="string">'string'</span>))</div></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>27.◑ Python’s <strong>random</strong> module includes a function <strong><code>choice()</code></strong> which randomly chooses an item from a sequence; e.g., <strong><code>choice(&quot;aehh &quot;)</code></strong> will produce one of four possible characters, with the letter h being twice as frequent as the others. Write a generator expression that produces a sequence of 500 randomly chosen letters drawn from the string <strong>“aehh “</strong>, and put this expression inside a call to the <strong><code>&#39;&#39;.join()</code></strong> function, to concatenate them into one long string. You should get a result that looks like uncontrolled sneezing or maniacal laughter: <strong>he haha ee heheeh eha</strong>. Use <strong><code>split()</code></strong> and <strong><code>join()</code></strong> again to normalize the whitespace in this string.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">test27</span><span class="params">()</span>:</span></div><div class="line">    <span class="comment"># choice</span></div><div class="line">    string = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">500</span>):</div><div class="line">        string.append(random.choice(<span class="string">'hahe'</span>))</div><div class="line">    result = <span class="string">''</span>.join(string).split()</div><div class="line">    print(result)</div></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>29.◑ Readability measures are used to score the reading difficulty of a text, for the purposes of selecting texts of appropriate difficulty for language learners. Let us define $μ_w$ to be the average number of letters per word, and $μ_s$ to be the average number of words per sentence, in a given text. The Automated Readability Index (ARI) of the text is defined to be: $4.71 μ_w + 0.5 μ_s - 21.43$. Compute the ARI score for various sections of the Brown Corpus, including section f (popular lore) and j (learned). Make use of the fact that <strong><code>nltk.corpus.brown.words()</code></strong> produces a se- quence of words, whereas <strong><code>nltk.corpus.brown.sents()</code></strong> produces a sequence of sentences.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">test29</span><span class="params">()</span>:</span></div><div class="line">    words1 = [len(word) <span class="keyword">for</span> word <span class="keyword">in</span> nltk.corpus.brown.words(categories = <span class="string">'lore'</span>)]</div><div class="line">    sents1 = [len(sent) <span class="keyword">for</span> sent <span class="keyword">in</span> nltk.corpus.brown.sents(categories = <span class="string">'lore'</span>)]</div><div class="line">    words2 = [len(word) <span class="keyword">for</span> word <span class="keyword">in</span> nltk.corpus.brown.words(categories = <span class="string">'learned'</span>)]</div><div class="line">    sents2 = [len(sent) <span class="keyword">for</span> sent <span class="keyword">in</span> nltk.corpus.brown.sents(categories = <span class="string">'learned'</span>)]</div><div class="line">    wordsum = <span class="number">0</span></div><div class="line">    sentsum = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> wlength <span class="keyword">in</span> words1 :</div><div class="line">        wordsum += int(wlength)</div><div class="line"></div><div class="line">    <span class="keyword">for</span> slength <span class="keyword">in</span> sents1 :</div><div class="line">        sentsum += slength</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">ARI</span><span class="params">(uw,us)</span>:</span></div><div class="line">        <span class="keyword">return</span> <span class="number">4.71</span>*uw + <span class="number">0.5</span>*us - <span class="number">21.43</span></div><div class="line"></div><div class="line">    uw = wordsum/len(words1)</div><div class="line">    us = sentsum/len(sents1)</div><div class="line">    print(us)</div><div class="line">    print(ARI(uw, us))</div></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>30.◑ Use the Porter Stemmer to normalize some tokenized text, calling the stemmer on each word. Do the same thing with the Lancaster Stemmer, and see if you ob- serve any differences.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">test30</span><span class="params">()</span>:</span></div><div class="line">    saying = [<span class="string">'After'</span>, <span class="string">'all'</span>, <span class="string">'is'</span>, <span class="string">'said'</span>, <span class="string">'and'</span>, <span class="string">'done'</span>, <span class="string">','</span>, <span class="string">'more'</span>, <span class="string">'is'</span>, <span class="string">'said'</span>, <span class="string">'than'</span>, <span class="string">'done'</span>, <span class="string">'.'</span>]</div><div class="line">    porter = nltk.PorterStemmer()</div><div class="line">    lancaster = nltk.LancasterStemmer()</div><div class="line">    result_porter = [porter.stem(t) <span class="keyword">for</span> t <span class="keyword">in</span> saying]</div><div class="line">    result_lancaster = [lancaster.stem(t) <span class="keyword">for</span> t <span class="keyword">in</span> saying]</div><div class="line">    print(result_porter)</div><div class="line">    print(result_lancaster)</div></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>32.◑ Define a variable silly to contain the string: <strong>‘newly formed bland ideas are inexpressible in an infuriating way’</strong>. (This happens to be the legitimate inter- pretation that bilingual English-Spanish speakers can assign to Chomsky’s famous nonsense phrase <strong><em>colorless green ideas sleep furiously</em></strong>, according to Wikipedia). Now write code to perform the following tasks:</p>
<ol>
<li>Split <strong>silly</strong> into a list of strings, one per word, using Python’s <strong>split()</strong> opera- tion, and save this to a variable called <strong>bland</strong>.</li>
<li>Extract the second letter of each word in <strong>silly</strong> and join them into a string, to get <strong>‘eoldrnnnna’</strong>.</li>
</ol>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">test32</span><span class="params">()</span>:</span></div><div class="line">    silly=<span class="string">'newly formed bland ideas are inexpressible in an infuriating way'</span></div><div class="line">    bland = silly.split()</div><div class="line">    print(bland)</div><div class="line">    result = <span class="string">''</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(bland)):</div><div class="line">        result = result + bland[i][<span class="number">1</span>]</div><div class="line">    print(result,type(result))</div></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>35.◑ Read the LanguageLog post on phrases of the form <strong><em>as best as p can</em></strong> and <strong><em>as best p can</em></strong>, where <strong><em>p</em></strong> is a pronoun. Investigate this phenomenon with the help of a corpus and the <strong><code>findall()</code></strong> method for searching tokenized text described in Section 3.5. The post is at <em><a href="http://itre.cis.upenn.edu/~myl/languagelog/archives/002733.html" target="_blank" rel="external">http://itre.cis.upenn.edu/~myl/languagelog/archives/002733.html</a></em>.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">test35</span><span class="params">()</span>:</span></div><div class="line">    <span class="comment"># 为什么我的 brown.words()中没有 as best as p can 以及 as best p can 的形式？</span></div><div class="line">    text = nltk.Text(brown.words())</div><div class="line">    print(text)</div><div class="line">    print(text.findall(<span class="string">r'&lt;as&gt; &lt;\w*&gt; &lt;as&gt;'</span>))</div><div class="line">    <span class="keyword">print</span></div><div class="line">    print(text.findall(<span class="string">r'&lt;\w*&gt; &lt;and&gt; &lt;other&gt; &lt;\w*s&gt;'</span>))</div></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>37.◑ Read about the <strong><code>re.sub()</code></strong> function for string substitution using regular expres- sions, using <strong><code>help(re.sub)</code></strong> and by consulting the further readings for this chapter. Use <strong><code>re.sub</code></strong> in writing code to remove HTML tags from an HTML file, and to normalize whitespace.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">test37</span><span class="params">()</span>:</span></div><div class="line">    object = open(<span class="string">'Language Log: Asbestos she can.html'</span>)</div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        text = object.read()</div><div class="line">        pattern = <span class="string">'''(?x)</span></div><div class="line">        &lt;html&gt;</div><div class="line">        |&lt;/html&gt;</div><div class="line">'''</div><div class="line">        text = re.sub(pattern, <span class="string">''</span>, text)</div><div class="line">        object_copy = open(<span class="string">'text36.txt'</span>, <span class="string">'w+'</span>)</div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            object_copy.write(text)</div><div class="line">        <span class="keyword">finally</span>:</div><div class="line">            object_copy.close()</div><div class="line"></div><div class="line">    <span class="keyword">finally</span>:</div><div class="line">        object.close()</div></pre></td></tr></table></figure>
<hr>
<h1 id="Still-have-Question"><a href="#Still-have-Question" class="headerlink" title="Still have Question:"></a>Still have Question:</h1><ul>
<li><strong>暂无</strong> </li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文是关于「Natural Language Processing with Python」这本书的 Chapter 3 的学习笔记。
    
    </summary>
    
      <category term="NLP" scheme="http://randolph.pro/categories/NLP/"/>
    
      <category term="Book:「NLP with Python」" scheme="http://randolph.pro/categories/NLP/Book-%E3%80%8CNLP-with-Python%E3%80%8D/"/>
    
    
      <category term="NLP" scheme="http://randolph.pro/tags/NLP/"/>
    
      <category term="Python" scheme="http://randolph.pro/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>♞「NLP with Python」 Chapter 1 &amp; 2</title>
    <link href="http://randolph.pro/2015/09/11/%3CNatural%20Language%20Processing%20with%20Python%3E%20Chapter%201%20&amp;%202/"/>
    <id>http://randolph.pro/2015/09/11/&lt;Natural Language Processing with Python&gt; Chapter 1 &amp; 2/</id>
    <published>2015-09-10T16:00:00.000Z</published>
    <updated>2017-07-25T13:22:50.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fhu96awavpj30yg1cp1kx.jpg" alt=""></p>
<p>关于该书的其他学习笔记系列：<a href="http://randolph.pro/categories/NLP/Book-「NLP-with-Python」/">「NLP with Python」</a></p>
<h1 id="Related"><a href="#Related" class="headerlink" title="Related"></a>Related</h1><ul>
<li><strong>NLTK</strong></li>
<li><strong>concordance() function</strong></li>
<li><strong>Word Sense Disambiguation &amp; Pronoun Resolution</strong></li>
<li><strong>Text Corpus Structure</strong></li>
<li><strong>WordNet</strong></li>
</ul>
<hr>
<h1 id="Key"><a href="#Key" class="headerlink" title="Key:"></a>Key:</h1><h2 id="What’s-NTLK"><a href="#What’s-NTLK" class="headerlink" title="What’s NTLK?"></a><strong>What’s NTLK?</strong></h2><p>NTLK 是一个自然语言工具包，最初创建于 2001 年，最初是宾州大学计算机与信息科学系计算语言学课程的一部分，大部分 NLP 研究者入门的首选 tool。</p>
<p>另外，这本书是关于用 Python 进行自然语言处理的一本入门书，基本上可以看做是 NLTK 这个库的 HandBook，使用的方法均是 nltk 库中的方法。如果希望查阅 API 文档或者是下载安装 NLTK，可以前往 <a href="http://www.nltk.org" target="_blank" rel="external"> 官方网站 </a> 下载，官网上提供和的 API 文档涵盖了工具包中的每一个模块、类和函数，详细说明了各种参数，以及用法示例，在此不再赘述。</p>
<ul>
<li><strong>简单介绍一下 NLTK 的几个重要的模块以及功能描述：</strong></li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>语言处理任务</th>
<th>NLTK 模块</th>
<th>功能描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>获取语料库</td>
<td>nltk.corpus</td>
<td>语料库和字典的标准化接口</td>
</tr>
<tr>
<td>字符串处理</td>
<td>nltk.tokenize, nltk.stem</td>
<td>分词、句子分解、提取主干</td>
</tr>
<tr>
<td>搭配探究</td>
<td>nltk.collocations</td>
<td>t- 检验、卡方、点互信息</td>
</tr>
<tr>
<td>词性标识符</td>
<td>nltk.tag</td>
<td>n-gram、backoff、Brill、HMM、TnT</td>
</tr>
<tr>
<td>分类</td>
<td>nltk.classify，nltk.cluster</td>
<td>决策树、最大熵、朴素贝叶斯、EM、k-means</td>
</tr>
<tr>
<td>分块</td>
<td>nltk.chunk</td>
<td>正则表达式、n-gram、命名实体</td>
</tr>
<tr>
<td>解析</td>
<td>nltk.parse</td>
<td>图表、基于特征、一致性、概率性、依赖项</td>
</tr>
<tr>
<td>语义解释</td>
<td>nltk.sem，nltk.inference</td>
<td>ℷ 演算、一阶逻辑、模型检验</td>
</tr>
<tr>
<td>指标评测</td>
<td>nltk.metrice</td>
<td>精度、召回率、协议系数</td>
</tr>
<tr>
<td>概率与估计</td>
<td>nltk.probability</td>
<td>频率分布、平滑概率分布</td>
</tr>
<tr>
<td>应用</td>
<td>nltk.app，nltk.chat</td>
<td>图形化的关键词排序、分析器、WordNet 查看器、聊天机器人</td>
</tr>
<tr>
<td>语言学领域的工作</td>
<td>nltk.toolbox</td>
<td>处理 SIL 数据格式的工具箱</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h2 id="concordance-function"><a href="#concordance-function" class="headerlink" title="concordance function"></a><em>concordance</em> <strong>function</strong></h2><ul>
<li><strong>concordance</strong> 函数：这个函数挺有意思的，是 nltk 下的一个函数，可以显示指定单词的出现情况（使用这个函数，指定单词的大小写不敏感），同时还可以显示一些上下文。下面是该函数的使用场景（其中 text1 的内容是 nltk.book 导入后中的 text1）:</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; text1.concordance(&quot;monstrous&quot;)</div><div class="line">    Building index...</div><div class="line">    Displaying 11 of 11 matches:</div><div class="line">    ong the former , one was of a most monstrous size . ... This came towards us ,</div><div class="line">    ON OF THE PSALMS . &quot; Touching that monstrous bulk of the whale or ork we have r</div><div class="line">    ll over with a heathenish array of monstrous clubs and spears . Some were thick</div><div class="line">    d as you gazed , and wondered what monstrous cannibal and savage could ever hav</div><div class="line">    that has survived the flood ; most monstrous and most mountainous ! That Himmal</div><div class="line">    they might scout at Moby Dick as a monstrous fable , or still worse and more de</div><div class="line">    th of Radney .&apos;&quot; CHAPTER 55 Of the monstrous Pictures of Whales . I shall ere l</div><div class="line">    ing Scenes . In connexion with the monstrous pictures of whales , I am strongly</div><div class="line">    ere to enter upon those still more monstrous stories of them which are to be fo</div></pre></td></tr></table></figure>
<p>这个函数的具体实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">concordance</span><span class="params">(self, word, width=<span class="number">79</span>, lines=<span class="number">25</span>)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Print a concordance for ``word`` with the specified context window.</div><div class="line">    Word matching is not case-sensitive.</div><div class="line">    :seealso: ``ConcordanceIndex``</div><div class="line">"""</div><div class="line">    </div><div class="line">    <span class="keyword">if</span> <span class="string">'_concordance_index'</span> <span class="keyword">not</span> <span class="keyword">in</span> self.__dict__:</div><div class="line">        print(<span class="string">"Building index..."</span>)</div><div class="line">        self._concordance_index = ConcordanceIndex(self.tokens,</div><div class="line">                                                   key=<span class="keyword">lambda</span> s:s.lower())</div><div class="line"></div><div class="line">    self._concordance_index.print_concordance(word, width, lines)</div></pre></td></tr></table></figure>
<hr>
<h2 id="Word-Sense-Disambiguation-amp-Pronoun-Resolution"><a href="#Word-Sense-Disambiguation-amp-Pronoun-Resolution" class="headerlink" title="Word Sense Disambiguation &amp; Pronoun Resolution"></a>Word Sense Disambiguation &amp; Pronoun Resolution</h2><ul>
<li>Word Sense Disambiguation</li>
</ul>
<p>词义消歧，简而言之，我们需要做的就是分析出特定上下文中的词被赋予的是哪个意思。例如：</p>
<blockquote>
<p>a. <strong>serve</strong>: help with food or drink; hold an office; put ball into  play </p>
<p>b. <strong>dish</strong>: plate; course of a meal; communications device</p>
</blockquote>
<ul>
<li>Pronoun Resolution</li>
</ul>
<p>指代消解，是解决“词义消歧”的一个手段，解决“谁对谁做了什么”，即检测动词的主语和宾语，另外还有 <strong> 语义角色标注</strong>（semantic role labing）— 确定名词短语如何与动词相关联（如代理、受事、工具等）。</p>
<hr>
<h2 id="Text-Corpus-Structure"><a href="#Text-Corpus-Structure" class="headerlink" title="Text Corpus Structure"></a>Text Corpus Structure</h2><p>以下是几种常见的语料库结构：<br><img src="https://farm1.staticflickr.com/445/31263100710_d839312795_o.png" alt=""></p>
<ul>
<li>最简单的一种语料库是一些孤立的没有什么特别结构的文本集合；</li>
<li>一些语料库按如文体（布朗语料库）等分类成组织结构；</li>
<li>一些分类会重叠，如主题类别（路透社语料库）；</li>
<li>另外一些语料库可以表示随时间变化，语言用法的改变（就职演说语料库）；</li>
</ul>
<hr>
<h2 id="WordNet"><a href="#WordNet" class="headerlink" title="WordNet"></a>WordNet</h2><ul>
<li>Senses and Synonyms.（意义与同义词）</li>
<li>Synonyms and Synset.（同义词集与词条）</li>
<li>The WordNet Hierarchy.（WordNet 的层次结构）</li>
</ul>
<blockquote>
<p>WordNet synsets correspond to abstract concepts, and they don’t always have corre- sponding words in English. These concepts are linked together in a hierarchy. Some concepts are very general, such as Entity, State, Event; these are called unique begin- ners or root synsets. Others, such as gas guzzler and hatchback, are much more specific.</p>
</blockquote>
<p>WordNet 概念的层次片段：每个节点对应一个同义词集；边表示上位词 / 下位词关系，即上级概念与从属概念的关系。<br><img src="https://farm1.staticflickr.com/474/31598383846_537809b299_o.png" alt=""></p>
<ul>
<li>Hyponyms and Hypernyms.（下位词与上位词）</li>
<li>Antonyms.（反义词）</li>
</ul>
<hr>
<h1 id="Correct-errors-in-printing"><a href="#Correct-errors-in-printing" class="headerlink" title="Correct errors in printing:"></a>Correct errors in printing:</h1><p>P19.</p>
<p>在 「Your Trun」 的那块内容中：</p>
<blockquote>
<p>使用 text2 尝试前面频率分布的例子。…如果得到的是错误信息：NameError: name ‘FreqDist’is not defined，则需要在一开始输入  <strong><code>nltk.book import *</code></strong>。</p>
</blockquote>
<p>需更正为：</p>
<blockquote>
<p>使用 text2 尝试前面频率分布的例子。…如果得到的是错误信息：NameError: name ‘FreqDist’is not defined，则需要在一开始输入 <strong><code>nltk.import *</code></strong>。</p>
</blockquote>
<p><strong>原因：nltk.book 中并不存在 <code>FreqDist()</code> 这一 function.</strong></p>
<hr>
<p>P48.</p>
<p>在 [Inaugural Address Corpus] 的那块代码部分中：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; cfd = nltk.ConditionalFreqDist(</div><div class="line">    ...           (target, file[:4])</div><div class="line">    ...           <span class="keyword">for</span> fileid <span class="keyword">in</span> inaugural.fileids()</div></pre></td></tr></table></figure></p>
<p>需更正为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; cfd = nltk.ConditionalFreqDist(</div><div class="line">    ...           (target, fileid[:4])</div><div class="line">    ...           <span class="keyword">for</span> fileid <span class="keyword">in</span> inaugural.fileids()</div></pre></td></tr></table></figure>
<hr>
<h1 id="Practice"><a href="#Practice" class="headerlink" title="Practice:"></a>Practice:</h1><blockquote>
<p>6.○ In the discussion of comparative wordlists, we created an object called <strong>translate</strong>, which you could look up using words in both German and Italian in order to get corresponding words in English. What problem might arise with this approach? Can you suggest a way to avoid this problem?</p>
</blockquote>
<ul>
<li>如果输入错误（不存在的词语或者其他没有通过 <code>translate.update(dict(xx))</code> 加入字典的语言词语，则会引发 <strong>KeyError</strong>）。其中一个解决办法是，添加一个错误处理情况。</li>
</ul>
<blockquote>
<p>8.◑ Define a conditional frequency distribution over the Names Corpus that allows you to see which initial letters are more frequent for males versus females (see Figure 2-7).</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; cfd = nltk.ConditionalFreqDist((fileid, name[1]</div><div class="line">    ...                             <span class="keyword">for</span> fileid <span class="keyword">in</span> names.fileids()</div><div class="line">    ...                             <span class="keyword">for</span> name <span class="keyword">in</span> names.words(fileid))</div></pre></td></tr></table></figure>
<blockquote>
<p>14.◑ Define a function <strong><code>supergloss(s)</code></strong> that takes a synset s as its argument and returns a string consisting of the concatenation of the definition of <strong>s</strong>, and the definitions of all the hypernyms and hyponyms of <strong>s</strong>.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">supergloss</span><span class="params">(s)</span>:</span></div><div class="line">    s = wn.synset(<span class="string">'s'</span>)</div><div class="line">    hyponyms_of_s = s.hyponyms()</div><div class="line">    hypernyms_of_s = s.hypernyms()</div><div class="line">    <span class="keyword">return</span> str(s) + str(hyponyms_of_s) + str(hypernyms_of_s)</div></pre></td></tr></table></figure>
<blockquote>
<p>17.◑ Write a function that finds the 50 most frequently occurring words of a text that are not stopwords.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">most_fifty_words</span><span class="params">(text)</span>:</span></div><div class="line">    stopwords = nltk.corpus.stopwords.words(<span class="string">'english'</span>)</div><div class="line">    content = [w <span class="keyword">for</span> w <span class="keyword">in</span> text <span class="keyword">if</span> w.lower() <span class="keyword">not</span> <span class="keyword">in</span> stopwords]</div><div class="line">    fdist = FreqDist(content)</div><div class="line">    vocabulary = list(fdist.keys())</div><div class="line">    <span class="keyword">return</span> vocabulary[:<span class="number">50</span>]</div></pre></td></tr></table></figure>
<hr>
<h1 id="Still-have-Question"><a href="#Still-have-Question" class="headerlink" title="Still have Question:"></a>Still have Question:</h1><ul>
<li><strong>暂无</strong> </li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文是关于「Natural Language Processing with Python」这本书的 Chapter 1 &amp; 2 的学习笔记。
    
    </summary>
    
      <category term="NLP" scheme="http://randolph.pro/categories/NLP/"/>
    
      <category term="Book:「NLP with Python」" scheme="http://randolph.pro/categories/NLP/Book-%E3%80%8CNLP-with-Python%E3%80%8D/"/>
    
    
      <category term="NLP" scheme="http://randolph.pro/tags/NLP/"/>
    
      <category term="Python" scheme="http://randolph.pro/tags/Python/"/>
    
  </entry>
  
</feed>
