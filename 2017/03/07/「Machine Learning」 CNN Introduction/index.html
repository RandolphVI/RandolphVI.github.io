<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="baidu-site-verification" content="IYvqjZ3csg" />
<meta name="google-site-verification" content="o9GDuh4E6CmwFpEqUYW7VMmq_fysc1_3PpSQSNWSD8Y" />


  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-mac-osx.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Machine Learning," />





  <link rel="alternate" href="/atom.xml" title="黃某人" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="本文主要介绍 Deep Learning 中的 CNN 卷积神经网络。">
<meta name="keywords" content="Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="「Machine Learning」 CNN Introduction">
<meta property="og:url" content="http://randolph.pro/2017/03/07/「Machine Learning」 CNN Introduction/index.html">
<meta property="og:site_name" content="黃某人">
<meta property="og:description" content="本文主要介绍 Deep Learning 中的 CNN 卷积神经网络。">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://farm5.staticflickr.com/4300/35460446383_aafc34ca3c_o.jpg">
<meta property="og:image" content="https://farm3.staticflickr.com/2446/32873275652_9f6261728c_o.png">
<meta property="og:image" content="https://farm3.staticflickr.com/2563/32873276412_6330affec6_o.png">
<meta property="og:image" content="https://farm3.staticflickr.com/2233/32873279482_bf439eb5c7_o.gif">
<meta property="og:image" content="https://farm1.staticflickr.com/711/32873351892_a02b2be853_o.png">
<meta property="og:image" content="https://farm3.staticflickr.com/2919/32213941213_beabd8f9e5_o.png">
<meta property="og:image" content="https://farm3.staticflickr.com/2235/32902525261_d8091fe768_o.gif">
<meta property="og:image" content="https://farm3.staticflickr.com/2929/32183844484_8be44cdea0_o.png">
<meta property="og:image" content="https://farm3.staticflickr.com/2745/32986518056_d320066568_o.png">
<meta property="og:image" content="https://farm3.staticflickr.com/2421/32214171823_0cbab38971_o.png">
<meta property="og:image" content="https://farm3.staticflickr.com/2929/33186208875_5ab850f2ab_o.png">
<meta property="og:image" content="https://farm4.staticflickr.com/3852/32803703170_7605fcdbc2_o.png">
<meta property="og:image" content="https://farm3.staticflickr.com/2036/32647435560_470bdc2c7b_o.png">
<meta property="og:image" content="https://farm3.staticflickr.com/2202/32873928362_3a7b8b86cf_o.png">
<meta property="og:image" content="https://farm4.staticflickr.com/3881/32214568423_416fed1642_o.png">
<meta property="og:image" content="https://farm3.staticflickr.com/2044/32988985296_3a7106f13d_o.png">
<meta property="og:image" content="https://farm1.staticflickr.com/350/32875720272_88dd409c3f_o.png">
<meta property="og:image" content="https://farm1.staticflickr.com/739/32216466493_38095200db_o.png">
<meta property="og:image" content="https://farm3.staticflickr.com/2113/32875828582_ce237c84d2_o.png">
<meta property="og:image" content="https://farm4.staticflickr.com/3738/33031508435_aee3cd62ca_o.png">
<meta property="og:image" content="https://farm4.staticflickr.com/3934/32186606394_d904c8de2e_o.png">
<meta property="og:image" content="https://farm1.staticflickr.com/682/32186608014_f69038eb43_o.png">
<meta property="og:image" content="https://farm3.staticflickr.com/2830/32216998463_c7897cf1d5_o.png">
<meta property="og:updated_time" content="2017-08-17T15:22:49.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="「Machine Learning」 CNN Introduction">
<meta name="twitter:description" content="本文主要介绍 Deep Learning 中的 CNN 卷积神经网络。">
<meta name="twitter:image" content="https://farm5.staticflickr.com/4300/35460446383_aafc34ca3c_o.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"right","display":"hide","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: 'KGO9YVRPZZ',
      apiKey: 'dcf60767769bda7791ae195caf3dfb10',
      indexName: 'Randolph',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://randolph.pro/2017/03/07/「Machine Learning」 CNN Introduction/"/>





  <title>「Machine Learning」 CNN Introduction | 黃某人</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?80985281ddae6899cfd57ad9d458b284";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->










</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-right page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">黃某人</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">痴</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  
  <div class="algolia-popup popup search-popup">
    <div class="algolia-search">
      <div class="algolia-search-input-icon">
        <i class="fa fa-search"></i>
      </div>
      <div class="algolia-search-input" id="algolia-search-input"></div>
    </div>

    <div class="algolia-results">
      <div id="algolia-stats"></div>
      <div id="algolia-hits"></div>
      <div id="algolia-pagination" class="algolia-pagination"></div>
    </div>

    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>




    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://randolph.pro/2017/03/07/「Machine Learning」 CNN Introduction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Randolph">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="黃某人">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">「Machine Learning」 CNN Introduction</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-plus-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-07T00:00:00+08:00">
                2017-03-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/07/「Machine Learning」 CNN Introduction/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/03/07/「Machine Learning」 CNN Introduction/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2017/03/07/「Machine Learning」 CNN Introduction/" class="leancloud_visitors" data-flag-title="「Machine Learning」 CNN Introduction">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-fire"></i>
               </span>
               <span class="leancloud-visitors-count"></span>
               <span>℃</span>
               <span class="post-meta-divider">|</span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                <span title="Words count in article">
                  6,154
                </span>
                <span> words </span>
                
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                <span title="Reading time">
                  22
                </span>
                <span> mins </span>
              
            </div>
          

          
              <div class="post-description">
                  本文主要介绍 Deep Learning 中的 CNN 卷积神经网络。
              </div>
          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><img src="https://farm5.staticflickr.com/4300/35460446383_aafc34ca3c_o.jpg" alt=""></p>
<p>有关「Machine Learning」的其他学习笔记系列：<a href="http://randolph.pro/categories/Machine-Learning/">「Machine Learning」</a></p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>在 20 世纪 60 年代，Hubel 和 Wiesel 在研究猫脑皮层中用于局部敏感和方向选择的神经元时发现其独特的网络结构可以有效地降低反馈神经网络的复杂性，继而出了卷积神经网络（Convolutional Neural Networks- 简称 CNN）。</p>
<p>卷积神经网络（Convolutional Neural Network）虽然很早被出，但是却是近些年才得以发展起来并引起广泛重视的。它是深度学习技术中极具代表的网络结构之一，也是近些年语音分析和图像识别领域的研究热点，后来发现其在 NLP 自然语言处理上的效果同样不俗。它以其特有的局部连接、权值共享网络结构，有效地降低了深度神经网络模型的复杂度，极大地减少了权值的数量。</p>
<h2 id="Perceptron"><a href="#Perceptron" class="headerlink" title="Perceptron"></a>Perceptron</h2><p>在理解 CNN 卷积神经网络之前，有必要了解神经网络的机制以及缺点，而其中典型的神经元网络就是 MLP （Multi-Layer Perceptron）多层感知器。</p>
<p>而多层感知器中的 Multi-Layer 是针对单层感知器（Perceptron）而言，单层感知器是最简单的前馈人工神经网络，就是通常人们所说的“神经元”。 </p>
<p>而单层感知器的基本结构如图所示，其以一个实数向量作为输入，计算这些输入的线性组合，若结果大于某个阈值则输出 1，否则输出 0。</p>
<h1 id=""><a href="#"class="headerlink"title="#"></a>#</h1><h2 id="Build-a-Multilayer-Convolutional-Network"><a href="#Build-a-Multilayer-Convolutional-Network"class="headerlink"title="Build a Multilayer Convolutional Network"></a>Build a Multilayer Convolutional Network</h2><p>在 CNN 卷积神经网络中，主要有四个操作：</p>
<ol>
<li>卷积</li>
<li>非线性处理（ReLU）</li>
<li>池化或者亚采样</li>
<li>分类（全连接层）</li>
</ol>
<p>这些操作对于各个卷积神经网络来说都是基本组件，因此理解它们的工作原理有助于充分了解卷积神经网络。下面我们将会尝试理解各步操作背后的原理。</p>
<h2 id="What’s-CNN"><a href="#What’s-CNN" class="headerlink" title="What’s CNN"></a>What’s CNN</h2><h3 id="Convolution"><a href="#Convolution" class="headerlink" title="Convolution"></a>Convolution</h3><p>卷积的主要目的是为了从输入图像中提取特征。卷积可以通过从输入的一小块数据中学到图像的特征，并可以保留像素间的空间关系。让我们举个例子来尝试理解一下卷积是如何处理图像的：</p>
<p>正如我们上面所说，每张图像都可以看作是像素值的矩阵。考虑一下一个 5 x 5 的图像，它的像素值仅为 0 或者 1（注意对于灰度图像而言，像素值的范围是 0 到 255，下面像素值为 0 和 1 的绿色矩阵仅为特例）：</p>
<p><img src="https://farm3.staticflickr.com/2446/32873275652_9f6261728c_o.png" alt=""></p>
<p>同时，考虑下另一个 3 x 3 的矩阵，如下所示：</p>
<p><img src="https://farm3.staticflickr.com/2563/32873276412_6330affec6_o.png" alt=""></p>
<p>接下来，5 x 5 的图像和 3 x 3 的矩阵的卷积可以按下图所示的动画一样计算：</p>
<p><img src="https://farm3.staticflickr.com/2233/32873279482_bf439eb5c7_o.gif" alt=""></p>
<p>现在停下来好好理解下上面的计算是怎么完成的。我们用橙色的矩阵在原始图像（绿色）上滑动，每次滑动一个像素（也叫做「步长」），在每个位置上，我们计算对应元素的乘积（两个矩阵间），并把乘积的和作为最后的结果，得到输出矩阵（粉色）中的每一个元素的值。注意，3 x 3 的矩阵每次步长中仅可以看到输入图像的一部分。</p>
<p>在 CNN 的术语中，3x3 的矩阵叫做「滤波器」(filter) 或「核」(kernel) 或者 「特征检测器」(feature detector)，通过在图像上滑动滤波器并计算点乘得到矩阵叫做「卷积特征」(Convolved Feature) 或者 「激活图」(Activation Map) 或者 「特征图」(Feature Map)。记住，滤波器在原始输入图像上的作用是特征检测器。</p>
<p>从上面图中的动画可以看出，对于同样的输入图像，不同值的滤波器将会生成不同的特征图。比如，对于下面这张输入图像：</p>
<p><img src="https://farm1.staticflickr.com/711/32873351892_a02b2be853_o.png" alt=""></p>
<p>在下表中，我们可以看到不同滤波器对上图卷积的效果。正如表中所示，通过在卷积操作前修改滤波矩阵的数值，我们可以进行诸如边缘检测、锐化和模糊等操作 —— 这表明不同的滤波器可以从图中检测到不同的特征，比如边缘、曲线等。</p>
<p><img style="width:50%" src="https://farm3.staticflickr.com/2919/32213941213_beabd8f9e5_o.png"></p>
<p>另一个直观理解卷积操作的好方法是看下面这张图的动画：</p>
<p><img src="https://farm3.staticflickr.com/2235/32902525261_d8091fe768_o.gif" alt=""></p>
<p>滤波器（红色框）在输入图像滑过（卷积操作），生成一个特征图。另一个滤波器（绿色框）在同一张图像上卷积可以得到一个不同的特征图。注意卷积操作可以从原图上获取局部依赖信息。同时注意这两个不同的滤波器是如何从同一张图像上生成不同的特征图。记住上面的图像和两个滤波器仅仅是我们上面讨论的数值矩阵。</p>
<p>在实践中，CNN 会在训练过程中学习到这些滤波器的值（尽管我们依然需要在训练前指定诸如滤波器的个数、滤波器的大小、网络架构等参数）。我们使用的滤波器越多，提取到的图像特征就越多，网络所能在未知图像上识别的模式也就越好。</p>
<p>特征图的大小（卷积特征）由下面三个参数控制，我们需要在卷积前确定它们：</p>
<ul>
<li><p>深度（Depth）：<strong>深度对应的是卷积操作所需的滤波器个数</strong>。在下图的网络中，我们使用三个不同的滤波器对原始图像进行卷积操作，这样就可以生成三个不同的特征图。你可以把这三个特征图看作是堆叠的 2d 矩阵，那么，特征图的「深度」就是 3。</p>
</li>
<li><p>步长（Stride）：<strong>步长是我们在输入矩阵上滑动滤波矩阵的像素数</strong>。当步长为 1 时，我们每次移动滤波器一个像素的位置。当步长为 2 时，我们每次移动滤波器会跳过 2 个像素。步长越大，将会得到更小的特征图。</p>
</li>
<li><p>零填充（Zero-padding）：<strong>有时，在输入矩阵的边缘使用零值进行填充，这样我们就可以对输入图像矩阵的边缘进行滤波。</strong>零填充的一大好处是可以让我们控制特征图的大小。使用零填充的也叫做泛卷积，不适用零填充的叫做严格卷积。</p>
<p><img style="width:50%" src="https://farm3.staticflickr.com/2929/32183844484_8be44cdea0_o.png"></p>
</li>
</ul>
<h3 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h3><p>ReLU 表示修正线性单元（Rectified Linear Unit），是一个非线性操作。</p>
<p><img style="width:50%" src="https://farm3.staticflickr.com/2745/32986518056_d320066568_o.png"></p>
<script type="math/tex; mode=display">
Output = Max(zero, Input)</script><ol>
<li><p>为什么要引入非线性激励函数？</p>
<p>如果不用激励函数（其实相当于激励函数是 $f(x) = x$ ），在这种情况下你每一层输出都是上层输入的线性函数，很容易验证，无论你神经网络有多少层，输出都是输入的线性组合，与没有隐层效果相当，这种情况就是最原始的感知机（Perceptron）了。</p>
<p>正因为上面的原因，我们决定引入非线性函数作为激励函数，这样深层神经网络就有意义了（不再是输入的线性组合，可以逼近任意函数）。最早的想法是 sigmoid 函数或者 tanh 函数，输出有界，很容易充当下一层输入（以及一些人的生物解释 balabala）。</p>
</li>
<li><p>为什么要引入 ReLU 而不是其他的非线性函数（例如 Sigmoid 函数）？</p>
<ul>
<li>采用 sigmoid 等函数，<strong>算激活函数时（指数运算），计算量大</strong>，反向传播求误差梯度时，求导涉及除法，计算量相对大，而采用 Relu 激活函数，整个过程的计算量节省很多。</li>
<li>对于深层网络，<strong>sigmoid 函数反向传播时，很容易就会出现梯度消失的情况 </strong>（在 sigmoid 接近饱和区时，变换太缓慢，导数趋于 0，这种情况会造成<strong> 信息丢失</strong>），从而无法完成深层网络的训练。</li>
<li><strong>Relu 会使一部分神经元的输出为 0，这样就造成了网络的稀疏性，并且减少了参数的相互依存关系，缓解了过拟合问题的发生</strong>（以及一些人的生物解释 balabala）。</li>
</ul>
<p>当然现在也有一些对 relu 的改进，比如 prelu，random relu 等，在不同的数据集上会有一些训练速度上或者准确率上的改进，具体的可以找相关的 paper 看。</p>
<p>（多加一句，现在主流的做法，会多做一步 batch normalization，尽可能保证每一层网络的输入具有相同的分布。而最新的 paper，他们在加入 bypass connection 之后，发现改变 batch normalization 的位置会有更好的效果。）</p>
</li>
<li><p>ReLU 的优点与缺点？</p>
<p>优点：</p>
<ul>
<li>解决了 gradient vanishing 问题 (在正区间)</li>
<li>计算速度非常快，只需要判断输入是否大于 0</li>
<li>收敛速度远快于 sigmoid 和 tanh</li>
</ul>
<p>缺点：</p>
<ul>
<li>ReLU 的输出不是 zero-centered</li>
<li><strong>Dead ReLU Problem</strong>，指的是某些神经元可能永远不会被激活，导致相应的参数永远不能被更新。有两个主要原因可能导致这种情况产生: (1) 非常不幸的参数初始化，这种情况比较少见 (2) learning rate 太高导致在训练过程中参数更新太大，不幸使网络进入这种状态。解决方法是可以采用 Xavier 初始化方法，以及避免将 learning rate 设置太大或使用 adagrad 等自动调节 learning rate 的算法。</li>
</ul>
</li>
</ol>
<blockquote>
<p>几十年的机器学习发展中，我们形成了这样一个概念：非线性激活函数要比线性激活函数更加先进。</p>
<p>尤其是在布满 Sigmoid 函数的 BP 神经网络，布满径向基函数的 SVM 神经网络中，往往有这样的幻觉，非线性函数对非线性网络贡献巨大。</p>
<p>该幻觉在 SVM 中更加严重。核函数的形式并非完全是 SVM 能够处理非线性数据的主力功臣（支持向量充当着隐层角色）。</p>
<p>那么在深度网络中，对非线性的依赖程度就可以缩一缩。另外，在上一部分提到，稀疏特征并不需要网络具有很强的处理线性不可分机制。</p>
<p>综合以上两点，在深度学习模型中，使用简单、速度快的线性激活函数可能更为合适。</p>
</blockquote>
<p>ReLU 操作可以从下面的图中理解。这里的输出特征图也可以看作是“修正”过的特征图。</p>
<p><img style="width:80%" src="https://farm3.staticflickr.com/2421/32214171823_0cbab38971_o.png"></p>
<p>所谓麻雀虽小，五脏俱全，ReLU 虽小，但也是可以改进的。</p>
<h4 id="ReLU 的种类"><a href="#ReLU 的种类" class="headerlink" title="ReLU 的种类"></a>ReLU 的种类</h4><p><strong>ReLU 的区分主要在负数端，根据负数端斜率的不同来进行区分</strong>，大致如下图所示。</p>
<p><img src="https://farm3.staticflickr.com/2929/33186208875_5ab850f2ab_o.png" alt=""></p>
<p>普通的 ReLU 负数端斜率是 0，Leaky ReLU 则是负数端有一个比较小的斜率，而 PReLU 则是在后向传播中学习到斜率。而 Randomized Leaky ReLU 则是使用一个均匀分布在训练的时候随机生成斜率，在测试的时候使用均值斜率来计算。</p>
<h4 id="效果"><a href="# 效果" class="headerlink" title="效果"></a>效果 </h4><p> 其中，NDSB 数据集是 Kaggle 的比赛，而 RReLU 正是在这次比赛中崭露头角的。</p>
<p><img src="https://farm4.staticflickr.com/3852/32803703170_7605fcdbc2_o.png" alt=""></p>
<p>通过上述结果，可以看到四点：</p>
<ul>
<li>对于 Leaky ReLU 来说，如果斜率很小，那么与 ReLU 并没有大的不同，当斜率大一些时，效果就好很多。</li>
<li>在训练集上，PReLU 往往能达到最小的错误率，说明 PReLU 容易过拟合。</li>
<li>在 NSDB 数据集上 RReLU 的提升比 cifar10 和 cifar100 上的提升更加明显，而 NSDB 数据集比较小，从而可以说明，RReLU 在与过拟合的对抗中更加有效。</li>
<li>对于 RReLU 来说，还需要研究一下随机化得斜率是怎样影响训练和测试过程的。</li>
</ul>
<h4 id="参考文献"><a href="# 参考文献" class="headerlink" title="参考文献"></a>参考文献</h4><p>[1]. Xu B, Wang N, Chen T, et al. Empirical evaluation of rectified activations in convolutional network[J]. arXiv preprint arXiv:1505.00853, 2015.</p>
<h3 id="Pooling"><a href="#Pooling" class="headerlink" title="Pooling"></a>Pooling</h3><p>空间池化（Spatial Pooling）（也叫做亚采用或者下采样）<strong>降低了各个特征图的维度，但可以保持大部分重要的信息</strong>。空间池化有下面几种方式：最大化、平均化、加和等等。</p>
<p>对于最大池化（Max Pooling），我们定义一个空间邻域（比如，2x2 的窗口），并从窗口内的修正特征图中取出最大的元素。除了取最大元素，我们也可以取平均（Average Pooling）或者对窗口内的元素求和。<strong>在实际中，最大池化被证明效果更好一些。</strong></p>
<p>下面的图展示了使用 2x2 窗口在修正特征图（在卷积 + ReLU 操作后得到）使用最大池化的例子。</p>
<p><img style="width:50%" src="https://farm3.staticflickr.com/2036/32647435560_470bdc2c7b_o.png"></p>
<p>我们以 2 个元素（也叫做“步长”）滑动我们 2x2 的窗口，并在每个区域内取最大值。如上图所示，这样操作可以降低我们特征图的维度。</p>
<p>在下图展示的网络中，池化操作是分开应用到各个特征图的（注意，因为这样的操作，我们可以从三个输入图中得到三个输出图）。</p>
<p><img style="width:50%" src="https://farm3.staticflickr.com/2202/32873928362_3a7b8b86cf_o.png"></p>
<p>下图展示了我们在 ReLU 操作之后得到的修正特征图的池化操作的效果：</p>
<p><img style="width:80%" src="https://farm4.staticflickr.com/3881/32214568423_416fed1642_o.png"></p>
<p>池化函数可以逐渐降低输入表示的空间尺度。特别地，Pooling 的好处是:</p>
<ul>
<li><p>使输入表示（特征维度）变得更小，并且网络中的参数和计算的数量更加可控的减小，因此，可以控制过拟合。</p>
</li>
<li><p>使网络对于输入图像中更小的变化、冗余和变换变得不变性（输入的微小冗余将不会改变池化的输出——因为我们在局部邻域中使用了最大化 / 平均值的操作）。</p>
</li>
<li><p>帮助我们获取图像最大程度上的尺度不变性（准确的词是“不变性”）。它非常的强大，因为我们可以检测图像中的物体，无论它们位置在哪里。</p>
<p>​</p>
</li>
</ul>
<p>到目前为止我们了解了卷积、ReLU 和池化是如何操作的。理解这些层是构建任意 CNN 的基础是很重要的。正如下图所示，<strong>我们有两组卷积、ReLU &amp; 池化层 —— 第二组卷积层使用六个滤波器对第一组的池化层的输出继续卷积，得到一共六个特征图</strong>。接下来对所有六个特征图应用 ReLU。接着我们对六个修正特征图分别进行最大池化操作。</p>
<p>这些层一起就可以从图像中提取有用的特征，并在网络中引入非线性，减少特征维度，同时保持这些特征具有某种程度上的尺度变化不变性。</p>
<p><img src="https://farm3.staticflickr.com/2044/32988985296_3a7106f13d_o.png" alt=""></p>
<p>第二组池化层的输出作为全连接层的输入，接下来我们将介绍全连接层。</p>
<h3 id="Connect"><a href="#Connect" class="headerlink" title="Connect"></a>Connect</h3><p>全连接层是传统的多层感知器，在输出层使用的是 softmax 激活函数（也可以使用其他像 SVM 的分类器，但在本文中只使用 softmax）。「全连接」(Fully Connected) 这个词表明前面层的所有神经元都与下一层的所有神经元连接。</p>
<p>卷积和池化层的输出表示了输入图像的高级特征。全连接层的目的是为了使用这些特征把输入图像基于训练数据集进行分类。比如，在下面图中我们进行的图像分类有四个可能的输出结果（注意下图并没有显示全连接层的节点连接）。</p>
<p><img style="width:80%" src="https://farm1.staticflickr.com/350/32875720272_88dd409c3f_o.png"></p>
<p>除了分类，添加一个全连接层也（一般）是学习这些特征的非线性组合的简单方法。从卷积和池化层得到的大多数特征可能对分类任务有效，但这些特征的组合可能会更好。</p>
<p>从全连接层得到的输出概率和为 1。这个可以在输出层使用 softmax 作为激活函数进行保证。softmax 函数输入一个任意大于 0 值的矢量，并把它们转换为零一之间的数值矢量，其和为一。</p>
<h3 id="Use-Backpropagation-to-Train-whole-network"><a href="#Use-Backpropagation-to-Train-whole-network" class="headerlink" title="Use Backpropagation to Train whole network"></a>Use Backpropagation to Train whole network</h3><p>正如上面讨论的，卷积 + 池化层的作用是从输入图像中提取特征，而全连接层的作用是分类器。</p>
<p>注意在下面的图中，因为输入的图像是船，对于船这一类的目标概率是 1，而其他三类的目标概率是 0，即</p>
<ul>
<li><p>输入图像 = 船</p>
</li>
<li><p>目标矢量 = [0, 0, 1, 0]</p>
<p><img src="https://farm1.staticflickr.com/739/32216466493_38095200db_o.png" alt=""></p>
</li>
</ul>
<p>完整的卷积网络的训练过程可以总结如下：</p>
<ul>
<li>第一步：我们初始化所有的滤波器，使用随机值设置参数 / 权重</li>
<li>第二步：网络接收一张训练图像作为输入，通过前向传播过程（卷积、ReLU 和池化操作，以及全连接层的前向传播），找到各个类的输出概率</li>
<li><ul>
<li>我们假设船这张图像的输出概率是 [0.2, 0.4, 0.1, 0.3]</li>
<li>因为对于第一张训练样本的权重是随机分配的，输出的概率也是随机的</li>
</ul>
</li>
<li>第三步：在输出层计算总误差（计算 4 类的和）</li>
<li><ul>
<li>Total Error = ∑  ½ (target probability – output probability) ²</li>
</ul>
</li>
<li>第四步：使用反向传播算法，根据网络的权重计算误差的梯度，并使用梯度下降算法更新所有滤波器的值 / 权重以及参数的值，使输出误差最小化</li>
<li><ul>
<li>权重的更新与它们对总误差的占比有关</li>
<li>当同样的图像再次作为输入，这时的输出概率可能会是 [0.1, 0.1, 0.7, 0.1]，这就与目标矢量 [0, 0, 1, 0] 更接近了</li>
<li>这表明网络已经通过调节权重 / 滤波器，可以正确对这张特定图像的分类，这样输出的误差就减小了</li>
<li>像滤波器数量、滤波器大小、网络结构等这样的参数，在第一步前都是固定的，在训练过程中保持不变——仅仅是滤波器矩阵的值和连接权重在更新</li>
</ul>
</li>
<li>第五步：对训练数据中所有的图像重复步骤 1 ~ 4</li>
</ul>
<p>上面的这些步骤可以 <strong> 训练</strong> ConvNet —— 这本质上意味着对于训练数据集中的图像，ConvNet 在更新了所有权重和参数后，已经优化为可以对这些图像进行正确分类。</p>
<p>当一张新的（未见过的）图像作为 ConvNet 的输入，网络将会再次进行前向传播过程，并输出各个类别的概率（对于新的图像，输出概率是使用已经在前面训练样本上优化分类的参数进行计算的）。如果我们的训练数据集非常的大，网络将会（有希望）对新的图像有很好的泛化，并把它们分到正确的类别中去。</p>
<p><strong>注 1</strong>: 上面的步骤已经简化，也避免了数学详情，只为提供训练过程的直观内容。</p>
<p><strong>注 2</strong>: 在上面的例子中我们使用了两组卷积和池化层。然而请记住，这些操作可以在一个 ConvNet 中重复多次。实际上，现在有些表现最好的 ConvNet 拥有多达十几层的卷积和池化层！同时，每次卷积层后面不一定要有池化层。如下图所示，我们可以在池化操作前连续使用多个卷积 + ReLU 操作。还有，请注意 ConvNet 的各层在下图中是如何可视化的。</p>
<p><img style="width:80%" src="https://farm3.staticflickr.com/2113/32875828582_ce237c84d2_o.png"></p>
<h3 id="Visualization-on-CNN"><a href="#Visualization-on-CNN" class="headerlink" title="Visualization on CNN"></a>Visualization on CNN</h3><p>一般而言，越多的卷积步骤，网络可以学到的识别特征就越复杂。比如，ConvNet 的图像分类可能在第一层从原始像素中检测出边缘，然后在第二层使用边缘检测简单的形状，接着使用这些形状检测更高级的特征，比如更高层的人脸。下面的图中展示了这些内容——我们使用 <a href="http://web.eecs.umich.edu/~honglak/icml09-ConvolutionalDeepBeliefNetworks.pdf" target="_blank" rel="external"> 卷积深度置信网络 </a> 学习到的特征，这张图仅仅是用来证明上面的内容（这仅仅是一个例子：真正的卷积滤波器可能会检测到对我们毫无意义的物体）。</p>
<p><img src="https://farm4.staticflickr.com/3738/33031508435_aee3cd62ca_o.png" alt=""></p>
<p>Adam Harley 创建了一个卷积神经网络的可视化结果，使用的是 MNIST 手写数字的训练集。我强烈建议使用它来理解 CNN 的工作原理。</p>
<p>我们可以在下图中看到网络是如何识别输入 「8」 的。注意下图中的可视化并没有单独展示 ReLU 操作。</p>
<p><img src="https://farm4.staticflickr.com/3934/32186606394_d904c8de2e_o.png" alt=""></p>
<p>输入图像包含 1024 个像素（32 x 32 大小），第一个卷积层（卷积层 1）由六个独特的 5x5 （步长为 1）的滤波器组成。如图可见，使用六个不同的滤波器得到一个深度为六的特征图。</p>
<p>卷积层 1 后面是池化层 1，在卷积层 1 得到的六个特征图上分别进行 2x2 的最大池化（步长为 2）的操作。你可以在池化层上把鼠标移动到任意的像素上，观察在前面卷积层（如上图所示）得到的 4x4 的小格。你会发现 4x4 小格中的最大值（最亮）的像素将会进入到池化层。</p>
<p><img src="https://farm1.staticflickr.com/682/32186608014_f69038eb43_o.png" alt=""></p>
<p>池化层 1 后面的是六个 5x5 （步长为 1）的卷积滤波器，进行卷积操作。后面就是池化层 2，进行 2x2 的最大池化（步长为 2）的操作。这两层的概念和前面描述的一样。</p>
<p>接下来我们就到了三个全连接层。它们是：</p>
<ul>
<li>第一个全连接层有 120 个神经元</li>
<li>第二层全连接层有 100 个神经元</li>
<li>第三个全连接层有 10 个神经元，对应 10 个数字——也就做输出层</li>
</ul>
<p>注意在下图中，输出层中的 10 个节点的各个都与第二个全连接层的所有 100 个节点相连（因此叫做全连接）。</p>
<p>同时，注意在输出层那个唯一的亮的节点是如何对应于数字 “8” 的——这表明网络把我们的手写数字正确分类（越亮的节点表明从它得到的输出值越高，即，8 是所有数字中概率最高的）。</p>
<p><img src="https://farm3.staticflickr.com/2830/32216998463_c7897cf1d5_o.png" alt=""></p>
<p>同样的 3D 可视化可以在 <a href="http://scs.ryerson.ca/~aharley/vis/conv/" target="_blank" rel="external"> 这里 </a> 看到。</p>
<h3 id="Other-ConvNet"><a href="#Other-ConvNet" class="headerlink" title="Other ConvNet"></a>Other ConvNet</h3><p>卷积神经网络从上世纪 90 年代初期开始出现。我们上面提到的 LeNet 是早期卷积神经网络之一。其他有一定影响力的架构如下所示：</p>
<ul>
<li>LeNet (1990s)： 本文已介绍。</li>
<li>1990s to 2012：在上世纪 90 年代后期至 2010 年初期，卷积神经网络进入孵化期。随着数据量和计算能力的逐渐发展，卷积神经网络可以处理的问题变得越来越有趣。</li>
<li>AlexNet (2012) – 在 2012，Alex Krizhevsky （与其他人）发布了 <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="external">AlexNet</a>，它是比 LeNet 更深更宽的版本，并在 2012 年的 ImageNet 大规模视觉识别大赛（ImageNet Large Scale Visual Recognition Challenge，ILSVRC）中以巨大优势获胜。这对于以前的方法具有巨大的突破，当前 CNN 大范围的应用也是基于这个工作。</li>
<li>ZF Net (2013) – ILSVRC 2013 的获胜者是来自 Matthew Zeiler 和 Rob Fergus 的卷积神经网络。它以 <a href="http://arxiv.org/abs/1311.2901" target="_blank" rel="external">ZFNet</a> （Zeiler &amp; Fergus Net 的缩写）出名。它是在 AlexNet 架构超参数上进行调整得到的效果提升。</li>
<li>GoogLeNet (2014) – ILSVRC 2014 的获胜者是来自于 Google 的 <a href="http://arxiv.org/abs/1409.4842" target="_blank" rel="external">Szegedy</a>等人的卷积神经网络。它的主要贡献在于使用了一个 Inception 模块，可以大量减少网络的参数个数（4M，AlexNet 有 60M 的参数）。</li>
<li>VGGNet (2014) – 在 ILSVRC 2014 的领先者中有一个 <a href="http://www.robots.ox.ac.uk/~vgg/research/very_deep/" target="_blank" rel="external">VGGNet</a> 的网络。它的主要贡献是展示了网络的深度（层数）对于性能具有很大的影响。</li>
<li>ResNets (2015) – <a href="http://arxiv.org/abs/1512.03385" target="_blank" rel="external">残差网络 </a> 是何凯明（和其他人）开发的，并赢得 ILSVRC 2015 的冠军。ResNets 是当前卷积神经网络中最好的模型，也是实践中使用 ConvNet 的默认选择（截至到 2016 年五月）。</li>
<li>DenseNet (2016 八月) – 近来由 Gao Huang （和其他人）发表的，<a href="http://arxiv.org/abs/1608.06993" target="_blank" rel="external">the Densely Connected Convolutional Network</a> 的各层都直接于其他层以前向的方式连接。DenseNet 在五种竞争积累的目标识别基准任务中，比以前最好的架构有显著的提升。可以在 <a href="https://github.com/liuzhuang13/DenseNet" target="_blank" rel="external"> 这里 </a> 看 Torch 实现。</li>
</ul>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/03/03/「Machine Learning」 Factorization Machines/" rel="next" title="「Machine Learning」 Factorization Machines">
                <i class="fa fa-chevron-left"></i> 「Machine Learning」 Factorization Machines
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/03/10/♜「Papers」About Text Classification based on CNN/" rel="prev" title="♜「Papers」 About Text Classification based on CNN">
                ♜「Papers」 About Text Classification based on CNN <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="Randolph" />
          <p class="site-author-name" itemprop="name">Randolph</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">31</span>
                <span class="site-state-item-name">Posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">Categories</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">Tags</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/RandolphVI" target="_blank" title="Github">
                  
                    <i class="fa fa-fw fa-github-alt"></i>
                  
                  Github
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.linkedin.com/in/威-黄-88060b74/" target="_blank" title="LinkedIn">
                  
                    <i class="fa fa-fw fa-linkedin"></i>
                  
                  LinkedIn
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://music.163.com/#/user/home?id=57901575" target="_blank" title="Music">
                  
                    <i class="fa fa-fw fa-music"></i>
                  
                  Music
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://steamcommunity.com/id/Chinawolfman/" target="_blank" title="Steam">
                  
                    <i class="fa fa-fw fa-steam"></i>
                  
                  Steam
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="https://www.tensorflow.org" title="TensorFlow" target="_blank">TensorFlow</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://www.kaggle.com" title="Kaggle" target="_blank">Kaggle</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://leetcode.com" title="LeetCode" target="_blank">LeetCode</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://weekly.codetengu.com" title="CodeTengu" target="_blank">CodeTengu</a>
                </li>
              
            </ul>
          </div>
        
        
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=320 height=150 src="//music.163.com/outchain/player?type=0&id=2148530957&auto=1&height=90"></iframe>

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Perceptron"><span class="nav-number">1.1.</span> <span class="nav-text">Perceptron</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#"><span class="nav-number">2.</span> <span class="nav-text">#</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Build-a-Multilayer-Convolutional-Network"><span class="nav-number">2.1.</span> <span class="nav-text">Build a Multilayer Convolutional Network</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#What’s-CNN"><span class="nav-number">2.2.</span> <span class="nav-text">What’s CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Convolution"><span class="nav-number">2.2.1.</span> <span class="nav-text">Convolution</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ReLU"><span class="nav-number">2.2.2.</span> <span class="nav-text">ReLU</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ReLU 的种类"><span class="nav-number">2.2.2.1.</span> <span class="nav-text">ReLU 的种类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#效果"><span class="nav-number">2.2.2.2.</span> <span class="nav-text">效果 </span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#参考文献"><span class="nav-number">2.2.2.3.</span> <span class="nav-text">参考文献</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pooling"><span class="nav-number">2.2.3.</span> <span class="nav-text">Pooling</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Connect"><span class="nav-number">2.2.4.</span> <span class="nav-text">Connect</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Use-Backpropagation-to-Train-whole-network"><span class="nav-number">2.2.5.</span> <span class="nav-text">Use Backpropagation to Train whole network</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Visualization-on-CNN"><span class="nav-number">2.2.6.</span> <span class="nav-text">Visualization on CNN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Other-ConvNet"><span class="nav-number">2.2.7.</span> <span class="nav-text">Other ConvNet</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="motto" >
  <span class="motto">「莫怕真理无穷 进一寸便有进一寸的欢喜」</span>
</div>

<div class="copyright">
  
  &copy;  2017 - 
  <span itemprop="copyrightYear">2018</span>
  
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  
  <span class="author" itemprop="copyrightHolder">Randolph</span>
  
</div>

<!--  -->
<!-- <div class="powered-by"> -->
<!--   Powered by <a class="theme-link" href="https://hexo.io">Hexo</a> -->
<!-- </div> -->
<!--  -->
<!-- <div class="theme-info"> -->
<!--   Theme - -->
<!--   <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next"> -->
<!--     NexT.Mist -->
<!--   </a> -->
<!-- </div> -->


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 鸿儒之顾
      <span class="stop">:</span>
      <span class="busuanzi-value" id="busuanzi_value_site_uv" style="display: inline;"></span>
      
    </span>
    
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 管中窥豹
      <span class="stop">:</span>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  

    
      <script id="dsq-count-scr" src="https://randolphvi.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://randolph.pro/2017/03/07/「Machine Learning」 CNN Introduction/';
          this.page.identifier = '2017/03/07/「Machine Learning」 CNN Introduction/';
          this.page.title = '「Machine Learning」 CNN Introduction';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://randolphvi.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  








  




  
  
  
  <link rel="stylesheet" href="/lib/algolia-instant-search/instantsearch.min.css">

  
  
  <script src="/lib/algolia-instant-search/instantsearch.min.js"></script>
  

  <script src="/js/src/algolia-search.js?v=5.1.1"></script>



  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("rlX1ugcCzQRlB8ljks0eiIKp-gzGzoHsz", "kpFrsFctrAimlBvhHvlgWnhV");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



  

  

  
  


  

  

</body>
</html>
